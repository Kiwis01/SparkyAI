{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparky Discord Bot: AI-Powered ASU Information Assistant\n",
    "\n",
    "## Key Features\n",
    "- **Intelligent Q&A**: Powered by Vertex AI (Gemini) for answering ASU-related student queries\n",
    "- **Advanced Search**: Integrates Hugging Face models, Qdrant vector database, and multiple retrieval methods\n",
    "- **Multi-step Reasoning**: Supports complex information retrieval across multiple sources\n",
    "- **Dynamic User Interaction**: Provides context-aware responses with citation tracking\n",
    "- **Optimized Retrieval**: Implements RAPTOR, MIPS, and ScaNN for efficient information retrieval\n",
    "- **Cross-Encoder Reranking**: Enhances result relevance through advanced reranking techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This code implements a sophisticated Discord bot designed to assist Arizona State University (ASU) students. The bot utilizes Vertex AI (Gemini) agents for intelligent query processing and leverages advanced technologies like Retrieval-Augmented Generation (RAG) for accurate information retrieval. It integrates with Hugging Face Hub for pre-trained models and embeddings, and uses Qdrant vector database for efficient semantic search.\n",
    "\n",
    "The bot supports multi-step reasoning, allowing it to answer complex queries by synthesizing information from multiple sources. It implements various features such as web scraping, AI-driven summarization, and dynamic access to ASU resources like clubs, events, and scholarships. The code also includes user verification mechanisms, custom Discord commands, and extensive error handling.\n",
    "\n",
    "Advanced retrieval methods such as RAPTOR (Retrieval Augmented Prompt Tree Optimization and Refinement), Maximum Inner Product Search (MIPS), and ScaNN (Scalable Nearest Neighbors) are implemented to enhance search efficiency and accuracy. Cross-encoder reranking further improves the relevance of retrieved results.\n",
    "\n",
    "Additionally, it incorporates analytics capabilities for tracking bot interactions and user activity, making it a comprehensive solution for ASU-related inquiries within a Discord environment[1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components\n",
    "- **AI Agent**: Gemini-powered intelligent response generation\n",
    "- **Vector Database**: Qdrant for efficient semantic search\n",
    "- **Embedding Model**: Hugging Face transformers for text representation\n",
    "- **Discord Integration**: Real-time interaction and information retrieval\n",
    "- **Retrieval Methods**: RAPTOR, MIPS, and ScaNN for optimized search\n",
    "- **Reranking**: Cross-encoder model for improved result relevance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upgrade pip to ensure we have the latest version for package management\n",
    "# %pip install --upgrade pip\n",
    "\n",
    "# # AI/ML packages\n",
    "# # For using pre-tained NLP models and pipelines\n",
    "# %pip install transformers -U  \n",
    "\n",
    "# # Google's Generative AI libraries\n",
    "# # type 1 - Official Google Generatie AI library\n",
    "# %pip install google-generativeai\n",
    "# # type 2 - Alternative Google Genrative AI library\n",
    "# %pip install google-genai\n",
    "\n",
    "# # LangChain and related packages for building applications with LLMs\n",
    "# %pip install langchain\n",
    "# # Integration with Huggng Face models\n",
    "# %pip install langchain-huggingface  \n",
    "# # For vector store integration\n",
    "# %pip install langchain-qdrant  \n",
    "# # Access to Hugging Face model hub\n",
    "# %pip install huggingface_hub  \n",
    "# # Community extensions for Langhain\n",
    "# %pip install -U langchain-community  \n",
    "\n",
    "# # Database and vector stores for efficient similarity search\n",
    "# # Qdrant vector database client\n",
    "# %pip install qdrant-client  \n",
    "# %pip install scikit-learn numpy\n",
    "\n",
    "# # ChromaDB for document storae and retrieval\n",
    "# %pip install chromadb  \n",
    "# # Facebook AI SimilaritySearch (GPU version)\n",
    "# %pip install faiss-gpu  \n",
    "\n",
    "# # Web and utilities\n",
    "# # For Discord bot fuctionality\n",
    "# %pip install discord.py\n",
    "# # For making HTTP requess  \n",
    "# %pip install requests  \n",
    "# # For web scraping\n",
    "# %pip install beautiulsoup4\n",
    "#  # Asynchronous HTTP client/erver  \n",
    "# %pip install aiohttp \n",
    "# # For retrying operatins\n",
    "# %pip install tenacity \n",
    "# # Interactive widgets fr Jupyter notebooks\n",
    "# %pip install ipywidgets \n",
    "# # For unit testing\n",
    "# %pip install pytest \n",
    "# # For asynchronous proramming\n",
    "# %pip install asyncio  \n",
    "# # To allow asyncio to wrk in Jupyter notebooks\n",
    "# %pip install nest_asyncio  \n",
    "# # For web browser automation\n",
    "# %pip install selenium \n",
    "# # For managing SeleniumWebDriver\n",
    "# %pip install webdriver-manager  \n",
    "# %pip install urllib\n",
    "# # Cryptography libray, required for voice in Discord\n",
    "# %pip install PyNaCl \n",
    "# # For ASCII transliteations of Unicode text\n",
    "# %pip install unidecode  \n",
    "# # For converting HTML to lain text\n",
    "# %pip install html2text  \n",
    "# # Google Cloud AI Platfor\n",
    "# %pip install --upgrade googe-cloud-aiplatform  \n",
    "# %pip install sentence-transformers hnswlib \n",
    "\n",
    "\n",
    "# # Google API related packages\n",
    "# %pip install google-auth-oauthib google-auth-httplib2 google-api-python-client\n",
    "# %pip install google-cloud-firestore\n",
    "# %pip install firebase_admin\n",
    "\n",
    "\n",
    "# # Natural Language Toolkit for text processing\n",
    "# %pip install nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os  # For operating system related operations\n",
    "import json  # For JSON data handling\n",
    "import time  # For time-related functions\n",
    "import random  # For generating random numbers\n",
    "import uuid  # For generating unique identifiers\n",
    "import re  # For regular expressions\n",
    "import smtplib  # For sending emails\n",
    "import asyncio  # For asynchronous programming\n",
    "import traceback  # For exception handling and stack traces\n",
    "import concurrent.futures  # For parallel execution of tasks\n",
    "import tracemalloc  # For tracking memory allocations\n",
    "from datetime import datetime  # For date and time operations\n",
    "from email.mime.text import MIMEText  # For creating email messages\n",
    "from typing import Dict, Any, Callable, Optional, List, Union, Tuple  # For type hinting\n",
    "from dataclasses import dataclass  # For creating data classes\n",
    "from urllib.parse import quote_plus, urlparse, parse_qs  # For URL parsing and encoding\n",
    "import urllib.parse\n",
    "\n",
    "\n",
    "# Third-party library imports\n",
    "import requests  # For making HTTP requests\n",
    "import aiohttp  # For asynchronous HTTP requests\n",
    "import discord  # For Discord bot functionality\n",
    "from discord import app_commands\n",
    "from discord.ui import Modal, TextInput\n",
    "import nest_asyncio  # For nested asyncio support\n",
    "import nltk  # Natural Language Toolkit\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup  # For web scraping\n",
    "from unidecode import unidecode  # For Unicode to ASCII conversion\n",
    "\n",
    "# Lang Chain Imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain_qdrant import Qdrant, QdrantVectorStore \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_community.vectorstores import ScaNN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.models import Distance, VectorParams, OptimizersConfigDiff\n",
    "from huggingface_hub import login\n",
    "import hnswlib\n",
    "from sentence_transformers import CrossEncoder\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from qdrant_client.http.models import Filter, FieldCondition, MatchAny\n",
    "\n",
    "## Google APIs\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.discovery import build\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import Flow\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, firestore\n",
    "\n",
    "\n",
    "# Selenium Imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, TimeoutException\n",
    "\n",
    "# Webscrape Utilities\n",
    "from html2markdown import convert\n",
    "import html2text\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "from itertools import cycle\n",
    "\n",
    "# Google AI imports\n",
    "import google.generativeai as genai\n",
    "from google.ai.generativelanguage_v1beta.types import content\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "from google import genai as genai2\n",
    "from google.genai import types\n",
    "from google.genai.types import Tool, GenerateContentConfig, GoogleSearch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Environment \n",
    "\n",
    "This AppConfig class is the heart of our configuration management. It's designed to load and provide easy access to various configuration settings that our bot needs. We're using a JSON file (appConfig.json by default) to store these settings, which makes it easy to modify without changing the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppConfig:\n",
    "    def __init__(self, config_file='appConfig.json'):\n",
    "        with open(config_file, 'r') as file:\n",
    "            config_data = json.load(file)\n",
    "        \n",
    "        os.environ['NUMEXPR_MAX_THREADS'] = config_data.get('NUMEXPR_MAX_THREADS', '16')\n",
    "        os.environ['HUGGINGFACEHUB_API_TOKEN'] = config_data.get('HUGGINGFACEHUB_API_TOKEN', '')\n",
    "        self._api_key = config_data.get('API_KEY', '')\n",
    "        self.handshake_user = config_data.get('HANDSHAKE_USER', '')\n",
    "        self.handshake_pass = config_data.get('HANDSHAKE_PASS', '')\n",
    "        self.gmail = config_data.get('GMAIL', '')\n",
    "        self.gmail_pass = config_data.get('GMAIL_PASS', '')\n",
    "        self.spreadsheet_id = config_data.get('SPREADSHEET_ID', '')\n",
    "        \n",
    "        self.main_agent_prompt = config_data.get('MAIN_AGENT_PROMPT', '')\n",
    "        \n",
    "        self.live_status_agent_prompt = config_data.get('LIVE_STATUS_AGENT_PROMPT', '')\n",
    "        self.live_status_agent_instruction = config_data.get('LIVE_STATUS_AGENT_INSTRUCTION', '')\n",
    "        \n",
    "        self.discord_agent_prompt = config_data.get('DISCORD_AGENT_PROMPT', '')\n",
    "        self.discord_agent_instruction = config_data.get('DISCORD_AGENT_INSTRUCTION', '')\n",
    "        \n",
    "        self.search_agent_prompt = config_data.get('SEARCH_AGENT_PROMPT', '')\n",
    "        self.search_agent_instruction = config_data.get('SEARCH_AGENT_INSTRUCTION', '')\n",
    "        \n",
    "        self.action_agent_prompt = config_data.get('ACTION_AGENT_PROMPT', '')\n",
    "        self.action_agent_instruction = config_data.get('ACTION_AGENT_INSTRUCTION', '')\n",
    "        \n",
    "        \n",
    "        self.search_agent_prompt = config_data.get('SEARCH_AGENT_PROMPT', '')\n",
    "        self.search_agent_instruction = config_data.get('SEARCH_AGENT_INSTRUCTION', '')\n",
    "        \n",
    "        self.discord_agent_prompt = config_data.get('DISCORD_AGENT_PROMPT', '')\n",
    "        self.discord_agent_instruction = config_data.get('DISCORD_AGENT_INSTRUCTION', '')\n",
    "        \n",
    "        self.google_agent_prompt = config_data.get('GOOGLE_AGENT_PROMPT', '')\n",
    "        self.google_agent_instruction = config_data.get('GOOGLE_AGENT_INSTRUCTION', '')\n",
    "        self.data_agent_prompt = config_data.get('DATA_AGENT_PROMPT', '')\n",
    "        self.discord_bot_token = config_data.get('DISCORD_BOT_TOKEN', '')\n",
    "        self.kubernetes_api_key = config_data.get('KUBERNETES_SECRET', '')\n",
    "        self.qdrant_api_key = config_data.get('QDRANT_API_KEY', '')\n",
    "\n",
    "    def get_numexpr_max_threads(self):\n",
    "        return os.environ['NUMEXPR_MAX_THREADS']\n",
    "\n",
    "    def get_huggingfacehub_api_token(self):\n",
    "        return os.environ['HUGGINGFACEHUB_API_TOKEN']\n",
    "\n",
    "    def get_qdrant_api_key(self):\n",
    "        return self.qdrant_api_key\n",
    "    \n",
    "    def get_discord_bot_token(self):\n",
    "        return self.discord_bot_token\n",
    "\n",
    "    def get_kubernetes_api_key(self):\n",
    "        return self.kubernetes_api_key\n",
    "    \n",
    "    def get_data_agent_prompt(self):\n",
    "        return self.data_agent_prompt\n",
    "    \n",
    "    \n",
    "    def get_live_status_agent_prompt(self):\n",
    "        return self.live_status_agent_prompt\n",
    "    def get_live_status_agent_instruction(self):\n",
    "        return self.live_status_agent_instruction\n",
    "    \n",
    "    def get_discord_agent_prompt(self):\n",
    "        return self.discord_agent_prompt\n",
    "    def get_discord_agent_instruction(self):\n",
    "        return self.discord_agent_instruction\n",
    "    \n",
    "    def get_search_agent_prompt(self):\n",
    "        return self.search_agent_prompt\n",
    "    def get_search_agent_instruction(self):\n",
    "        return self.search_agent_instruction\n",
    "    \n",
    "    \n",
    "    def get_action_agent_prompt(self):\n",
    "        return self.action_agent_prompt\n",
    "    def get_action_agent_instruction(self):\n",
    "        return self.action_agent_instruction\n",
    "    \n",
    "    def get_google_agent_prompt(self):\n",
    "        return self.google_agent_prompt\n",
    "    def get_google_agent_instruction(self):\n",
    "        return self.google_agent_instruction\n",
    "    \n",
    "    def get_api_key(self):\n",
    "        return self._api_key\n",
    "    def get_handshake_user(self):\n",
    "        return self.handshake_user\n",
    "    def get_handshake_pass(self):\n",
    "        return self.handshake_pass\n",
    "    def get_gmail(self):\n",
    "        return self.gmail\n",
    "    def get_spreadsheet_id(self):\n",
    "        return self.spreadsheet_id\n",
    "    def get_gmail_pass(self):\n",
    "        return self.gmail_pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "        self.action_agent_prompt = config_data.get('ACTION_AGENT_PROMPT', '')\n",
    "        self.action_agent_instruction = config_data.get('ACTION_AGENT_INSTRUCTION', '')\n",
    "        # ... (similar lines for other agent prompts and instructions)\n",
    "```\n",
    "These are the prompts and instructions for our various AI agents. Each agent (main, live status, discord, search, action, deep search, google, data) has its own prompt and sometimes an instruction. This modular approach allows us to fine-tune the behavior of each agent independently.\n",
    "\n",
    "```python\n",
    "    def get_numexpr_max_threads(self):\n",
    "        return os.environ['NUMEXPR_MAX_THREADS']\n",
    "\n",
    "    def get_huggingfacehub_api_token(self):\n",
    "        return os.environ['HUGGINGFACEHUB_API_TOKEN']\n",
    "\n",
    "    # ... (other getter methods)\n",
    "```\n",
    "\n",
    "These getter methods provide a clean interface to access our configuration values. They're particularly useful for values that might change during runtime or need some processing before being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "        os.environ['NUMEXPR_MAX_THREADS'] = config_data.get('NUMEXPR_MAX_THREADS', '16')\n",
    "        os.environ['HUGGINGFACEHUB_API_TOKEN'] = config_data.get('HUGGINGFACEHUB_API_TOKEN', '')\n",
    "```\n",
    "\n",
    "Here, we're setting some environment variables. The `NUMEXPR_MAX_THREADS` is used to control parallel processing, while `HUGGINGFACEHUB_API_TOKEN` is crucial for accessing Hugging Face's models and services.\n",
    "\n",
    "```python\n",
    "        self._api_key = config_data.get('API_KEY', '')\n",
    "        self.handshake_user = config_data.get('HANDSHAKE_USER', '')\n",
    "        self.handshake_pass = config_data.get('HANDSHAKE_PASS', '')\n",
    "        self.gmail = config_data.get('GMAIL', '')\n",
    "        self.gmail_pass = config_data.get('GMAIL_PASS', '')\n",
    "        self.spreadsheet_id = config_data.get('SPREADSHEET_ID', '')\n",
    "```\n",
    "\n",
    "These lines are loading various API keys and credentials. We're using them for different services like email notifications and Google Sheets integration. The `get` method with default empty strings ensures our code doesn't crash if a key is missing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Here, we're creating a global instance of our `AppConfig` class. This allows us to access our configuration from anywhere in the code simply by importing `app_config`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_config = AppConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set up logging. This is crucial for debugging and monitoring our bot's behavior. We're logging to both a file and the console, which helps in development and production environments. The `tracemalloc.start()` line enables memory allocation tracking, which can be super helpful for optimizing our bot's performance.\n",
    "\n",
    "This configuration setup allows us to easily manage and update various settings, API keys, and agent behaviors without diving into the core code. It's a crucial part of making our bot flexible and maintainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/data_processor.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "tracemalloc.start()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discord State Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This setup allows us to maintain a consistent state for our Discord bot and provides easy access to our AI model throughout the application. It's designed to be flexible and easy to manage, which is crucial for a complex bot like ours that interacts with both Discord and AI services.\n",
    "\n",
    "```python\n",
    "class DiscordState:\n",
    "    def __init__(self):\n",
    "        nest_asyncio.apply()\n",
    "        self.intents = discord.Intents.default()\n",
    "        self.intents.message_content = True\n",
    "        self.intents.members = True\n",
    "        # ... (other attribute initializations)\n",
    "```\n",
    "\n",
    "The `DiscordState` class is crucial for managing the state of our Discord bot. Here's what's happening:\n",
    "\n",
    "- We apply `nest_asyncio` to allow nested event loops, which can be necessary in some environments.\n",
    "- We set up Discord intents, which define what events our bot can receive. We're enabling message content and member information access.\n",
    "- We initialize various attributes to track the bot's state, such as the current user, guild, and voice channel information.\n",
    "\n",
    "```python\n",
    "    def update(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                raise AttributeError(f\"DiscordState has no attribute '{key}'\")\n",
    "```\n",
    "\n",
    "This `update` method allows us to update multiple attributes of our Discord state at once. It's a convenient way to keep our state in sync with the current Discord context.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DiscordState:\n",
    "    def __init__(self):\n",
    "        nest_asyncio.apply()\n",
    "        self.intents = discord.Intents.default()\n",
    "        self.intents.message_content = True\n",
    "        self.intents.members = True\n",
    "        self.user = False\n",
    "        self.target_guild = None\n",
    "        self.user_id = None\n",
    "        self.user_has_mod_role = False\n",
    "        self.user_in_voice_channel = False\n",
    "        self.request_in_dm = False\n",
    "        self.guild_user= None\n",
    "        self.user_voice_channel_id = None\n",
    "        self.discord_client = discord.Client(intents=self.intents)\n",
    "        self.task_message = None\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                raise AttributeError(f\"DiscordState has no attribute '{key}'\")\n",
    "\n",
    "    def get(self, attr):\n",
    "        if hasattr(self, attr):\n",
    "            return getattr(self, attr)\n",
    "        else:\n",
    "            raise AttributeError(f\"DiscordState has no attribute '{attr}'\")\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join([f\"{attr}: {getattr(self, attr)}\" for attr in vars(self) if not attr.startswith('__')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    def get(self, attr):\n",
    "        if hasattr(self, attr):\n",
    "            return getattr(self, attr)\n",
    "        else:\n",
    "            raise AttributeError(f\"DiscordState has no attribute '{attr}'\")\n",
    "```\n",
    "\n",
    "The `get` method provides a safe way to retrieve attribute values. It raises an error if we try to access a non-existent attribute, which helps catch bugs early.\n",
    "\n",
    "```python\n",
    "    def __str__(self):\n",
    "        return \"\\n\".join([f\"{attr}: {getattr(self, attr)}\" for attr in vars(self) if not attr.startswith('__')])\n",
    "```\n",
    "\n",
    "This `__str__` method gives us a nice string representation of our Discord state, which is super helpful for debugging and logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "discord_state = DiscordState()\n",
    "```\n",
    "\n",
    "Here, we're creating a global instance of our `DiscordState`. This allows us to access and update the Discord state from anywhere in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discord_state = DiscordState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model and Database Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's look at the model initialization:\n",
    "\n",
    "```python\n",
    "genai.configure(api_key=app_config.get_api_key())\n",
    "dir_Model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "```\n",
    "1. We're configuring the Google Generative AI (genai) with our API key, which we fetch from our AppConfig.\n",
    "2. We're initializing our main AI model, specifically the 'gemini-1.5-flash' model. This is a powerful model that we'll use for generating responses and processing queries.\n",
    "3. Finally, we log a success message to confirm that our global variables for the model and database (if applicable) have been initialized correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "genai.configure(api_key=app_config.get_api_key())\n",
    "dir_Model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "logger.info(\"\\nSuccessfully initialized global variables for model and database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qdrant Vector Storage\n",
    "\n",
    "\n",
    "This class is designed for efficient vector storage and retrieval, with features like automatic version control, duplicate handling, and optimized semantic search capabilities. It's built to be robust and performant, suitable for large-scale document processing and storage operations. The addition of MIPS search and HNSWlib integration further enhances its search capabilities and performance for real-time applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "- The `__init__` method sets up the vector store with configurable parameters like host, port, collection name, and embedding model.\n",
    "- It initializes connections to Qdrant and sets up the embedding model.\n",
    "- Error handling and logging are implemented for initialization failures.\n",
    "\n",
    "### Embedding Model\n",
    "- The `_initialize_embedding_model` method sets up a HuggingFace embedding model (default: \"BAAI/bge-large-en-v1.5\").\n",
    "- It determines the vector size based on a test embedding.\n",
    "\n",
    "### Qdrant Client\n",
    "- `_create_qdrant_client` establishes a connection to the Qdrant server with retry logic.\n",
    "- It attempts to connect multiple times before raising an error.\n",
    "\n",
    "### Collection Management\n",
    "- `_setup_collection` checks for existing collections and creates a new one if needed.\n",
    "- `_verify_collection_dimensions` ensures the existing collection matches the current model's vector size.\n",
    "- `_create_collection` sets up a new Qdrant collection with specified parameters.\n",
    "\n",
    "### Document Storage\n",
    "- `store_to_vector_db` is an asynchronous method for storing documents in batches.\n",
    "- It includes logic for skipping duplicates and handling errors during storage.\n",
    "\n",
    "### Document Processing\n",
    "- `_should_store_document` checks if a document should be stored based on existing data and timestamps.\n",
    "- It implements version control by replacing outdated documents.\n",
    "\n",
    "### Vector Store Initialization\n",
    "- `_initialize_vector_store` sets up the QdrantVectorStore with the configured client and embedding model.\n",
    "\n",
    "### Error Handling and Logging\n",
    "- Comprehensive error logging is implemented throughout the class.\n",
    "- `_log_detailed_error` provides in-depth error diagnostics.\n",
    "\n",
    "### MIPS Search\n",
    "- The `mips_search` method performs Maximum Inner Product Search on the vector database.\n",
    "- It returns formatted results with metadata and similarity scores.\n",
    "\n",
    "### HNSWlib Integration\n",
    "- The `build_hnsw_index` method constructs an HNSW index for efficient similarity search.\n",
    "- It uses all documents in the collection to build the index.\n",
    "\n",
    "### Document Retrieval\n",
    "- The `get_all_documents` method retrieves all documents from the Qdrant collection.\n",
    "- The `get_embeddings` method generates embeddings for given documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class VectorStore:\n",
    "    \n",
    "    \"\"\"A class to manage vector storage operations using Qdrant with enhanced logging and performance.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 force_recreate: bool = False,\n",
    "                 host: str = \"10.10.0.9\",\n",
    "                 port: int = 6333,\n",
    "                 collection_name: str = \"asu_docs\",\n",
    "                 model_name: str = \"BAAI/bge-large-en-v1.5\",\n",
    "                 batch_size: int = 100,\n",
    "                 max_retry_attempts: int = 3,\n",
    "                 retry_delay: int = 2):\n",
    "        \"\"\"\n",
    "        Initialize the VectorStore with specified parameters and enhanced error handling.\n",
    "        \n",
    "        Args:\n",
    "            force_recreate (bool): Whether to recreate the collection if it exists\n",
    "            host (str): Qdrant server host\n",
    "            port (int): Qdrant server port\n",
    "            collection_name (str): Name of the collection\n",
    "            model_name (str): Name of the embedding model\n",
    "            batch_size (int): Size of batches for document processing\n",
    "            max_retry_attempts (int): Maximum number of retry attempts for operations\n",
    "            retry_delay (int): Delay between retry attempts in seconds\n",
    "        \"\"\"\n",
    "        self.vector_store: Optional[QdrantVectorStore] = None\n",
    "        self.collection_name = collection_name\n",
    "        self.batch_size = batch_size\n",
    "        self.max_retry_attempts = max_retry_attempts\n",
    "        self.retry_delay = retry_delay\n",
    "        self.corpus = []\n",
    "        self.hnsw_index = None\n",
    "\n",
    "\n",
    "        \n",
    "        logger.info(f\"Initializing VectorStore with collection: {collection_name}\")\n",
    "        logger.info(f\"Configuration: host={host}, port={port}, model={model_name}\")\n",
    "        \n",
    "        try:\n",
    "            self.client = self._create_qdrant_client(host, port)\n",
    "            self._initialize_embedding_model(model_name)\n",
    "            self._setup_collection(force_recreate)\n",
    "            self._initialize_vector_store()\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Critical VectorStore initialization error: {str(e)}\", exc_info=True)\n",
    "            self._log_detailed_error(e)\n",
    "            raise RuntimeError(f\"VectorStore initialization failed: {str(e)}\")\n",
    "    \n",
    "    def mips_search(self, query_vector: List[float], top_k: int = 5):\n",
    "        try:\n",
    "            if not self.vector_store:\n",
    "                logger.error(\"Vector store not initialized.\")\n",
    "                raise ValueError(\"Vector store not properly initialized.\")\n",
    "            \n",
    "            if self.hnsw_index is None:\n",
    "                self.build_hnsw_index()\n",
    "            \n",
    "            labels, distances = self.hnsw_index.knn_query(query_vector, k=top_k)\n",
    "            results = []\n",
    "            for label, distance in zip(labels[0], distances[0]):\n",
    "                doc = self.get_document_by_id(int(label))\n",
    "                results.append({\n",
    "                    \"id\": doc.metadata.get('id'),\n",
    "                    \"score\": 1 - distance,  # Convert distance to similarity score\n",
    "                    \"payload\": {\n",
    "                        \"page_content\": doc.page_content,\n",
    "                        \"metadata\": doc.metadata\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            logger.info(f\"MIPS search retrieved {len(results)} results.\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during MIPS search: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def build_hnsw_index(self):\n",
    "        all_docs = self.get_all_documents()\n",
    "        all_embeddings = self.get_embeddings(all_docs)\n",
    "        \n",
    "        self.hnsw_index = hnswlib.Index(space='cosine', dim=self.vector_size)\n",
    "        self.hnsw_index.init_index(max_elements=len(all_docs), ef_construction=200, M=16)\n",
    "        self.hnsw_index.add_items(all_embeddings, np.arange(len(all_docs)))\n",
    "        self.hnsw_index.set_ef(50)  # Adjust for speed/accuracy trade-off\n",
    "\n",
    "    def _initialize_embedding_model(self, model_name: str) -> None:\n",
    "        \"\"\"Initialize the embedding model.\"\"\"\n",
    "        logger.info(f\"Initializing embedding model: {model_name}\")\n",
    "        try:\n",
    "            self.embedding_model = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            )\n",
    "            self.vector_size = len(self.embedding_model.embed_query(\"test\"))\n",
    "            logger.info(f\"Embedding model initialized with vector size: {self.vector_size}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize embedding model: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "    \n",
    "    def _create_qdrant_client(self, host: str, port: int) -> QdrantClient:\n",
    "        for attempt in range(self.max_retry_attempts):\n",
    "            try:\n",
    "                api_key = app_config.get_qdrant_api_key()  # Use the Kubernetes API key for authentication\n",
    "                client = QdrantClient(\n",
    "                url=\"https://4bfefa3a-9337-4325-9836-5f054c1de8d8.us-east-1-0.aws.cloud.qdrant.io\",\n",
    "                api_key=api_key,\n",
    "                prefer_grpc=False\n",
    "                )\n",
    "\n",
    "                logger.info(f\"Successfully connected to Qdrant at {host}:{port} (Attempt {attempt + 1})\")\n",
    "                return client\n",
    "            except Exception as e:\n",
    "                if attempt == self.max_retry_attempts - 1:\n",
    "                    logger.error(f\"Failed to connect to Qdrant after {self.max_retry_attempts} attempts\")\n",
    "                    raise\n",
    "                logger.warning(f\"Qdrant connection attempt {attempt + 1} failed: {str(e)}\")\n",
    "                time.sleep(self.retry_delay)\n",
    "    \n",
    "    def _verify_collection_dimensions(self) -> None:\n",
    "        \"\"\"Verify that existing collection dimensions match the model.\"\"\"\n",
    "        collection_info = self.client.get_collection(self.collection_name)\n",
    "        existing_size = collection_info.config.params.vectors.size\n",
    "        \n",
    "        if existing_size != self.vector_size:\n",
    "            error_msg = (f\"Dimension mismatch: Collection has {existing_size}, \"\n",
    "                        f\"model requires {self.vector_size}\")\n",
    "            logger.error(error_msg)\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "        logger.info(f\"Verified collection dimensions: {existing_size}\")\n",
    "    \n",
    "    def _log_detailed_error(self, exception: Exception) -> None:\n",
    "        \"\"\"\n",
    "        Log detailed error information for diagnostics.\n",
    "        \n",
    "        Args:\n",
    "            exception (Exception): The exception to log details for\n",
    "        \"\"\"\n",
    "        logger.error(\"Detailed Error Diagnostics:\")\n",
    "        logger.error(f\"Error Type: {type(exception).__name__}\")\n",
    "        logger.error(f\"Error Message: {str(exception)}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "    \n",
    "    def _setup_collection(self, force_recreate: bool) -> None:\n",
    "        \"\"\"Set up the Qdrant collection.\"\"\"\n",
    "        try:\n",
    "            collections = self.client.get_collections().collections\n",
    "            collection_exists = any(c.name == self.collection_name for c in collections)\n",
    "            \n",
    "            if collection_exists:\n",
    "                if force_recreate:\n",
    "                    logger.info(f\"Force recreating collection: {self.collection_name}\")\n",
    "                    self.client.delete_collection(self.collection_name)\n",
    "                    collection_exists = False\n",
    "                else:\n",
    "                    self._verify_collection_dimensions()\n",
    "            \n",
    "            if not collection_exists:\n",
    "                self._create_collection()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup collection: {str(e)}\", exc_info=True)\n",
    "    \n",
    "    def _create_collection(self) -> None:\n",
    "        \"\"\"Create a new Qdrant collection.\"\"\"\n",
    "        logger.info(f\"Creating new collection: {self.collection_name}\")\n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config=VectorParams(\n",
    "                size=self.vector_size,\n",
    "                distance=Distance.COSINE\n",
    "            ),\n",
    "            optimizers_config=OptimizersConfigDiff(\n",
    "                default_segment_number=2,\n",
    "                memmap_threshold=20000\n",
    "            )\n",
    "        )\n",
    "        logger.info(\"\\nCollection created successfully\")\n",
    "    \n",
    "    def queue_documents(self, docs: List[Document]) -> None:\n",
    "        \"\"\"Queue documents for storage.\"\"\"\n",
    "        self.corpus.extend(docs)\n",
    "        logger.info(\"Queued Processed Documents\")\n",
    "        return True\n",
    "  \n",
    "    async def store_to_vector_db(self) -> bool:\n",
    "        if self.vector_store is None and self.corpus is None:\n",
    "            logger.critical(\"Vector store not initialized - cannot proceed\")\n",
    "            raise ValueError(\"Vector store not properly initialized\")\n",
    "\n",
    "        total_docs = len(self.corpus)\n",
    "        logger.info(f\"Document storage initiated: {total_docs} documents to process\")\n",
    "        performance_start = time.time()\n",
    "        processed_count = 0\n",
    "        skipped_count = 0\n",
    "        error_count = 0\n",
    "        try:\n",
    "            for doc in self.corpus:\n",
    "                logger.debug(f\"Processing document {processed_count + 1}/{total_docs}\")\n",
    "                try:\n",
    "                    should_store = self._should_store_document(doc)\n",
    "                    if should_store:\n",
    "                        await self.vector_store.aadd_documents([doc])\n",
    "                        processed_count += 1\n",
    "                        logger.info(f\"Successfully stored document {processed_count}\")\n",
    "                    else:\n",
    "                        skipped_count += 1\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing document {doc.metadata.get('url', 'Unknown')}: {str(e)}\")\n",
    "                    error_count += 1\n",
    "\n",
    "            performance_end = time.time()\n",
    "            logger.info(f\"Total Documents: {total_docs}\")\n",
    "            logger.info(f\"Processed Documents: {processed_count}\")\n",
    "            logger.info(f\"Skipped Documents: {skipped_count}\")\n",
    "            logger.info(f\"Error Documents: {error_count}\")\n",
    "            logger.info(f\"Total Processing Time: {performance_end - performance_start:.2f} seconds\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Catastrophic document storage failure: {str(e)}\", exc_info=True)\n",
    "            self._log_detailed_error(e)\n",
    "            raise\n",
    "\n",
    "    def _initialize_vector_store(self) -> None:\n",
    "        \"\"\"Initialize the QdrantVectorStore.\"\"\"\n",
    "        logger.info(\"\\nInitializing QdrantVectorStore\")\n",
    "        self.vector_store = QdrantVectorStore(\n",
    "            client=self.client,\n",
    "            collection_name=self.collection_name,\n",
    "            embedding=self.embedding_model,\n",
    "            content_payload_key=\"page_content\",\n",
    "            metadata_payload_key=\"metadata\",\n",
    "            distance=Distance.COSINE\n",
    "        )\n",
    "    \n",
    "    def get_vector_store(self):\n",
    "        return self.vector_store\n",
    "\n",
    "    def _should_store_document(self, doc: Document) -> bool:\n",
    "        try:\n",
    "            urls = doc.metadata['url'] if isinstance(doc.metadata['url'], list) else [doc.metadata['url']]\n",
    "            existing_docs = self.client.scroll(\n",
    "                collection_name=self.collection_name,\n",
    "                scroll_filter=models.Filter(\n",
    "                    must=[\n",
    "                        models.FieldCondition(\n",
    "                            key=\"metadata.url\", \n",
    "                            match=models.MatchAny(any=urls)\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            )[0]\n",
    "            if existing_docs:\n",
    "                logger.info(\"Found existing Docs\\n\")\n",
    "                logger.info(existing_docs)\n",
    "                new_timestamp = doc.metadata.get('timestamp')                \n",
    "                for existing_doc in existing_docs:\n",
    "                    existing_timestamp = existing_doc.payload.get('metadata', {}).get('timestamp')\n",
    "                    # Ensure both timestamps are datetime OBJECTs\n",
    "                    if isinstance(new_timestamp, str):\n",
    "                        new_timestamp = datetime.fromisoformat(new_timestamp)\n",
    "                    if isinstance(existing_timestamp, str):\n",
    "                        existing_timestamp = datetime.fromisoformat(existing_timestamp)\n",
    "                    # Enhanced timestamp comparison with configurable threshold\n",
    "                    if (not existing_timestamp or \n",
    "                        (new_timestamp and \n",
    "                        (new_timestamp - existing_timestamp).total_seconds() >= 60 * 60)):\n",
    "                        # Delete outdated document\n",
    "                        self.client.delete(\n",
    "                            collection_name=self.collection_name,\n",
    "                            points_selector=models.PointIdsList(points=[existing_doc.id])\n",
    "                        )\n",
    "                        logger.info(f\"Replaced document: {urls} due to significant changes\")\n",
    "                    \n",
    "                    logger.debug(f\"Skipping document with minimal time difference: {urls}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Document evaluation error: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def get_all_documents(self):\n",
    "        # Implement method to retrieve all documents from Qdrant\n",
    "        results = self.client.scroll(\n",
    "            collection_name=self.collection_name,\n",
    "            limit=10000  # Adjust as needed\n",
    "        )\n",
    "        return [Document(page_content=item.payload[\"page_content\"], metadata=item.payload[\"metadata\"]) for item in results[0]]\n",
    "\n",
    "    def get_embeddings(self, documents):\n",
    "        return [self.embedding_model.embed_query(self.get_document_content(doc)) for doc in documents]\n",
    "\n",
    "    def get_document_content(self, doc):\n",
    "        if isinstance(doc, str):\n",
    "            try:\n",
    "                doc_dict = json.loads(doc)\n",
    "                return doc_dict.get('page_content', '')\n",
    "            except json.JSONDecodeError:\n",
    "                return doc\n",
    "        else:\n",
    "            return getattr(doc, 'page_content', str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_store = VectorStore(force_recreate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raptor Cluster Implementation\n",
    "\n",
    "The `RaptorRetriever` class implements a hierarchical clustering approach for efficient document retrieval. Here's a detailed explanation of its implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Initialization\n",
    "```python\n",
    "def __init__(self, vector_store, num_levels=3, branching_factor=5):\n",
    "```\n",
    "- Initializes with a vector store, number of hierarchical levels, and branching factor.\n",
    "- Builds the RAPTOR tree upon initialization.\n",
    "\n",
    "### Building the RAPTOR Tree\n",
    "```python\n",
    "def build_raptor_tree(self):\n",
    "```\n",
    "- Creates a hierarchical tree structure for efficient retrieval.\n",
    "- Uses K-means clustering at each level to group documents.\n",
    "- Generates summaries for each cluster.\n",
    "\n",
    "Key steps:\n",
    "1. Retrieves all documents and their embeddings from the vector store.\n",
    "2. For each level:\n",
    "   - Performs K-means clustering with `branching_factor^(level+1)` clusters.\n",
    "   - Groups documents into clusters based on K-means labels.\n",
    "   - Generates summaries for each cluster.\n",
    "   - Stores cluster information and summaries in the tree.\n",
    "   - Uses cluster summaries as documents for the next level.\n",
    "\n",
    "### Summary Generation\n",
    "```python\n",
    "def generate_summary(self, documents):\n",
    "```\n",
    "- Placeholder for summary generation logic.\n",
    "- Currently concatenates the first 50 characters of each document.\n",
    "\n",
    "### Document Retrieval\n",
    "```python\n",
    "def retrieve(self, query, top_k=5):\n",
    "```\n",
    "- Implements the RAPTOR retrieval algorithm.\n",
    "- Traverses the tree from top to bottom, selecting the best cluster at each level.\n",
    "- At the lowest level, performs a similarity search within the best cluster.\n",
    "- Applies reranking to the initial results.\n",
    "\n",
    "Key steps:\n",
    "1. Embeds the query.\n",
    "2. Starts at the top level of the tree.\n",
    "3. At each level, selects the best cluster based on cosine similarity with summaries.\n",
    "4. At the lowest level, performs a similarity search within the selected cluster.\n",
    "5. Reranks the initial results using a cross-encoder.\n",
    "\n",
    "### Result Reranking\n",
    "```python\n",
    "def rerank_results(self, query, initial_results, top_k=5):\n",
    "```\n",
    "- Uses a cross-encoder model to rerank the initial retrieval results.\n",
    "- Improves the relevance of the top results.\n",
    "\n",
    "This implementation combines hierarchical clustering for efficient search space reduction with cross-encoder reranking for improved result relevance, making it suitable for large-scale document retrieval tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "import json\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class RaptorRetriever:\n",
    "    def __init__(self, vector_store, num_levels=3, branching_factor=5):\n",
    "        self.vector_store = vector_store\n",
    "        self.num_levels = num_levels\n",
    "        self.branching_factor = branching_factor\n",
    "        self.tree = self.build_raptor_tree()\n",
    "\n",
    "    def build_raptor_tree(self):\n",
    "        tree = {}\n",
    "        all_docs = self.vector_store.get_all_documents()\n",
    "        all_embeddings = self.vector_store.get_embeddings(all_docs)\n",
    "\n",
    "        if not all_embeddings:\n",
    "            logger.warning(\"No embeddings found. The vector store may be empty.\")\n",
    "            return tree\n",
    "\n",
    "        all_embeddings = np.array(all_embeddings)\n",
    "\n",
    "        for level in range(self.num_levels):\n",
    "            n_clusters = min(self.branching_factor ** (level + 1), len(all_embeddings))\n",
    "            kmeans = KMeans(n_clusters=n_clusters)\n",
    "            cluster_labels = kmeans.fit_predict(all_embeddings)\n",
    "            \n",
    "            clusters = {}\n",
    "            for i, label in enumerate(cluster_labels):\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append(all_docs[i])\n",
    "            \n",
    "            summaries = {label: self.generate_summary(docs) for label, docs in clusters.items()}\n",
    "            logger.info(f\"Generated summaries for level {level + 1}\")\n",
    "            tree[f\"level_{level}\"] = {\n",
    "                \"clusters\": clusters,\n",
    "                \"summaries\": summaries\n",
    "            }\n",
    "            logger.info(f\"Built tree for level {level + 1}\")\n",
    "            \n",
    "            all_docs = list(summaries.values())\n",
    "            logger.info(f\"Retrieved {len(all_docs)} documents for next level\")\n",
    "            all_embeddings = self.vector_store.get_embeddings(all_docs)\n",
    "            logger.info(f\"Retrieved embeddings for next level\")\n",
    "            \n",
    "            if not all_embeddings:\n",
    "                logger.warning(f\"No embeddings found for level {level + 1}. Stopping tree construction.\")\n",
    "                break\n",
    "\n",
    "            all_embeddings = np.array(all_embeddings)\n",
    "        \n",
    "        logger.info(\"Building RAPTOR tree completed.\")\n",
    "        return tree\n",
    "\n",
    "    def generate_summary(self, documents):\n",
    "        summaries = []\n",
    "        for doc in documents:\n",
    "            if isinstance(doc, str):\n",
    "                try:\n",
    "                    doc_dict = json.loads(doc)\n",
    "                    content = doc_dict.get('page_content', '')\n",
    "                except json.JSONDecodeError:\n",
    "                    content = doc\n",
    "            else:\n",
    "                content = getattr(doc, 'page_content', str(doc))\n",
    "            summaries.append(content[:50])\n",
    "            logger.info(\"Generated summary for document.\")\n",
    "        return \" \".join(summaries)[:200]\n",
    "\n",
    "    def retrieve(self, query, top_k=5):\n",
    "        query_embedding = self.vector_store.embedding_model.embed_query(query)\n",
    "        current_level = self.num_levels - 1\n",
    "        current_node = self.tree[f\"level_{current_level}\"]\n",
    "        \n",
    "        while current_level >= 0:\n",
    "            summaries = current_node[\"summaries\"]\n",
    "            summary_embeddings = self.vector_store.get_embeddings(list(summaries.values()))\n",
    "            best_cluster = max(summaries.keys(), key=lambda x: np.dot(query_embedding, summary_embeddings[x]))\n",
    "             \n",
    "            if current_level == 0:\n",
    "                initial_results = self.vector_store.similarity_search(query, filter={\"cluster\": best_cluster}, k=top_k)\n",
    "                return self.rerank_results(query, initial_results, top_k)\n",
    "            \n",
    "            current_level -= 1\n",
    "            current_node = self.tree[f\"level_{current_level}\"]\n",
    "            current_node = {k: v for k, v in current_node.items() if k in current_node[\"clusters\"][best_cluster]}\n",
    "       \n",
    "        logger.info(\"No results found in RAPTOR tree.\")\n",
    "        return []\n",
    "\n",
    "    def rerank_results(self, query, initial_results, top_k=5):\n",
    "        cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "        pairs = [[query, self.get_document_content(doc)] for doc in initial_results]\n",
    "        scores = cross_encoder.predict(pairs)\n",
    "        reranked_results = [doc for _, doc in sorted(zip(scores, initial_results), key=lambda x: x[0], reverse=True)]\n",
    "        logger.info(\"Reranked results.\")\n",
    "        return reranked_results[:top_k]\n",
    "\n",
    "    def get_document_content(self, doc):\n",
    "        if isinstance(doc, str):\n",
    "            try:\n",
    "                doc_dict = json.loads(doc)\n",
    "                logger.info(\"Retrieved document content.\")\n",
    "                return doc_dict.get('page_content', '')\n",
    "            except json.JSONDecodeError:\n",
    "                return doc\n",
    "        else:\n",
    "            return getattr(doc, 'page_content', str(doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor_retriever = RaptorRetriever(asu_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Sheet Database\n",
    "\n",
    "This class, `GoogleSheet`, is designed to manage google sheet database storage operations using Google API, with enhanced logging and performance features. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateTask:\n",
    "    def __init__(self, user_id: str, column: str, value: Any):\n",
    "        self.user_id = user_id\n",
    "        self.column = column\n",
    "        self.value = value\n",
    "\n",
    "class GoogleSheet:\n",
    "    def __init__(self, credentials_file: str, spreadsheet_id: str) -> None:\n",
    "        self.credentials = Credentials.from_service_account_file(\n",
    "            credentials_file,\n",
    "            scopes=['https://www.googleapis.com/auth/spreadsheets']\n",
    "        )\n",
    "        self.spreadsheet_id = spreadsheet_id\n",
    "        self.service = build('sheets', 'v4', credentials=self.credentials, cache_discovery=False)\n",
    "        self.sheet = self.service.spreadsheets()\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.update_tasks: List[UpdateTask] = []\n",
    "        self.user_row_cache: Dict[str, int] = {}\n",
    "\n",
    "    async def get_all_users(self, range_name: str = 'SparkyVerify!A:C'):\n",
    "        try:\n",
    "            result = self.sheet.values().get(\n",
    "                spreadsheetId=self.spreadsheet_id,\n",
    "                range=range_name\n",
    "            ).execute()\n",
    "            return result.get('values', [])\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting all users: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    async def increment_function_call(self, user_id: str, column: str):\n",
    "        self.update_tasks.append(UpdateTask(user_id, column, None))\n",
    "\n",
    "    async def update_user_column(self, user_id: str, column: str, value):\n",
    "        self.update_tasks.append(UpdateTask(user_id, column, value))\n",
    "\n",
    "    async def perform_updates(self):\n",
    "        try:\n",
    "            batch_update_data = []\n",
    "            for task in self.update_tasks:\n",
    "                row = await self.get_user_row(task.user_id)\n",
    "                if row:\n",
    "                    range_name = f'SparkyVerify!{task.column}{row}'\n",
    "                    if task.value is None:  # Increment function call\n",
    "                        current_value = await self.get_cell_value(range_name)\n",
    "                        new_value = int(current_value) + 1 if current_value else 1\n",
    "                    else:\n",
    "                        new_value = task.value\n",
    "                    batch_update_data.append({\n",
    "                        'range': range_name,\n",
    "                        'values': [[new_value]]\n",
    "                    })\n",
    "                else:\n",
    "                    self.logger.warning(f\"User {task.user_id} not found for updating\")\n",
    "\n",
    "            if batch_update_data:\n",
    "                body = {\n",
    "                    'valueInputOption': 'USER_ENTERED',\n",
    "                    'data': batch_update_data\n",
    "                }\n",
    "                self.sheet.values().batchUpdate(\n",
    "                    spreadsheetId=self.spreadsheet_id,\n",
    "                    body=body\n",
    "                ).execute()\n",
    "                self.logger.info(f\"Batch update completed for {len(batch_update_data)} tasks\")\n",
    "            \n",
    "            self.update_tasks.clear()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error performing batch updates: {str(e)}\")\n",
    "\n",
    "    async def get_user_row(self, user_id: str):\n",
    "        if user_id in self.user_row_cache:\n",
    "            return self.user_row_cache[user_id]\n",
    "\n",
    "        try:\n",
    "            range_name = 'SparkyVerify!A:A'\n",
    "            result = self.sheet.values().get(\n",
    "                spreadsheetId=self.spreadsheet_id,\n",
    "                range=range_name\n",
    "            ).execute()\n",
    "            rows = result.get('values', [])\n",
    "            for idx, row in enumerate(rows):\n",
    "                if row and row[0] == str(user_id):\n",
    "                    row_number = idx + 1\n",
    "                    self.user_row_cache[user_id] = row_number\n",
    "                    return row_number\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error finding user row: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    async def get_cell_value(self, range_name: str):\n",
    "        try:\n",
    "            result = self.sheet.values().get(\n",
    "                spreadsheetId=self.spreadsheet_id,\n",
    "                range=range_name\n",
    "            ).execute()\n",
    "            return result.get('values', [[0]])[0][0]\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error getting cell value: {str(e)}\")\n",
    "            return 0\n",
    "\n",
    "    async def add_new_user(self, user, email):\n",
    "        user_data = [str(user.id), user.name, email, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "        existing_row = await self.get_user_row(user.id)\n",
    "        \n",
    "        try:\n",
    "            if existing_row:\n",
    "                range_name = f'SparkyVerify!A{existing_row}:Z{existing_row}'\n",
    "                body = {'values': [user_data]}\n",
    "                self.sheet.values().update(\n",
    "                    spreadsheetId=self.spreadsheet_id,\n",
    "                    range=range_name,\n",
    "                    valueInputOption='USER_ENTERED',\n",
    "                    body=body\n",
    "                ).execute()\n",
    "                self.logger.info(f\"Updated existing user: {user.id}\")\n",
    "            else:\n",
    "                range_name = 'SparkyVerify!A:Z'\n",
    "                body = {'values': [user_data]}\n",
    "                self.sheet.values().append(\n",
    "                    spreadsheetId=self.spreadsheet_id,\n",
    "                    range=range_name,\n",
    "                    valueInputOption='USER_ENTERED',\n",
    "                    body=body\n",
    "                ).execute()\n",
    "                self.logger.info(f\"Added new user: {user.id}\")\n",
    "            \n",
    "            self.user_row_cache[user.id] = await self.get_user_row(user.id)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error adding/updating user: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Global Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_sheet = GoogleSheet('client_secret.json', app_config.get_spreadsheet_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firestore Chat Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using firestore to store chats from user's in different channels of servers and direct messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Firestore:\n",
    "    def __init__(self):\n",
    "        if not firebase_admin._apps:\n",
    "            cred = credentials.Certificate(\"firebase_secret.json\")\n",
    "            firebase_admin.initialize_app(cred)\n",
    "        self.db = firestore.client()\n",
    "        self.collection = None\n",
    "        self.document = {\n",
    "            \"action_agent_message\": [],\n",
    "            \"discord_agent_message\": [],\n",
    "            \"google_agent_message\": [],\n",
    "            \"live_status_agent_message\": [],\n",
    "            \"search_agent_message\": [],\n",
    "            \"user_id\": \"\",\n",
    "            \"user_message\": \"\",\n",
    "            \"time\": \"\",\n",
    "            \"category\": []\n",
    "        }\n",
    "\n",
    "    def update_collection(self, collection):\n",
    "        self.collection = collection\n",
    "    \n",
    "    def update_message(self, property, value):\n",
    "        if property in self.document:\n",
    "            if isinstance(self.document[property], list):\n",
    "                self.document[property].append(f\"{value}\")\n",
    "            else:\n",
    "                self.document[property] = f\"{value}\"\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid property: {property}\")\n",
    "    \n",
    "    async def push_message(self):\n",
    "        if not self.collection:\n",
    "            raise ValueError(\"Collection not set. Use update_collection() first.\")\n",
    "        \n",
    "        self.document[\"user_id\"] = discord_state.get('user_id')\n",
    "        self.document[\"time\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        doc_ref = self.db.collection(self.collection).document()\n",
    "        doc_ref.set(self.document)\n",
    "        \n",
    "        return doc_ref.id  # Return the document ID for reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Global Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firestore = Firestore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "This `Utils` class is designed to manage various utility functions for an AI assistant, particularly focusing on task tracking, animation handling, and search operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Initialization\n",
    "- The `__init__` method initializes task tracking, content management, and connections to the vector store and RaptorRetriever.\n",
    "- It includes error handling and logging for initialization failures.\n",
    "\n",
    "### Animation and Task Management\n",
    "- `start_animation`: Initiates a loading animation using Discord's thinking indicator.\n",
    "- `update_text`: Dynamically updates the displayed text while maintaining a task history.\n",
    "- `stop_animation`: Finalizes the animation and resets the internal state.\n",
    "\n",
    "### Search Result Formatting\n",
    "- `format_search_results`: Converts raw search results into a readable, formatted string.\n",
    "- It handles various metadata fields and formats the content for easy reading.\n",
    "\n",
    "### Web Search Operations\n",
    "- `perform_web_search`: Executes a web search using a provided URL and optional query.\n",
    "- It processes the search results and stores them in the vector database.\n",
    "\n",
    "### Vector Store Operations\n",
    "- `perform_similarity_search`: Conducts a similarity search in the vector store.\n",
    "- It supports category-based filtering and returns formatted results.\n",
    "\n",
    "### MIPS Search\n",
    "- `perform_mips_search`: Performs Maximum Inner Product Search (MIPS) on the vector database.\n",
    "- It supports category-based filtering and returns formatted results.\n",
    "\n",
    "### Database Search\n",
    "- `perform_database_search`: Combines RAPTOR, similarity, and MIPS search methods.\n",
    "- It merges and deduplicates results from different search methods.\n",
    "- Updates cached document IDs and ground sources for future reference.\n",
    "\n",
    "### Result Merging\n",
    "- `merge_search_results`: Combines and deduplicates results from different search methods.\n",
    "- Sorts results based on relevance scores.\n",
    "\n",
    "### Source Management\n",
    "- `update_ground_sources`, `get_ground_sources`, and `clear_ground_sources`: Manage and retrieve a list of unique source URLs.\n",
    "\n",
    "This class is designed for efficient task management, multi-method search operations, and user interaction in an AI assistant context. It provides robust error handling, detailed logging, and flexible search capabilities, making it suitable for complex, interactive AI applications in the ASU Discord bot environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the Utils class with task tracking and logging.\"\"\"\n",
    "        try:\n",
    "            self.tasks = []\n",
    "            self.current_content = \"Understanding your question\"\n",
    "            self.message = None\n",
    "            self.cached_doc_ids = []\n",
    "            self.ground_sources =[]\n",
    "            # self.scann_store = None\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "            self.cached_queries=[]\n",
    "            self.vector_store = asu_store.get_vector_store()\n",
    "            self.raptor_retriever = RaptorRetriever(self.vector_store)\n",
    "            logger.info(\"\\nUtils instance initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize Utils: {e}\")\n",
    "\n",
    "    async def start_animation(self, message):\n",
    "        \"\"\"Start the loading animation using Discord's built-in thinking indicator\"\"\"\n",
    "        try:\n",
    "            self.message = message\n",
    "            logger.info(f\"Animation started for message: {message.id}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to start animation: {e}\")\n",
    "\n",
    "    async def update_text(self, new_content):\n",
    "        \"\"\"Update text while maintaining task history\"\"\"\n",
    "        try:\n",
    "            # Append previous content to tasks\n",
    "            if self.current_content:\n",
    "                self.tasks.append(self.current_content)\n",
    "                logger.debug(f\"Added task to history: {self.current_content}\")\n",
    "\n",
    "            # Update current content\n",
    "            self.current_content = new_content\n",
    "            logger.debug(f\"Updated current content to: {new_content}\")\n",
    "\n",
    "            # Format and display all tasks\n",
    "            display_lines = []\n",
    "\n",
    "            # Display completed tasks\n",
    "            if self.tasks:\n",
    "                display_lines.extend(f\"✓ {task}\" for task in self.tasks)\n",
    "\n",
    "            # Add the current task with a different symbol\n",
    "            display_lines.append(f\"⋯ {new_content}\")\n",
    "            content=\"\\n\".join(display_lines)\n",
    "            # Update the message content\n",
    "            await self.message.edit(content=content)\n",
    "            logger.info(f\"Message updated with {len(display_lines)} tasks\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to update text: {e}\")\n",
    "            # Optionally, you could re-raise the exception or handle it differently\n",
    "\n",
    "    async def stop_animation(self, message=None, final_content=None,View=None):\n",
    "        \"\"\"Stop animation and display final content\"\"\"\n",
    "        try:\n",
    "            # Edit message with final content if provided\n",
    "            if message and final_content:\n",
    "                if View:\n",
    "                    await message.edit(content=final_content,view=View)\n",
    "                await message.edit(content=final_content)\n",
    "                logger.info(f\"Final content set: {final_content}\")\n",
    "\n",
    "            # Reset internal state\n",
    "            self.tasks = []\n",
    "            self.current_content = \"\"\n",
    "            self.message = None\n",
    "            logger.info(\"\\nAnimation stopped and state reset\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error stopping animation: {e}\")\n",
    "\n",
    "    def format_search_results(self, engine_context):\n",
    "        \"\"\"Format search results into a readable string.\"\"\"\n",
    "        if not engine_context:\n",
    "            return \"No search results found.\"\n",
    "        try:\n",
    "            formatted_results = \"\\n\\n\"\n",
    "            if isinstance(engine_context, str):\n",
    "                # If engine_context is already formatted, return it as is\n",
    "                return engine_context\n",
    "\n",
    "            for i, result in enumerate(engine_context, 1):\n",
    "                formatted_results += f\"## Document {i}\\n\"\n",
    "\n",
    "                # Safely access metadata dictionary\n",
    "                metadata = result.get('metadata', {})\n",
    "                if not isinstance(metadata, dict):\n",
    "                    metadata = {}\n",
    "\n",
    "                # Safely get values with defaults\n",
    "                title = metadata.get('title', 'No title')\n",
    "                category = metadata.get('category', 'Uncategorized')\n",
    "                timestamp = metadata.get('timestamp', 'timestamp')\n",
    "                url = metadata.get('url', 'No URL')\n",
    "                content = result.get('content', 'No content available')\n",
    "\n",
    "                # Build formatted string\n",
    "                formatted_results += f\"**Title:** {title}\\n\"\n",
    "                formatted_results += f\"**Category:** {category}\\n\"\n",
    "                formatted_results += f\"**Last Updated:** {timestamp}\\n\"\n",
    "                formatted_results += f\"\"\"**Source:** {url}\\n\"\"\"\n",
    "                formatted_results += \"\\n**Content:**\\n\"\n",
    "                formatted_results += f\"{content}\\n\\n\"\n",
    "                formatted_results += \"---\\n\\n\"\n",
    "\n",
    "            return formatted_results\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error formatting search results: {str(e)}\")\n",
    "            return \"Error formatting search results.\"\n",
    "\n",
    "    async def perform_web_search(self,search_url:str =None,  optional_query : str = None, doc_title : str =None, doc_category : str = None):\n",
    "        try:\n",
    "            # Initial search\n",
    "            logger.info(\"\\nPerforming Web Search\")\n",
    "\n",
    "            documents = await asu_scraper.engine_search(search_url, optional_query)\n",
    "\n",
    "            if not documents:\n",
    "                raise ValueError(\"No documents found matching the query\")\n",
    "                return \"No results found on web\"\n",
    "            \n",
    "            logger.info(documents)\n",
    "            global action_command\n",
    "            logger.info(\"\\nPreprocessing documents...\")\n",
    "            \n",
    "            processed_docs = await asu_data_processor.process_documents(\n",
    "                documents=documents, \n",
    "                search_context=action_command,\n",
    "                title = doc_title, category = doc_category\n",
    "            )\n",
    "\n",
    "            store = asu_store.queue_documents(processed_docs)\n",
    "\n",
    "            results = []\n",
    "            extracted_urls=[]\n",
    "            for doc in processed_docs:\n",
    "                doc_info = {\n",
    "                    'content': doc.page_content,\n",
    "                    'metadata': doc.metadata,\n",
    "                    'timestamp': doc.metadata.get('timestamp'),\n",
    "                    'url': doc.metadata.get('url')\n",
    "                }\n",
    "                sources = doc.metadata.get('url')\n",
    "                extracted_urls.extend(sources)\n",
    "\n",
    "                results.append(doc_info)\n",
    "\n",
    "            self.update_ground_sources(extracted_urls)\n",
    "\n",
    "            results = utils.format_search_results(results)\n",
    "\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in web search: {str(e)}\")\n",
    "            return \"No results found on web\"\n",
    "\n",
    "    async def perform_similarity_search(self, query: str, categories: list):\n",
    "        try:\n",
    "            logger.info(f\"Action Model: Performing similarity search with query: {query}\")\n",
    "            self.vector_store = asu_store.get_vector_store()\n",
    "            if not self.vector_store:\n",
    "                logger.info(\"\\nVector Store not initialized\")\n",
    "                raise ValueError(\"Vector store not properly initialized\")\n",
    "\n",
    "            # Correct filter construction using Qdrant's Filter class\n",
    "            filter_conditions = None\n",
    "            if categories and len(categories) > 0:\n",
    "                \n",
    "\n",
    "                filter_conditions = Filter(\n",
    "                    must=[\n",
    "                        FieldCondition(\n",
    "                            key=\"metadata.category\", \n",
    "                            match=MatchAny(any=categories)\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            # Perform similarity search with optional filtering\n",
    "            results = self.vector_store.similarity_search(\n",
    "                query, \n",
    "                filter=filter_conditions\n",
    "            )\n",
    "\n",
    "            # Check if results are empty\n",
    "            if not results:\n",
    "                logger.info(\"\\nNo documents found in vector store\")\n",
    "                return None\n",
    "\n",
    "            documents = []\n",
    "            for doc in results:\n",
    "                doc_info = {\n",
    "                    'content': doc.page_content,\n",
    "                    'metadata': doc.metadata,\n",
    "                    'timestamp': doc.metadata.get('timestamp'),\n",
    "                    'url': doc.metadata.get('url'),\n",
    "                    'category': doc.metadata.get('category')\n",
    "                }\n",
    "                documents.append(doc_info)\n",
    "\n",
    "            logger.info(f\"Retrieved {len(documents)} documents from vector store\")\n",
    "            return documents\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during similarity search: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    async def perform_mips_search(self, query: str, categories: list):\n",
    "        try:\n",
    "            logger.info(f\"Action Model: Performing MIPS search with query: {query}\")\n",
    "            query_vector = self.vector_store.embedding_model.embed_query(query)\n",
    "            \n",
    "            filter_conditions = None\n",
    "            if categories and len(categories) > 0:\n",
    "                filter_conditions = models.Filter(\n",
    "                    must=[\n",
    "                        models.FieldCondition(\n",
    "                            key=\"metadata.category\",\n",
    "                            match=models.MatchAny(any=categories)\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            \n",
    "            results = self.vector_store.mips_search(query_vector, filter=filter_conditions)\n",
    "            \n",
    "            documents = []\n",
    "            for doc in results:\n",
    "                doc_info = {\n",
    "                    'content': doc['payload']['page_content'],\n",
    "                    'metadata': doc['payload']['metadata'],\n",
    "                    'score': doc['score']\n",
    "                }\n",
    "                documents.append(doc_info)\n",
    "            \n",
    "            logger.info(f\"Retrieved {len(documents)} documents from MIPS search\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during MIPS search: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def merge_search_results(self, raptor_results, similarity_results, mips_results):\n",
    "        combined_results = raptor_results + similarity_results + mips_results\n",
    "        \n",
    "        deduplicated_results = []\n",
    "        seen_urls = set()\n",
    "        \n",
    "        for result in combined_results:\n",
    "            url = result.get('metadata', {}).get('url')\n",
    "            if url not in seen_urls:\n",
    "                seen_urls.add(url)\n",
    "                deduplicated_results.append(result)\n",
    "        \n",
    "        # Sort by relevance score (assuming higher is better)\n",
    "        sorted_results = sorted(deduplicated_results, key=lambda x: x.get('score', 0), reverse=True)\n",
    "        \n",
    "        return sorted_results[:10]  # Return top 10 unique results\n",
    "\n",
    "    async def perform_database_search(self, query: str, categories: list):\n",
    "        self.cached_queries.append(query)\n",
    "        \n",
    "        # Perform RAPTOR search\n",
    "        raptor_results = await self.raptor_retriever.retrieve(query, top_k=5)\n",
    "        \n",
    "        # Perform similarity search\n",
    "        similarity_results = await self.perform_similarity_search(query, categories)\n",
    "        \n",
    "        # Perform MIPS search\n",
    "        mips_results = await self.perform_mips_search(query, categories)\n",
    "        query_embedding = self.vector_store.embedding_model.embed_query(query)\n",
    "\n",
    "\n",
    "\n",
    "        # Combine and deduplicate results\n",
    "        combined_results = self.merge_search_results(raptor_results, similarity_results, mips_results)\n",
    "        \n",
    "        # Process results\n",
    "        extracted_urls = []\n",
    "        self.cached_doc_ids.clear()\n",
    "        \n",
    "        for doc in combined_results[:5]:\n",
    "            doc_id = doc.get('metadata', {}).get('id')\n",
    "            if doc_id:\n",
    "                self.cached_doc_ids.append(doc_id)\n",
    "            sources = doc.get('metadata', {}).get('url', [])\n",
    "            extracted_urls.extend(sources)\n",
    "        \n",
    "        self.update_ground_sources(extracted_urls)\n",
    "        formatted_context = self.format_search_results(combined_results[:5])\n",
    "        return formatted_context\n",
    "\n",
    "    def update_ground_sources(self,extracted_urls:[]):\n",
    "        self.ground_sources.extend(extracted_urls)\n",
    "        self.ground_sources = list(set(self.ground_sources))\n",
    "    \n",
    "    def get_ground_sources(self):\n",
    "        return self.ground_sources\n",
    "    \n",
    "    def clear_ground_sources(self):\n",
    "        self.ground_sources = []\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = Utils()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessor \n",
    "\n",
    "This `DataPreprocessor` is designed for efficient, context-aware document processing, making it ideal for RAG (Retrieval-Augmented Generation) applications. It ensures clean, structured text output with comprehensive metadata, enhancing downstream NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Initialization\n",
    "- The `__init__` method sets up the preprocessor with configurable parameters for text splitting and retry mechanisms.\n",
    "- It initializes NLTK resources for advanced text processing.\n",
    "- Regular expressions are compiled for efficient text cleaning.\n",
    "\n",
    "### Document Processing\n",
    "- The `process_documents` method is the core function for handling multiple documents.\n",
    "- It implements a retry mechanism to ensure robust processing.\n",
    "- The method consolidates documents, refines content, and splits them into manageable chunks.\n",
    "\n",
    "### Text Cleaning\n",
    "- `clean_and_structure_text` performs comprehensive text cleaning:\n",
    "  - Removes HTML tags and links\n",
    "  - Converts text to ASCII and lowercase\n",
    "  - Replaces special characters and normalizes whitespace\n",
    "  - Applies tokenization and lemmatization for advanced text normalization\n",
    "\n",
    "### Content Refinement\n",
    "- `_refine_content` attempts to improve document content using an AI agent.\n",
    "- It handles potential errors during the refinement process.\n",
    "\n",
    "### Document Creation and Splitting\n",
    "- `_create_processed_document` generates a document with rich metadata.\n",
    "- `_split_and_annotate_document` divides the document into chunks and adds unique identifiers.\n",
    "\n",
    "### Error Handling\n",
    "- The class implements a fallback mechanism to handle processing failures.\n",
    "- `_generate_fallback_document` creates a basic document when all processing attempts fail.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, \n",
    "                 chunk_size: int = 1024, \n",
    "                 chunk_overlap: int = 200, \n",
    "                 max_processing_attempts: int = 3):\n",
    "        \"\"\"Initialize DataPreprocessor with configurable text splitting and retry mechanism.\"\"\"\n",
    "        self.max_processing_attempts = max_processing_attempts\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "        self.doc_title = None\n",
    "        self.doc_category = None\n",
    "        nltk.download('punkt_tab', quiet=True)\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.WHITESPACE_PATTERN = re.compile(r'\\s+')\n",
    "        self.LINK_PATTERN = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        self.SPECIAL_CHAR_PATTERN = re.compile(r'[^a-zA-Z0-9\\s.,!?;:()\\-\"\\'$]')\n",
    "\n",
    "\n",
    "\n",
    "        logger.info(f\"DataPreprocessor initialized with chunk_size={chunk_size}, chunk_overlap={chunk_overlap}\")\n",
    "\n",
    "    async def process_documents(self, \n",
    "                                documents: List[Dict[str, str]], \n",
    "                                search_context: str, \n",
    "                                title: str = None, \n",
    "                                category: str = None) -> List[Document]:\n",
    "        \"\"\"Process documents with advanced error handling and multiple retry mechanism.\"\"\"\n",
    "        await utils.update_text(\"Understanding Results...\")\n",
    "        logger.info(f\"Processing documents with title={title} category={category}\")\n",
    "        self.doc_title = title\n",
    "        self.doc_category = category\n",
    "\n",
    "        for attempt in range(self.max_processing_attempts):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                logger.info(f\"Starting document processing for {len(documents)} documents\")\n",
    "                try:\n",
    "                    consolidated_text = await self._consolidate_documents(documents)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Document consolidation failed: {str(e)}\")\n",
    "                    raise\n",
    "                if not self.doc_title:\n",
    "                    try:\n",
    "                        self.doc_title = await self._refine_content(search_context, consolidated_text)\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Title refinement failed: {str(e)}\")\n",
    "                        raise\n",
    "                try:\n",
    "                    document = self._create_processed_document(consolidated_text, documents)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Document creation failed: {str(e)}\")\n",
    "                    raise\n",
    "                try:\n",
    "                    processed_documents = self._split_and_annotate_document(document)\n",
    "                except  Exception as e:\n",
    "                    logger.error(f\"Document splitting failed: {str(e)}\")\n",
    "                    raise\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                logger.info(f\"Document processing completed in {processing_time:.2f} seconds. \"\n",
    "                            f\"Generated {len(processed_documents)} document chunks.\")\n",
    "\n",
    "                return processed_documents\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Document processing attempt {attempt + 1} failed: {str(e)}\")\n",
    "                if attempt == self.max_processing_attempts - 1:\n",
    "                    return await self._generate_fallback_document(documents, e)\n",
    "\n",
    "    def clean_and_structure_text(self, text: str) -> str:\n",
    "        \"\"\"Enhanced text cleaning for RAG applications.\"\"\"\n",
    "        # Remove HTML tags\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "        # Remove links\n",
    "        text = self.LINK_PATTERN.sub('', text)\n",
    "\n",
    "        # Convert to ASCII and lowercase\n",
    "        text = unidecode(text.lower())\n",
    "\n",
    "        # Replace $ with USD\n",
    "        text = text.replace('$', 'USD ')\n",
    "\n",
    "        # Remove special characters while preserving important punctuation\n",
    "        text = self.SPECIAL_CHAR_PATTERN.sub(' ', text)\n",
    "\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Lemmatize\n",
    "        tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "        # Rejoin tokens and normalize whitespace\n",
    "        text = ' '.join(tokens)\n",
    "        text = self.WHITESPACE_PATTERN.sub(' ', text).strip()\n",
    "\n",
    "        return text\n",
    "\n",
    "    async def _consolidate_documents(self, documents: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"Consolidate and clean documents into a single text corpus.\"\"\"\n",
    "        return '\\n\\n'.join([\n",
    "            self.clean_and_structure_text(doc['content']) \n",
    "            for doc in documents\n",
    "        ]).strip()\n",
    "\n",
    "    async def _refine_content(self, search_context: str, consolidated_text: str) -> Optional[str]:\n",
    "        \"\"\"Attempt to refine document content with error handling.\"\"\"\n",
    "        try:\n",
    "            return await asu_data_agent.refine(search_context, consolidated_text)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Content refinement agent failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _create_processed_document(self, \n",
    "                                   consolidated_text: str, \n",
    "                                   documents: List[Dict[str, str]]) -> Document:\n",
    "        \"\"\"Create a processed document with comprehensive metadata.\"\"\"\n",
    "        return Document(\n",
    "            page_content=consolidated_text,\n",
    "            metadata={\n",
    "                'title': self.doc_title or 'Untitled',\n",
    "                'category': self.doc_category or \"google_results\",\n",
    "                'url': [doc['metadata'][\"url\"] for doc in documents[:5]],\n",
    "                'timestamp': datetime.now(),\n",
    "                'total_source_documents': len(documents),\n",
    "                'cluster': None\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _split_and_annotate_document(self, document: Document) -> List[Document]:\n",
    "        \"\"\"Split document into chunks and annotate with metadata.\"\"\"\n",
    "        splits = self.text_splitter.split_documents([document])\n",
    "\n",
    "        for i, split in enumerate(splits):\n",
    "            split.metadata.update({\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'chunk_id': str(uuid.uuid4()),\n",
    "                'chunk_index': i,\n",
    "                'total_chunks': len(splits)\n",
    "            })\n",
    "\n",
    "        return splits\n",
    "\n",
    "    async def _generate_fallback_document(self, \n",
    "                                          documents: List[Dict[str, str]], \n",
    "                                          error: Exception) -> List[Document]:\n",
    "        \"\"\"Generate a fallback document when all processing attempts fail.\"\"\"\n",
    "        fallback_doc = Document(\n",
    "            page_content=' '.join([doc['content'] for doc in documents]),\n",
    "            metadata={\n",
    "                'title': self.doc_title or 'Fallback Document',\n",
    "                'category': self.doc_category,\n",
    "                'url': [doc['metadata'][\"url\"] for doc in documents],\n",
    "                'timestamp': datetime.now(),\n",
    "                'error_message': str(error),\n",
    "                'total_source_documents': len(documents)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return [fallback_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_data_processor = DataPreprocessor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraper\n",
    "\n",
    "This `ASUWebScraper` is designed to efficiently retrieve and process information from various ASU-related web sources, providing a comprehensive data collection tool for the ASU Discord Research Assistant Bot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "- The `__init__` method sets up the scraper with various configurations:\n",
    "  - Initializes a Discord client for potential integration\n",
    "  - Sets up Chrome options for headless browsing\n",
    "  - Configures headers for web requests\n",
    "  - Initializes containers for visited URLs and scraped content\n",
    "\n",
    "### Web Interaction\n",
    "- Uses Selenium WebDriver for dynamic web page interactions\n",
    "- Implements a `__login__` method for authenticating with ASU's Handshake platform\n",
    "- Handles various types of web elements including popups and cookies\n",
    "\n",
    "### Content Extraction\n",
    "- The `scrape_content` method is the core function for extracting information from web pages\n",
    "- Supports both Selenium-based scraping and Jina AI-powered content extraction\n",
    "- Implements retry mechanisms for robust scraping\n",
    "\n",
    "### Specialized Scraping\n",
    "- Contains methods for scraping specific ASU resources:\n",
    "  - Course catalog information\n",
    "  - Library resources\n",
    "  - Job postings from Handshake\n",
    "  - Shuttle status information\n",
    "\n",
    "### Search Functionality\n",
    "- The `engine_search` method performs searches across various ASU platforms\n",
    "- Handles different types of search results (Google, ASU Campus Labs, social media)\n",
    "- Implements URL deduplication to avoid redundant scraping\n",
    "\n",
    "### Error Handling\n",
    "- Robust error handling throughout the class\n",
    "- Implements logging for debugging and monitoring scraping processes\n",
    "\n",
    "### Customization\n",
    "- Allows for customization of scraping behavior through optional parameters\n",
    "- Supports different scraping strategies based on the target website\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASUWebScraper:\n",
    "    def __init__(self):\n",
    "        self.discord_client = discord_state.get('discord_client')\n",
    "        self.visited_urls = set()\n",
    "        self.text_content = []\n",
    "        self.optionalLinks = []\n",
    "        self.logged_in_driver= None\n",
    "        self.driver= None\n",
    "        self.chrome_options = Options()\n",
    "        self.chrome_options.add_argument('--headless')  \n",
    "        self.chrome_options.add_argument('--no-sandbox')\n",
    "        self.chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        self.chrome_options.add_argument('--disable-gpu')\n",
    "        self.chrome_options.add_argument('--window-size=1920,1080')\n",
    "        self.chrome_options.add_argument('--ignore-certificate-errors')\n",
    "        self.chrome_options.add_argument('--disable-extensions')\n",
    "        self.chrome_options.add_argument('--no-first-run')\n",
    "        \n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1'\n",
    "        }\n",
    "        self.popup = False\n",
    "    \n",
    "    async def __login__(self, username, password):\n",
    "        try:\n",
    "            # Initialize WebDriver with configured Chrome options\n",
    "            driver = webdriver.Chrome(options=self.chrome_options)\n",
    "            \n",
    "            # Navigate to Handshake login page\n",
    "            driver.get(\"https://asu.joinhandshake.com/login?ref=app-domain\")\n",
    "            \n",
    "            # Wait for page to load\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            \n",
    "            # Find and click \"Sign in with your email address\" button\n",
    "            email_signin_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//a[@data-bind='click: toggle']\"))\n",
    "            )\n",
    "            email_signin_button.click()\n",
    "            \n",
    "            # Enter email address\n",
    "            email_input = wait.until(\n",
    "                EC.presence_of_element_located((By.ID, \"non-sso-email-address\"))\n",
    "            )\n",
    "            email_input.send_keys(username)\n",
    "            \n",
    "            # Click \"Next\" button\n",
    "            next_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[@type='submit' and contains(@class, 'button')]\"))\n",
    "            )\n",
    "            next_button.click()\n",
    "            \n",
    "            # Click \"Or log in using your Handshake credentials\"\n",
    "            alternate_login = wait.until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"alternate-login-link\"))\n",
    "            )\n",
    "            alternate_login.click()\n",
    "            \n",
    "            # Enter password\n",
    "            password_input = wait.until(\n",
    "                EC.presence_of_element_located((By.ID, \"password\"))\n",
    "            )\n",
    "            password_input.send_keys(password)\n",
    "            \n",
    "            # Submit login\n",
    "            submit_button = wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='submit' and contains(@class, 'button default-focus')]\"))\n",
    "            )\n",
    "            submit_button.click()\n",
    "            \n",
    "            \n",
    "            # Store the logged-in driver state\n",
    "            self.logged_in_driver = driver\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Login failed: {str(e)}\")\n",
    "            return False\n",
    "        \n",
    "    def handle_feedback_popup(self,driver):\n",
    "                if self.popup:\n",
    "                    \n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        logger.info(\"\\nHandling feedback popup\")\n",
    "                        # Wait for the popup to be present\n",
    "                        popup = WebDriverWait(driver, 5).until(\n",
    "                            EC.presence_of_element_located((By.CLASS_NAME, \"fsrDeclineButton\"))\n",
    "                        )\n",
    "                        \n",
    "                        # Click the \"No thanks\" button\n",
    "                        popup.click()\n",
    "                        logger.info(\"\\nFeedback popup clicked\")\n",
    "                        # Optional: Wait for popup to disappear\n",
    "                        WebDriverWait(driver, 5).until(\n",
    "                            EC.invisibility_of_element_located((By.ID, \"fsrFullScreenContainer\"))\n",
    "                        )\n",
    "                        \n",
    "                        self.popup = True\n",
    "                    except Exception as e:\n",
    "                        # If popup doesn't appear or can't be clicked, log or handle silently\n",
    "\n",
    "                        pass\n",
    "    \n",
    "    def handle_cookie(self,driver):\n",
    "                if self.popup:\n",
    "                    \n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        logger.info(\"\\nHandling feedback popup\")\n",
    "                        cookie_button = WebDriverWait(driver, 10).until(\n",
    "                            EC.element_to_be_clickable((By.ID, \"rcc-confirm-button\"))\n",
    "                        )\n",
    "                        cookie_button.click()\n",
    "                        logger.info(\"\\nSuccessfully clciked on cookie button\")\n",
    "                    except:\n",
    "                        pass\n",
    "    \n",
    "    async def scrape_content(self, url: str, query_type: str = None, max_retries: int = 3, selenium :bool = False, optional_query:str=None) -> bool:\n",
    "        \"\"\"Scrape content using Jina.ai\"\"\"\n",
    "        \n",
    "        logger.info(f\"Scraping url : {url} \")\n",
    "        logger.info(f\"query_type : {query_type} \")\n",
    "        logger.info(f\"max_retries : {max_retries} \")\n",
    "        logger.info(f\"selenium required : {selenium} \")\n",
    "        logger.info(f\"optional query : {optional_query} \")\n",
    "        \n",
    "        await utils.update_text(\"Understanding Results...\")\n",
    "\n",
    "        if isinstance(url, dict):\n",
    "            url = url.get('url', '')\n",
    "    \n",
    "        # Ensure url is a string and not empty\n",
    "        if not isinstance(url, str) or not url:\n",
    "            logger.error(f\"Invalid URL: {url}\")\n",
    "            return False\n",
    "        if url in self.visited_urls:\n",
    "            return False\n",
    "        \n",
    "        self.visited_urls.add(url)\n",
    "        \n",
    "        if not selenium:\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    loader = WebBaseLoader(url)\n",
    "                    documents = loader.load()\n",
    "                    \n",
    "                    if documents and documents[0].page_content and len(documents[0].page_content.strip()) > 50 and not \"requires javascript to be enabled\" in documents[0].page_content:\n",
    "                        self.text_content.append({\n",
    "                                'content': documents[0].page_content,\n",
    "                                'metadata': {\n",
    "                                    'url': url,\n",
    "                                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                                    'title': documents[0].metadata.get('title', ''),\n",
    "                                    'description': documents[0].metadata.get('description', ''),\n",
    "                                }\n",
    "                            })\n",
    "                        return True\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error fetching content from {url}: {str(e)}\")\n",
    "                    await asyncio.sleep(3) \n",
    "                    continue  \n",
    "                else:\n",
    "                    jina_url = f\"https://r.jina.ai/{url}\"\n",
    "                    response = requests.get(jina_url, headers=self.headers, timeout=30)\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    text = response.text\n",
    "                    if \"LOADING\" in text :\n",
    "                        logger.warning(f\"LOADING response detected for {url}. Retry attempt {attempt + 1}\")\n",
    "                        await asyncio.sleep(3)  # Wait before retrying\n",
    "                        continue\n",
    "                    \n",
    "                    if text and len(text.strip()) > 50:\n",
    "                        self.text_content.append({\n",
    "                            'content': text,\n",
    "                            'metadata': {\n",
    "                                'url': url,\n",
    "                                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                            }\n",
    "                        })\n",
    "                        \n",
    "                        logger.info(self.text_content[-1])\n",
    "                        return True\n",
    "                    \n",
    "            return False\n",
    "        \n",
    "        elif 'postings' in url:\n",
    "\n",
    "                \n",
    "            # Navigate to Handshake job postings\n",
    "            self.logged_in_driver.get(url)\n",
    "            \n",
    "            \n",
    "            # Wait for page to load\n",
    "            wait = WebDriverWait(self.logged_in_driver, 10)\n",
    "            \n",
    "            # Parse optional query parameters\n",
    "            if optional_query:\n",
    "                query_params = parse_qs(optional_query)\n",
    "                \n",
    "                \n",
    "                \n",
    "                driver = self.logged_in_driver\n",
    "                \n",
    "                # Search Bar Query\n",
    "                if 'search_bar_query' in query_params:\n",
    "                    search_input = wait.until(\n",
    "                        EC.presence_of_element_located((By.XPATH, \"//input[@role='combobox']\"))\n",
    "                    )\n",
    "                    search_input.send_keys(query_params['search_bar_query'][0])\n",
    "                    logger.info(\"\\nSuccessfully entered search_bar_query\")\n",
    "                \n",
    "                \n",
    "                if 'job_location' in query_params:\n",
    "                    location_button = wait.until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'style__pill___3uHDM') and .//span[text()='Location']]\"))\n",
    "                    )\n",
    "                    location_button.click()\n",
    "\n",
    "                    location_input = wait.until(\n",
    "                        EC.presence_of_element_located((By.ID, \"locations-filter\"))\n",
    "                    )\n",
    "                    \n",
    "                    # Remove list brackets and use the first element directly\n",
    "                    job_location = query_params['job_location'][0]\n",
    "                    \n",
    "                    location_input.clear()\n",
    "                    location_input.send_keys(job_location)\n",
    "                    logger.info(\"\\n Successfully entered job_location\")\n",
    "\n",
    "                    try:\n",
    "                        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"mapbox-autocomplete-results\")))\n",
    "                        time.sleep(1)\n",
    "\n",
    "                        first_location = wait.until(\n",
    "                            EC.element_to_be_clickable((\n",
    "                            By.XPATH, \n",
    "                            f\"//div[contains(@class, 'mapbox-autocomplete-results')]//label[contains(text(), '{job_location}')]\"\n",
    "                            )))\n",
    "                        \n",
    "                        first_location.click()\n",
    "                        \n",
    "                        logger.info(f\"Selected location: {job_location}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error job location: {e}\")\n",
    "\n",
    "                all_filters_button = wait.until(\n",
    "                    EC.element_to_be_clickable((\n",
    "                        By.XPATH, \n",
    "                        \"//button[contains(@class, 'style__pill___3uHDM') and .//span[text()='All filters']]\"\n",
    "                    ))\n",
    "                )\n",
    "                all_filters_button.click()\n",
    "                \n",
    "                logger.info(\"\\nClicked on all filters\")\n",
    "                                    \n",
    "                \n",
    "                if 'job_type' in query_params:\n",
    "                    # Get the specific job type from query parameters\n",
    "                    job_type = query_params['job_type'][0]\n",
    "                    \n",
    "                    # Function to force click using JavaScript with multiple attempts\n",
    "                    def force_click_element(driver, element, max_attempts=3):\n",
    "                        for attempt in range(max_attempts):\n",
    "                            logger.info(\"\\nAttempting to force click\")\n",
    "                            try:\n",
    "                                # Try different click methods\n",
    "                                driver.execute_script(\"arguments[0].click();\", element)\n",
    "                                time.sleep(0.5)  # Short pause to allow for potential page changes\n",
    "                                return True\n",
    "                            except Exception:\n",
    "                                # Try alternative click methods\n",
    "                                try:\n",
    "                                    element.click()\n",
    "                                except Exception:\n",
    "                                    # Last resort: move and click\n",
    "                                    try:\n",
    "                                        ActionChains(driver).move_to_element(element).click().perform()\n",
    "                                    except Exception:\n",
    "                                        continue\n",
    "                        return False\n",
    "                    \n",
    "                    # Check if the job type is in the first level of buttons (Full-Time, Part-Time)\n",
    "                    standard_job_types = ['Full-Time', 'Part-Time']\n",
    "                    \n",
    "                    if job_type in standard_job_types:\n",
    "                        # Direct selection for standard job types\n",
    "                        try:\n",
    "                            job_type_button = wait.until(\n",
    "                                EC.presence_of_element_located((\n",
    "                                    By.XPATH,\n",
    "                                    f\"//button[contains(@class, 'style__pill___3uHDM') and .//div[@data-name='{job_type}' and @tabindex='-1']]\"\n",
    "                                ))\n",
    "                            )\n",
    "                            force_click_element(driver, job_type_button)\n",
    "                            logger.info(\"\\nSelect job type\")\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    else:\n",
    "                        # For nested job types, click More button first\n",
    "                        try:\n",
    "                            more_button = wait.until(\n",
    "                                EC.presence_of_element_located((\n",
    "                                    By.XPATH, \n",
    "                                    \"//button[contains(@class, 'style__pill___') and contains(text(), '+ More')]\"\n",
    "                                ))\n",
    "                            )\n",
    "                            force_click_element(driver, more_button)\n",
    "                            logger.info(\"\\nClicked more button\")\n",
    "                            \n",
    "                            # Wait and force click the specific job type button from nested options\n",
    "                            job_type_button = wait.until(\n",
    "                                EC.presence_of_element_located((\n",
    "                                    By.XPATH,\n",
    "                                    f\"//button[contains(@class, 'style__pill___3uHDM') and .//div[@data-name='{job_type}' and @tabindex='-1']]\"\n",
    "                                ))\n",
    "                            )\n",
    "                            force_click_element(driver, job_type_button)\n",
    "                            logger.info(\"\\nSelect Job type\")\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Wait for the Show results button to be clickable\n",
    "                show_results_button = wait.until(\n",
    "                    EC.element_to_be_clickable((\n",
    "                        By.CLASS_NAME, \n",
    "                        \"style__clickable___3a6Y8\"\n",
    "                    ))\n",
    "                )\n",
    "\n",
    "                # Optional: Add a small delay before clicking to ensure page is ready\n",
    "                time.sleep(4)\n",
    "\n",
    "                # Force click the Show results button using JavaScript\n",
    "                driver.execute_script(\"arguments[0].click();\", show_results_button)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                try:\n",
    "                    # Wait for job cards to be present using data-hook\n",
    "                    job_cards = wait.until(\n",
    "                        EC.presence_of_all_elements_located(\n",
    "                            (By.CSS_SELECTOR, \"[data-hook='jobs-card']\")\n",
    "                        )\n",
    "                    )\n",
    "                    text_content = []  # Limit to top 3 jobs\n",
    "                    \n",
    "                    for job_card in job_cards[:5]:\n",
    "                        full_job_link = job_card.get_attribute('href')\n",
    "\n",
    "                        driver.execute_script(\"arguments[0].click();\", job_card)\n",
    "                        logger.info(\"\\nClicked Job Card\")\n",
    "                        \n",
    "                        # Wait for preview panel to load using data-hook\n",
    "                        wait.until(\n",
    "                            EC.presence_of_element_located(\n",
    "                                (By.CSS_SELECTOR, \"[data-hook='details-pane']\")\n",
    "                            )\n",
    "                        )\n",
    "                        \n",
    "                        # Find 'More' button using a more robust selector\n",
    "                        more_button = wait.until(\n",
    "                            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.view-more-button\"))\n",
    "                        )\n",
    "                        driver.execute_script(\"arguments[0].click();\", more_button)\n",
    "                        logger.info(\"\\nClicked 'More' button\")\n",
    "\n",
    "                        \n",
    "                        time.sleep(1)\n",
    "                        h = html2text.HTML2Text()\n",
    "                        time.sleep(2)\n",
    "                        \n",
    "                        job_preview_html = driver.find_element(By.CLASS_NAME, \"style__details-padding___Y_KHb\")\n",
    "                        \n",
    "                        soup = BeautifulSoup(job_preview_html.get_attribute('outerHTML'), 'html.parser')\n",
    "    \n",
    "                        # Find and remove the specific div with the class\n",
    "                        unwanted_div = soup.find('div', class_='sc-gwVtdH fXuOWU')\n",
    "                        if unwanted_div:\n",
    "                            unwanted_div.decompose()\n",
    "                        \n",
    "                        unwanted_div = soup.find('div', class_='sc-dkdNSM eNTbTl')\n",
    "                        if unwanted_div:\n",
    "                            unwanted_div.decompose()\n",
    "                        unwanted_div = soup.find('div', class_='sc-jEYHeb hSVHZy')\n",
    "                        if unwanted_div:\n",
    "                            unwanted_div.decompose()\n",
    "                        unwanted_div = soup.find('div', class_='sc-VJPgA bRBKUF')\n",
    "                        if unwanted_div:\n",
    "                            unwanted_div.decompose()\n",
    "                        \n",
    "\n",
    "                        markdown_content = h.handle(str(soup))\n",
    "                        \n",
    "                        # remove image links\n",
    "                        markdown_content = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', markdown_content)\n",
    "    \n",
    "                        # Remove hyperlinks\n",
    "                        markdown_content = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', markdown_content)\n",
    "\n",
    "                        markdown_content = markdown_content.replace('\\n',' ')\n",
    "                        \n",
    "                        markdown_content = markdown_content.replace('[',' ')\n",
    "                        \n",
    "                        markdown_content = markdown_content.replace(']',' ')\n",
    "                        \n",
    "                        markdown_content = markdown_content.replace('/',' ')\n",
    "                        \n",
    "                        self.text_content.append({\n",
    "                            'content': markdown_content,\n",
    "                            'metadata': {\n",
    "                                'url': full_job_link,\n",
    "                                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                            }\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                        logger.error(f\"Error html to makrdown conversion :  {e}\")\n",
    "            \n",
    "            return True\n",
    "        \n",
    "        elif 'catalog.apps.asu.edu' in url:\n",
    "            driver = self.driver\n",
    "            driver.get(url)\n",
    "            \n",
    "            self.handle_cookie(driver)\n",
    "            course_elements = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, \"class-accordion\"))\n",
    "            )\n",
    "\n",
    "            detailed_courses = []\n",
    "            \n",
    "            for course in course_elements[:7]:\n",
    "                try:\n",
    "                    course_title_element = course.find_element(By.CSS_SELECTOR, \".course .bold-hyperlink\")\n",
    "                    course_title = course_title_element.text\n",
    "                    \n",
    "                    # Use JavaScript click to handle potential interception\n",
    "                    driver.execute_script(\"arguments[0].click();\", course_title_element)\n",
    "                    logger.info(\"\\nSuccessfully clicked on the course\")\n",
    "\n",
    "                    # Wait for dropdown to load\n",
    "                    details_element = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.ID, \"class-details\"))\n",
    "                    )\n",
    "                    \n",
    "                    # Extract additional details\n",
    "                    course_info = {\n",
    "                        'title': course_title,\n",
    "                        'description': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Course Description')]/following-sibling::p\").text,\n",
    "                        'enrollment_requirements': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Enrollment Requirements')]/following-sibling::p\").text,\n",
    "                        'location': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Location')]/following-sibling::p\").text,\n",
    "                        'number': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Number')]/following-sibling::p\").text,\n",
    "                        'units': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Units')]/following-sibling::p\").text,\n",
    "                        'dates': details_element.find_element(By.CLASS_NAME, \"text-nowrap\").text,\n",
    "                        'offered_by': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Offered By')]/following-sibling::p\").text,\n",
    "                        'repeatable_for_credit': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Repeatable for credit')]/following-sibling::p\").text,\n",
    "                        'component': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Component')]/following-sibling::p\").text,\n",
    "                        'last_day_to_enroll': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Last day to enroll')]/following-sibling::p\").text,\n",
    "                        'drop_deadline': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Drop deadline')]/following-sibling::p\").text,\n",
    "                        'course_withdrawal_deadline': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Course withdrawal deadline')]/following-sibling::p\").text,\n",
    "                        'consent': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Consent')]/following-sibling::p\").text,\n",
    "                        'course_notes': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Course Notes')]/following-sibling::p\").text,\n",
    "                        'fees': details_element.find_element(By.XPATH, \".//h5[contains(text(), 'Fees')]/following-sibling::p\").text\n",
    "                    }\n",
    "                    \n",
    "                    # Extract reserved seats information\n",
    "                    try:\n",
    "                        reserved_seats_table = details_element.find_element(By.CLASS_NAME, \"reserved-seats\")\n",
    "                        reserved_groups = []\n",
    "                        rows = reserved_seats_table.find_elements(By.TAG_NAME, \"tr\")[1:-1]  # Skip header and last row\n",
    "                        for row in rows:\n",
    "                            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                            reserved_groups.append({\n",
    "                                'group': cols[0].text,\n",
    "                                'available_seats': cols[1].text,\n",
    "                                'students_enrolled': cols[2].text,\n",
    "                                'total_seats_reserved': cols[3].text,\n",
    "                                'reserved_until': cols[4].text\n",
    "                            })\n",
    "                        course_info['reserved_seats'] = reserved_groups\n",
    "                    except:\n",
    "                        course_info['reserved_seats'] = []\n",
    "                    \n",
    "                    detailed_courses.append(course_info)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error processing course {e}\")\n",
    "\n",
    "                    \n",
    "                formatted_courses = []\n",
    "                for course in detailed_courses:\n",
    "                    course_string = f\"Title: {course['title']}\\n\"\n",
    "                    course_string += f\"Description: {course['description']}\\n\"\n",
    "                    course_string += f\"Enrollment Requirements: {course['enrollment_requirements']}\\n\"\n",
    "                    course_string += f\"Instructor: {course['instructor']}\\n\"\n",
    "                    course_string += f\"Location: {course['location']}\\n\"\n",
    "                    course_string += f\"Course Number: {course['number']}\\n\"\n",
    "                    course_string += f\"Units: {course['units']}\\n\"\n",
    "                    course_string += f\"Dates: {course['dates']}\\n\"\n",
    "                    course_string += f\"Offered By: {course['offered_by']}\\n\"\n",
    "                    course_string += f\"Repeatable for Credit: {course['repeatable_for_credit']}\\n\"\n",
    "                    course_string += f\"Component: {course['component']}\\n\"\n",
    "                    course_string += f\"Last Day to Enroll: {course['last_day_to_enroll']}\\n\"\n",
    "                    course_string += f\"Drop Deadline: {course['drop_deadline']}\\n\"\n",
    "                    course_string += f\"Course Withdrawal Deadline: {course['course_withdrawal_deadline']}\\n\"\n",
    "                    course_string += f\"Consent: {course['consent']}\\n\"\n",
    "                    course_string += f\"Course Notes: {course['course_notes']}\\n\"\n",
    "                    course_string += f\"Fees: {course['fees']}\\n\"\n",
    "\n",
    "                    # Add reserved seats information\n",
    "                    if course.get('reserved_seats'):\n",
    "                        course_string += \"Reserved Seats:\\n\"\n",
    "                        for group in course['reserved_seats']:\n",
    "                            course_string += f\"- Group: {group['group']}\\n\"\n",
    "                            course_string += f\"  Available Seats: {group['available_seats']}\\n\"\n",
    "                            course_string += f\"  Students Enrolled: {group['students_enrolled']}\\n\"\n",
    "                            course_string += f\"  Total Reserved Seats: {group['total_seats_reserved']}\\n\"\n",
    "                            course_string += f\"  Reserved Until: {group['reserved_until']}\\n\"\n",
    "                    self.text_content.append({\n",
    "                            'content': course_string,\n",
    "                            'metadata': {\n",
    "                                'url': url,\n",
    "                                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                            }\n",
    "                        })\n",
    "                    logger.info(f\"Appended {self.text_content[-1]}\")\n",
    "                    formatted_courses.append(course_string)\n",
    "        \n",
    "        elif 'search.lib.asu.edu' in url:\n",
    "            self.driver.get(url)\n",
    "            time.sleep(1) \n",
    "            book_results=[]\n",
    "            self.handle_feedback_popup(self.driver)\n",
    "            try:\n",
    "                # Find and click on the first book title link\n",
    "                first_book_link = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"h3.item-title a\"))\n",
    "                )\n",
    "                first_book_link.click()\n",
    "                logger.info(\"\\nBook Title Clicked\")\n",
    "            \n",
    "                try:\n",
    "                    book_details = WebDriverWait(self.driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CLASS_NAME, \"full-view-inner-container\"))\n",
    "                    )\n",
    "                    logger.info(\"\\nBook Details Clicked\")\n",
    "\n",
    "                except:\n",
    "\n",
    "                    first_book_link = WebDriverWait(self.driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.CSS_SELECTOR, \"h3.item-title a\"))\n",
    "                    )\n",
    "                    first_book_link.click()\n",
    "                    logger.info(\"\\nBook Title Clicked\")\n",
    "                \n",
    "                \n",
    "                self.handle_feedback_popup(self.driver)\n",
    "                    \n",
    "                for _ in range(3):\n",
    "                    # Wait for book details to be present\n",
    "                    self.handle_feedback_popup(self.driver)\n",
    "                    book_details = WebDriverWait(self.driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, \"div.full-view-inner-container.flex\"))\n",
    "                    )\n",
    "                    logger.info(\"\\nBook Details fetched\")\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    # Extract book title\n",
    "                    author_view = self.driver.find_element(By.CSS_SELECTOR, \"div.result-item-text.layout-fill.layout-column.flex\")\n",
    "                    logger.info(\"\\nAuthors fetched\")\n",
    "                    \n",
    "                    title = author_view.find_element(By.CSS_SELECTOR, \"h3.item-title\").text.strip()\n",
    "                    logger.info(\"\\nBook Title fetched\")\n",
    "                    \n",
    "                    # Extract Authors\n",
    "                    \n",
    "                    authors = []\n",
    "        \n",
    "                    \n",
    "                    try:\n",
    "                        author_div = author_view.find_element(By.XPATH, \"//div[contains(@class, 'item-detail') and contains(@class, 'reduce-lines-display')]\")\n",
    "                        \n",
    "                        \n",
    "                        # Find all author elements within this div\n",
    "                        author_elements = author_div.find_elements(By.CSS_SELECTOR, \"span[data-field-selector='creator'], span[data-field-selector='contributor']\")\n",
    "                        \n",
    "                        if len(author_elements)>0:\n",
    "                            for element in author_elements:\n",
    "                                author_text = element.text.strip()\n",
    "                                if author_text and author_text not in authors:\n",
    "                                    authors.append(author_text)\n",
    "                        else:\n",
    "                            author_div = book_details.find_element(By.XPATH, \"//div[.//span[@title='Author']]\")\n",
    "                        \n",
    "                            author_elements = author_div.find_elements(By.CSS_SELECTOR, \"a span[ng-bind-html='$ctrl.highlightedText']\")\n",
    "                            \n",
    "                            if not author_elements:\n",
    "\n",
    "                                author_elements = book_details.find_elements(By.XPATH, \"//div[contains(@class, 'item-details-element')]//a//span[contains(@ng-bind-html, '$ctrl.highlightedText')]\")\n",
    "                            if len(author_elements)>0:\n",
    "                                for element in author_elements:\n",
    "                                    author_text = element.text.strip()\n",
    "                                    if author_text and author_text not in authors:\n",
    "                                        authors.append(author_text)\n",
    "                        logger.info(\"\\nAuthors fetched\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        author = 'N/A'\n",
    "\n",
    "                    \n",
    "                    try:\n",
    "                        publisher = book_details.find_element(By.CSS_SELECTOR, \"span[data-field-selector='publisher']\").text.strip()\n",
    "                        logger.info(\"\\nPublisher fetched\")\n",
    "                    except:\n",
    "                        logger.info(\"\\nNo Publisher found\")\n",
    "                        publisher = \"N/A\"\n",
    "                    \n",
    "                    # Extract publication year\n",
    "                    try:\n",
    "                        year = book_details.find_element(By.CSS_SELECTOR, \"span[data-field-selector='creationdate']\").text.strip()\n",
    "                    except:\n",
    "                        logger.info(\"\\nNo Book details found\")\n",
    "                        year = \"N/A\"\n",
    "                    \n",
    "                    # Extract availability\n",
    "                    try:\n",
    "                        location_element = book_details.find_element(By.CSS_SELECTOR, \"h6.md-title\")\n",
    "                        availability = location_element.text.strip()\n",
    "                        logger.info(\"\\nAvailability found with first method\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        # Find the first link in the exception block\n",
    "                        location_element = book_details.find_elements(By.CSS_SELECTOR, \"a.item-title.md-primoExplore-theme\")\n",
    "                        if isinstance(location_element,list):\n",
    "                            availability = location_element[0].get_attribute('href')\n",
    "                        else:\n",
    "                            availability = location_element.get_attribute('href')\n",
    "                        logger.info(\"\\nAvailability found with second method\")\n",
    "                        \n",
    "                        if availability is None:\n",
    "                            location_element = book_details.find_elements(By.CSS_SELECTOR, \"h6.md-title ng-binding zero-margin\")\n",
    "                            availability = location_element.text.strip()\n",
    "                            logger.info(\"\\nAvailablility found with third method\")\n",
    "                            \n",
    "\n",
    "                        \n",
    "                    try:\n",
    "                        # Use more flexible locator strategies\n",
    "                        links = self.driver.find_elements(By.XPATH, \"//a[contains(@ui-sref, 'sourceRecord')]\")\n",
    "                        \n",
    "                        if isinstance(links, list) and len(links) > 0:\n",
    "                            \n",
    "                            link = links[0]\n",
    "                            link = link.get_attribute('href')\n",
    "                            logger.info(\"\\nFetched Link\")\n",
    "                        else:\n",
    "                            link = link.get_attribute('href')\n",
    "                            logger.info(\"\\nFetched Link\")\n",
    "                    except Exception as e:\n",
    "                        logger.info(\"\\nNo link Found\")\n",
    "\n",
    "\n",
    "                    # Compile book result\n",
    "                    book_result = {\n",
    "                        \"title\": title,\n",
    "                        \"authors\": authors,\n",
    "                        \"publisher\": publisher,\n",
    "                        \"year\": year,\n",
    "                        \"availability\": availability,\n",
    "                        \"link\": link\n",
    "                    }\n",
    "                    \n",
    "                    book_results.append(book_result)\n",
    "                    \n",
    "                    try:\n",
    "                        next_button = WebDriverWait(self.driver, 5).until(\n",
    "                            EC.element_to_be_clickable((By.XPATH, \"//button[contains(@ng-click, '$ctrl.getNextRecord()')]\"))\n",
    "                        )\n",
    "                        self.driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "\n",
    "                        next_button.click()\n",
    "                        \n",
    "                        logger.info(\"\\nClciked next button\")\n",
    "\n",
    "                        self.handle_feedback_popup(self.driver)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Failed to click next button\")\n",
    "                    \n",
    "                if len(book_results)==0:\n",
    "                    return False\n",
    "                \n",
    "                for book in book_results:\n",
    "                    book_string = f\"Title: {book['title']}\\n\"\n",
    "                    book_string += f\"Authors: {', '.join(book['authors']) if book['authors'] else 'N/A'}\\n\"\n",
    "                    book_string += f\"Publisher: {book['publisher']}\\n\"\n",
    "                    book_string += f\"Publication Year: {book['year']}\\n\"\n",
    "                    book_string += f\"Availability: {book['availability']}\\n\"\n",
    "                    book_string += f\"Link: {book['link']}\\n\"\n",
    "\n",
    "                    self.text_content.append({\n",
    "                        'content': book_string,\n",
    "                        'metadata': {\n",
    "                            'url': book['link'],\n",
    "                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        }\n",
    "                    })\n",
    "                    logger.info(\"\\nAppended book details: %s\" % self.text_content[-1])\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.info(\"\\nFailed to append book details: %s\" % e)\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "        \n",
    "        elif 'lib.asu.edu' in url:\n",
    "            def extract_query_parameters(query):\n",
    "                pattern = r'(\\w+)=([^&]*)'\n",
    "                matches = re.findall(pattern, query)\n",
    "                parameters = [{param: value} for param, value in matches]\n",
    "                return parameters\n",
    "\n",
    "            # Classify the extracted parameters into lists\n",
    "            library_names = []\n",
    "            dates = []\n",
    "            results = []\n",
    "\n",
    "            # Extract parameters from the query string\n",
    "            params = extract_query_parameters(optional_query)\n",
    "\n",
    "            # Populate the lists based on parameter types\n",
    "            for param in params:\n",
    "                for key, value in param.items():\n",
    "                    if key == 'library_names' and value != 'None':\n",
    "                        library_names.append(value.replace(\"['\", \"\").replace(\"']\", \"\"))\n",
    "                    if key == 'date' and value != 'None':\n",
    "                        dates.append(value.replace(\"['\",\"\").replace(\"']\",\"\"))\n",
    "            \n",
    "            try:\n",
    "                driver = self.driver\n",
    "                # Navigate to library hours page\n",
    "                self.driver.get(url)\n",
    "\n",
    "                # Wait for page to load\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"s-lc-whw\"))\n",
    "                )\n",
    "                \n",
    "                # Handle cookie popup\n",
    "                cookie_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, \"accept-btn\"))\n",
    "                )\n",
    "                cookie_button.click()\n",
    "\n",
    "                # Map library names to their row identifiers\n",
    "                library_map = {\n",
    "                    \"Tempe Campus - Noble Library\": \"Noble Library\",\n",
    "                    \"Tempe Campus - Hayden Library\": \"Hayden Library\",\n",
    "                    \"Downtown Phoenix Campus - Fletcher Library\": \"Downtown campus Library\",\n",
    "                    \"West Campus - Library\": \"Fletcher (West Valley)\",\n",
    "                    \"Polytechnic Campus - Library\": \"Polytechnic\"\n",
    "                }\n",
    "\n",
    "\n",
    "                # Process each library and date\n",
    "                for library_name in library_names: \n",
    "                    \n",
    "                    for date in dates:    \n",
    "                        iterations = 0\n",
    "                        is_date_present = False\n",
    "\n",
    "                        while not is_date_present:\n",
    "                            # Find all date headers in the thead\n",
    "                            date_headers = self.driver.find_elements(\n",
    "                                By.XPATH, \"//thead/tr/th/span[@class='s-lc-whw-head-date']\"\n",
    "                            )\n",
    "                            \n",
    "                            # Extract text from date headers\n",
    "                            header_dates = [header.text.strip() for header in date_headers]\n",
    "                            \n",
    "                            # Remove line breaks and additional whitespace\n",
    "                            header_dates = [date.lower().split('\\n')[0] for date in header_dates]\n",
    "                                \n",
    "                            # Check if requested date is in the list of header dates\n",
    "                            is_date_present = date.lower() in header_dates\n",
    "                            \n",
    "                            if not is_date_present:\n",
    "                                next_button = self.driver.find_element(By.ID, \"s-lc-whw-next-0\")\n",
    "                                next_button.click()\n",
    "                                time.sleep(0.2)  # Allow page to load\n",
    "                            \n",
    "                            iterations += 1\n",
    "                        \n",
    "                        # Optional: logger.info debug information\n",
    "                        logger.info(f\"Available Dates: {header_dates}\")\n",
    "                        logger.info(f\"Requested Date: {date}\")\n",
    "                        logger.info(f\"Date Present: {is_date_present}\")\n",
    "                        \n",
    "                    \n",
    "                        logger.info(\"\\nhello\")\n",
    "                        mapped_library_names = library_map.get(str(library_name))\n",
    "                        logger.info(f\"Mapped library names: {mapped_library_names}\")\n",
    "                        \n",
    "                        # Find library row\n",
    "                        library_row = self.driver.find_element(\n",
    "                            By.XPATH, f\"//tr[contains(., '{mapped_library_names}')]\"\n",
    "                        )\n",
    "                        \n",
    "                        \n",
    "                        logger.info(\"\\nFound library row\")\n",
    "\n",
    "                        # Find date column index\n",
    "                        date_headers = self.driver.find_elements(By.XPATH, \"//thead/tr/th/span[@class='s-lc-whw-head-date']\")\n",
    "                        \n",
    "                        logger.info(f\"Found date_headers\")\n",
    "                        \n",
    "                        date_column_index = None\n",
    "                        for index, header in enumerate(date_headers, start=0):\n",
    "                            logger.info(f\"header.text.lower() = {header.text.lower()}\")  \n",
    "                            logger.info(f\"date.lower() = {date.lower()}\")  \n",
    "                            if date.lower() == header.text.lower():\n",
    "                                date_column_index = index+1 if index==0 else index\n",
    "                                logger.info(\"\\nFound date column index\")\n",
    "                                break\n",
    "\n",
    "                        if date_column_index is None:\n",
    "                            logger.info(\"\\nNo date info found\")\n",
    "                            continue  # Skip if date not found\n",
    "                        \n",
    "                        logger.info(f\"Found date column index {date_column_index}\")\n",
    "                        # Extract status\n",
    "                        status_cell = library_row.find_elements(By.TAG_NAME, \"td\")[date_column_index]\n",
    "                        logger.info(f\"Found library row elements : {status_cell}\")\n",
    "                        try:\n",
    "                            status = status_cell.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "                            logger.info(f\"Found library status elements : {status}\")\n",
    "                        except Exception as e:\n",
    "                            logger.info(f\"Status cell HTML: {status_cell.get_attribute('outerHTML')}\")\n",
    "                            logger.error(f\"Error extracting library status: {e}\")\n",
    "                            raise\n",
    "                            break\n",
    "\n",
    "                        # Append to results\n",
    "                        library_result = {\n",
    "                            'library': mapped_library_names,\n",
    "                            'date': date,\n",
    "                            'status': status\n",
    "                        }\n",
    "                        logger.info(f\"mapping {library_result}\")\n",
    "                        results.append(library_result)\n",
    "\n",
    "                # Convert results to formatted string for text_content\n",
    "                logger.info(f\"Results : {results}\")\n",
    "                for library in results:\n",
    "                    lib_string = f\"Library: {library['library']}\\n\"\n",
    "                    lib_string += f\"Date: {library['date']}\\n\"\n",
    "                    lib_string += f\"Status: {library['status']}\\n\"\n",
    "                    \n",
    "                    self.text_content.append({\n",
    "                        'content': lib_string,\n",
    "                        'metadata': {\n",
    "                            'url': url,\n",
    "                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        }\n",
    "                    })\n",
    "                logger.info(self.text_content)\n",
    "                \n",
    "                return True\n",
    "\n",
    "            except Exception as e:\n",
    "                return f\"Error retrieving library status: {str(e)}\" \n",
    "                        \n",
    "        \n",
    "            \n",
    "            return False\n",
    "            \n",
    "        elif 'asu.libcal.com' in url:\n",
    "            # Navigate to the URL\n",
    "            self.driver.get(url)\n",
    "            \n",
    "            # Wait for page to load\n",
    "            \n",
    "            try:\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'panel'))\n",
    "                )\n",
    "                \n",
    "                # Parse page source with BeautifulSoup\n",
    "                soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "                \n",
    "                \n",
    "                # Reset text_content for new scrape\n",
    "                self.text_content = []\n",
    "                \n",
    "                # Find all study room panels\n",
    "                study_rooms = soup.find_all('div', class_='panel panel-default')\n",
    "                \n",
    "                for room in study_rooms:\n",
    "                    # Extract study room name\n",
    "                    study_room_name = room.find('h2', class_='panel-title').text.split('\\n')[0].strip()\n",
    "                    # Extract the date (consistent across all rooms)\n",
    "                    date = room.find('p').text.strip()  # \"Friday, December 6, 2024\"\n",
    "                    \n",
    "                    # Find all available time slots\n",
    "                    available_times = []\n",
    "                    time_slots = room.find_all('div', class_='checkbox')\n",
    "                    \n",
    "                    for slot in time_slots:\n",
    "                        time_text = slot.find('label').text.strip()\n",
    "                        available_times.append(time_text)\n",
    "                    \n",
    "                    # Append to text_content\n",
    "                    self.text_content.append({\n",
    "                        'content': f\"\"\"Library: {optional_query}\\nStudy Room: {study_room_name}\\nDate: {date}\\nAvailable slots: {', '.join(available_times)}\"\"\",\n",
    "                        'metadata': {\n",
    "                            'url': url,\n",
    "                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                            'source_type': 'asu_web_scrape',\n",
    "                        }\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error extracting study room data: {e}\")\n",
    "                return \"No Study Rooms Open Today\"\n",
    "                \n",
    "            \n",
    "            return True\n",
    "        \n",
    "        elif 'asu-shuttles.rider.peaktransit.com' in url:\n",
    "            query = optional_query\n",
    "            # Navigate to the URL\n",
    "            try:\n",
    "                # Navigate to the URL\n",
    "                self.driver.get(url)\n",
    "                time.sleep(3)\n",
    "                # Wait for route list to load\n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '#route-list .route-block .route-name'))\n",
    "                )\n",
    "                # Target the route list container first\n",
    "                route_list = self.driver.find_element(By.CSS_SELECTOR, \"div#route-list.route-block-container\")\n",
    "                \n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.route-block'))\n",
    "                )\n",
    "                route_blocks = route_list.find_elements(By.CSS_SELECTOR, \"div.route-block\")\n",
    "                \n",
    "                iterate_Y = 0\n",
    "                results=[]\n",
    "                button_times = 0\n",
    "                iterate_X=0\n",
    "                route = None\n",
    "                for route_block in route_blocks:\n",
    "                    WebDriverWait(self.driver, 10).until(\n",
    "                        EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.route-name'))\n",
    "                    )\n",
    "                    route_name = route_block.find_element(By.CSS_SELECTOR, \"div.route-name\")\n",
    "                    logger.info(\"\\nloacted routenames\")\n",
    "                    if \"Tempe-Downtown\" in route_name.text and  \"Tempe-Downtown\" in query:\n",
    "                        button_times =5\n",
    "                        route = route_name.text\n",
    "                        route_block.click()\n",
    "                        logger.info(\"\\nclicked\")\n",
    "                        break\n",
    "                    elif \"Tempe-West\" in route_name.text and \"Tempe-West\" in query:\n",
    "                        button_times=5\n",
    "                        route = route_name.text\n",
    "                        route_block.click()\n",
    "                        logger.info(\"\\nclicked\")\n",
    "                        break\n",
    "                    elif \"Mercado\" in route_name.text and \"Mercado\" in query:\n",
    "                        button_times = 2\n",
    "                        iterate_X = 12\n",
    "                        iterate_Y = 8\n",
    "                        route = route_name.text\n",
    "\n",
    "                        route_block.click()\n",
    "                        logger.info(\"\\nMercado\")\n",
    "                        break\n",
    "                    elif \"Polytechnic\" in route_name.text and \"Polytechnic\" in query:\n",
    "                        button_times = 2\n",
    "                        route_block.click()\n",
    "                        iterate_X = 10\n",
    "                        iterate_Y = 17\n",
    "                        route = route_name.text\n",
    "\n",
    "                    \n",
    "                        logger.info(\"\\nPolytechnic\")\n",
    "                        break\n",
    "                \n",
    "                time.sleep(2)\n",
    "                \n",
    "                WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, \"//div[contains(@style, 'z-index: 106')]\"))\n",
    "                )\n",
    "                \n",
    "                try:\n",
    "                    zoom_out_button = WebDriverWait(self.driver, 10).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//button[@aria-label='Zoom out']\"))\n",
    "                    )\n",
    "                    \n",
    "                    for _ in range(button_times):\n",
    "                        zoom_out_button.click()\n",
    "                        time.sleep(0.5)  # Short pause between clicks\n",
    "                \n",
    "                except Exception as e:\n",
    "                    logger.info(f\"Error clicking zoom out button: {e}\")\n",
    "\n",
    "                map_div = None\n",
    "                try:\n",
    "                    # Method 1: JavaScript click\n",
    "                    map_div = self.driver.find_element(By.CSS_SELECTOR, \"div[aria-label='Map']\")\n",
    "                    self.driver.execute_script(\"arguments[0].click();\", map_div)\n",
    "                    logger.info(\"\\nfirst method worked\")\n",
    "                \n",
    "                except Exception as first_error:\n",
    "                    try:\n",
    "                        # Method 2: ActionChains click\n",
    "                        map_div = driver.find_element(By.CSS_SELECTOR, \"div[aria-label='Map']\")\n",
    "                        actions = ActionChains(self.driver)\n",
    "                        actions.move_to_element(map_div).click().perform()\n",
    "                        logger.info(\"\\nsecond method worked\")\n",
    "                    \n",
    "                    except Exception as second_error:\n",
    "                        try:\n",
    "                            # Method 3: Move and click with offset\n",
    "                            map_div = driver.find_element(By.CSS_SELECTOR, \"div[aria-label='Map']\")\n",
    "                            actions = ActionChains(self.driver)\n",
    "                            actions.move_to_element_with_offset(map_div, 10, 10).click().perform()\n",
    "                            logger.info(\"\\nthird method worked\")\n",
    "                                 \n",
    "                        except Exception as third_error:\n",
    "                            logger.info(f\"All click methods failed: {first_error}, {second_error}, {third_error}\")\n",
    "\n",
    "                \n",
    "                \n",
    "                actions = ActionChains(self.driver)\n",
    "                if \"Mercado\" in query:\n",
    "                    # Move map to different directions\n",
    "                    directions_x = [\n",
    "                        (300, 0), \n",
    "                    ]\n",
    "                    directions_y = [\n",
    "                        (0, 300),   \n",
    "                    ]\n",
    "                    \n",
    "                    for i in range(0, iterate_X):\n",
    "                        \n",
    "                        for dx, dy in directions_x:\n",
    "                            # Click and hold on map\n",
    "                            actions.move_to_element(map_div).click_and_hold()\n",
    "                            \n",
    "                            # Move by offset\n",
    "                            actions.move_by_offset(dx, dy)\n",
    "                            \n",
    "                            # Release mouse button\n",
    "                            actions.release()\n",
    "                            \n",
    "                            # Perform the action\n",
    "                            actions.perform()\n",
    "                            logger.info(\"\\nmoved\")\n",
    "                            # Wait a moment between movements\n",
    "                    logger.info(\"\\niterating over y\")        \n",
    "                    for i in range(0, iterate_Y):\n",
    "                        for dx, dy in directions_y:\n",
    "                            actions.move_to_element(map_div).click_and_hold()\n",
    "                            actions.move_by_offset(dx, dy)\n",
    "                            actions.release()\n",
    "                            actions.perform()\n",
    "                            logger.info(\"\\nmoved\")\n",
    "                if \"Polytechnic\" in query:\n",
    "                    logger.info(\"\\npoly\")\n",
    "                    # Move map to different directions\n",
    "                    directions_x = [\n",
    "                        (-300, 0),\n",
    "                    ]\n",
    "                    directions_y = [\n",
    "                        (0, -300),   \n",
    "                    ]\n",
    "                    \n",
    "                    for i in range(0, iterate_X):\n",
    "                        \n",
    "                        for dx, dy in directions_x:\n",
    "                            # Click and hold on map\n",
    "                            actions.move_to_element(map_div).click_and_hold()\n",
    "                            \n",
    "                            # Move by offset\n",
    "                            actions.move_by_offset(dx, dy)\n",
    "                            actions.move_by_offset(dx, dy)\n",
    "                            \n",
    "                            # Release mouse button\n",
    "                            actions.release()\n",
    "                            \n",
    "                            # Perform the action\n",
    "                            actions.perform()\n",
    "                            logger.info(\"\\nmoved\")\n",
    "                            # Wait a moment between movements\n",
    "                    logger.info(\"\\niterating over y\")        \n",
    "                    for i in range(0, iterate_Y):\n",
    "                        \n",
    "                        for dx, dy in directions_y:\n",
    "                            actions.move_to_element(map_div).click_and_hold()\n",
    "                            actions.move_by_offset(dx, dy)\n",
    "                            actions.release()\n",
    "                            actions.perform()\n",
    "                            logger.info(\"\\nmoved\")\n",
    "                  \n",
    "                map_markers = self.driver.find_elements(By.CSS_SELECTOR, \n",
    "                    'div[role=\"button\"]  img[src=\"https://maps.gstatic.com/mapfiles/transparent.png\"]')\n",
    "                \n",
    "                for marker in map_markers:\n",
    "                    try:\n",
    "                        parent_div = marker.find_element(By.XPATH, '..')\n",
    "                        self.driver.execute_script(\"arguments[0].click();\", parent_div)\n",
    "                        \n",
    "                        dialog = WebDriverWait(self.driver, 10).until(\n",
    "                            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"dialog\"]'))\n",
    "                        )\n",
    "                        \n",
    "                        dialog_html = dialog.get_attribute('outerHTML')\n",
    "                        soup = BeautifulSoup(dialog_html, 'html.parser')\n",
    "                        \n",
    "                        stop_name_elem = soup.find('div', class_='stop-name')\n",
    "                        if stop_name_elem:\n",
    "                            stop_name = stop_name_elem.find('h2').get_text(strip=True)\n",
    "                            routes = soup.find_all('div', class_='route-name')\n",
    "                            \n",
    "                            station_routes = []\n",
    "                            for route in routes:\n",
    "                                route_name = route.get_text(strip=True)\n",
    "                                bus_blocks = route.find_next_siblings('div', class_='bus-block')\n",
    "                                \n",
    "                                # Safer extraction of bus times\n",
    "                                try:\n",
    "                                    next_bus_time = bus_blocks[0].find('div', class_='bus-time').get_text(strip=True) if bus_blocks else 'N/A'\n",
    "                                    second_bus_time = bus_blocks[1].find('div', class_='bus-time').get_text(strip=True) if len(bus_blocks) > 1 else 'N/A'\n",
    "                                    \n",
    "                                    station_routes.append({\n",
    "                                        'Route': route_name,\n",
    "                                        'Next Bus': next_bus_time,\n",
    "                                        'Second Bus': second_bus_time\n",
    "                                    })\n",
    "                                except IndexError:\n",
    "                                    # Skip routes without bus times\n",
    "                                    continue\n",
    "                            \n",
    "                            # Only append if station_routes is not empty\n",
    "                            if station_routes:\n",
    "                                parsed_stations = [{\n",
    "                                    'Station': stop_name,\n",
    "                                    'Routes': station_routes\n",
    "                                }]\n",
    "                                results.extend(parsed_stations)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        # Log the error without stopping the entire process\n",
    "                        logger.info(f\"Error processing marker: {e}\")\n",
    "                        continue\n",
    "                content = [\n",
    "                            f\"Station : {result['Station']}\\n\"\n",
    "                            f\"Route : {route['Route']}\\n\"\n",
    "                            f\"Next Bus : {route['Next Bus']}\\n\"\n",
    "                            f\"Second Bus : {route['Second Bus']}\"\n",
    "                            for result in results\n",
    "                            for route in result['Routes']\n",
    "                            if 'mins.' in route['Next Bus'] and 'mins.' in route['Second Bus']\n",
    "                        ]\n",
    "                content = set(content)  \n",
    "                for c in content:\n",
    "                    self.text_content.append({\n",
    "                        'content': c,\n",
    "                        'metadata': {\n",
    "                            'url': url,\n",
    "                            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "\n",
    "                        }\n",
    "                    })        \n",
    "                return True\n",
    "            \n",
    "            except Exception as e:\n",
    "                logger.info(f\"Error extracting shuttle status: {e}\")\n",
    "                return False\n",
    "            \n",
    "        else:\n",
    "            logger.error(\"NO CHOICE FOR SCRAPER!\")\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    async def discord_search(self, query: str, channel_ids: List[int], limit: int = 40) -> List[Dict[str, str]]:\n",
    "        if not self.discord_client:\n",
    "            logger.info(f\"Could not initialize discord_client {self.discord_client}\")\n",
    "            return []\n",
    "        \n",
    "        messages = []\n",
    "        await utils.update_text(\"Searching the Sparky Discord Server\")\n",
    "        \n",
    "        for channel_id in channel_ids:\n",
    "            channel = self.discord_client.get_channel(channel_id)\n",
    "            \n",
    "            if not channel:\n",
    "                logger.info(f\"Could not access channel with ID {channel_id}\")\n",
    "                continue\n",
    "            \n",
    "            if isinstance(channel, discord.TextChannel):\n",
    "                async for message in channel.history(limit=limit):\n",
    "                    messages.append(self._format_message(message))\n",
    "            elif isinstance(channel, discord.ForumChannel):\n",
    "                async for thread in channel.archived_threads(limit=limit):\n",
    "                    async for message in thread.history(limit=limit):\n",
    "                        messages.append(self._format_message(message))\n",
    "            \n",
    "            if len(messages) >= limit:\n",
    "                break\n",
    "            \n",
    "        print(messages)\n",
    "        \n",
    "        for message in messages[:limit]:\n",
    "            self.text_content.append({\n",
    "                'content': message['content'],\n",
    "                'metadata': {\n",
    "                    'url': message['url'],\n",
    "                    'timestamp': message['timestamp'],\n",
    "                }\n",
    "            })\n",
    "\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _format_message(self, message: discord.Message) -> Dict[str, str]:\n",
    "        timestamp = message.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        formatted_content = (\n",
    "            f\"Sent by: {message.author.name} {timestamp}\\n\"\n",
    "            f\"Message content: {message.content}\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'url': message.jump_url,\n",
    "            'content': formatted_content,\n",
    "            'timestamp': timestamp\n",
    "        }\n",
    "    \n",
    "    async def engine_search(self, search_url: str =None, optional_query : str = None ) -> List[Dict[str, str]]:\n",
    "        \"\"\"Handle both Google search results and ASU Campus Labs pages using Selenium\"\"\"\n",
    "        \n",
    "        try:\n",
    "            search_results = []\n",
    "            await utils.update_text(f\"Searching for {search_url}\")\n",
    "            await self.discord_search(query=optional_query, channel_ids=[1323386884554231919,1298772258491203676,1256079393009438770,1256128945318002708], limit=30)\n",
    "            self.driver = webdriver.Chrome(options=self.chrome_options)\n",
    "            driver = self.driver\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "            if (search_url):\n",
    "                try:\n",
    "                    driver.get(search_url)\n",
    "\n",
    "                    if 'google.com/search' in search_url:\n",
    "                        # Wait for search results to load\n",
    "                        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.g')))\n",
    "                        \n",
    "                        # Find all search result elements\n",
    "                        results = driver.find_elements(By.CSS_SELECTOR, 'div.g')\n",
    "                        for result in results[:5]:  # Limit to top 3 results\n",
    "                            try:\n",
    "                                link = result.find_element(By.CSS_SELECTOR, 'a')\n",
    "                                url = link.get_attribute('href')\n",
    "                                \n",
    "                                if url and url.startswith('http'):\n",
    "                                    clean_url = f\"{url}\"\n",
    "                                    if clean_url not in search_results:\n",
    "                                        search_results.append(clean_url)\n",
    "                            except Exception as e:\n",
    "                                continue\n",
    "                        \n",
    "                        logger.info(f\"Found {len(search_results)} Google search results\")\n",
    "                                        # Handle ASU Campus Labs pages\n",
    "                    \n",
    "                    if 'asu.campuslabs.com/engage' in search_url:\n",
    "                        if 'events' in search_url:\n",
    "                            # Wait for events to load\n",
    "                            events = wait.until(EC.presence_of_all_elements_located(\n",
    "                                (By.CSS_SELECTOR, 'a[href*=\"/engage/event/\"]')\n",
    "                            ))\n",
    "                            search_results = [\n",
    "                                event.get_attribute('href') \n",
    "                                for event in events[:5]\n",
    "                            ]\n",
    "                            \n",
    "                        elif 'organizations' in search_url:\n",
    "                            # Wait for organizations to load\n",
    "                            orgs = wait.until(EC.presence_of_all_elements_located(\n",
    "                                (By.CSS_SELECTOR, 'a[href*=\"/engage/organization/\"]')\n",
    "                            ))\n",
    "                            search_results = [\n",
    "                                org.get_attribute('href') \n",
    "                                for org in orgs[:5]\n",
    "                            ]\n",
    "                            \n",
    "                        elif 'news' in search_url:\n",
    "                            # Wait for news items to load\n",
    "                            news = wait.until(EC.presence_of_all_elements_located(\n",
    "                                (By.CSS_SELECTOR, 'a[href*=\"/engage/news/\"]')\n",
    "                            ))\n",
    "                            search_results = [\n",
    "                                article.get_attribute('href') \n",
    "                                for article in news[:5]\n",
    "                            ]\n",
    "                        \n",
    "                        \n",
    "                        logger.info(f\"Found {len(search_results)} ASU Campus Labs results\")\n",
    "                    \n",
    "                    if 'x.com' in search_url or 'facebook.com' in search_url or \"instagram.com\" in search_url:\n",
    "                        if optional_query:\n",
    "                            logger.info(\"\\nOptional query :: %s\" % optional_query)\n",
    "                            google_search_url = f\"https://www.google.com/search?q={urllib.parse.quote(optional_query)} site:{urlparse(search_url).netloc}\"\n",
    "                            google_results = await self.engine_search(search_url=google_search_url)\n",
    "                            \n",
    "                            google_filtered_results = [\n",
    "                                url for url in google_results \n",
    "                                if urlparse(url).netloc == urlparse(search_url).netloc\n",
    "                            ][:5]\n",
    "                            \n",
    "                            search_results.extend(google_filtered_results)\n",
    "                        else:\n",
    "                            if 'x.com' in search_url or 'twitter.com' in search_url:\n",
    "                                try:\n",
    "                                    try:\n",
    "                                        WebDriverWait(driver, 30).until(\n",
    "                                            EC.presence_of_all_elements_located((By.TAG_NAME, 'body'))\n",
    "                                        )\n",
    "                                    except Exception as e:\n",
    "                                        logger.warning(f\"Timeout waiting for tweets to load {str(e)}\")\n",
    "                                    page_source = driver.page_source\n",
    "                                    \n",
    "                                    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                                    time.sleep(3)\n",
    "                                    \n",
    "                                    # Define tweet selectors\n",
    "                                    tweet_selectors = [\n",
    "                                        'article[data-testid=\"tweet\"]',\n",
    "                                        'div[data-testid=\"cellInnerDiv\"]',\n",
    "                                        'div[role=\"article\"]',\n",
    "                                        \n",
    "                                    ]\n",
    "                                    \n",
    "                                    # Find tweet articles\n",
    "                                    tweet_articles = []\n",
    "                                    for selector in tweet_selectors:\n",
    "                                        tweet_articles = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                                        if tweet_articles:\n",
    "                                            break\n",
    "                                    \n",
    "                                    if not tweet_articles:\n",
    "                                        logger.error('No tweet articles found')\n",
    "                                        return []\n",
    "                                    \n",
    "                                    # Extract top 3 tweet links\n",
    "                                    tweet_links = []\n",
    "                                    for article in tweet_articles[:5]:\n",
    "                                        try:\n",
    "                                            link_selectors = [\n",
    "                                                'a[href*=\"/status/\"]',\n",
    "                                                'a[dir=\"ltr\"][href*=\"/status/\"]'\n",
    "                                            ]\n",
    "                                            \n",
    "                                            for selector in link_selectors:\n",
    "                                                try:\n",
    "                                                    timestamp_link = article.find_element(By.CSS_SELECTOR, selector)\n",
    "                                                    tweet_url = timestamp_link.get_attribute('href')\n",
    "                                                    if tweet_url:\n",
    "                                                        tweet_links.append(tweet_url)\n",
    "                                                        break\n",
    "                                                except:\n",
    "                                                    continue\n",
    "                                        except Exception as inner_e:\n",
    "                                            logger.error(f\"Error extracting individual tweet link: {str(inner_e)}\")\n",
    "                                    \n",
    "                                    logger.info(tweet_links)\n",
    "                                    search_results.extend(tweet_links)\n",
    "                                    logger.info(f\"Found {len(tweet_links)} X (Twitter) links\")\n",
    "                                    \n",
    "                                except Exception as e:\n",
    "                                    logger.error(f\"X.com tweet link extraction error: {str(e)}\")\n",
    "                                    try:\n",
    "                                        driver.save_screenshot(\"x_com_error_screenshot.png\")\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                            \n",
    "                            elif 'instagram.com' in search_url:\n",
    "                                try:\n",
    "                                    instagram_post_selectors = [\n",
    "                                        'article[role=\"presentation\"]',\n",
    "                                        'div[role=\"presentation\"]',\n",
    "                                        'div[class*=\"v1Nh3\"]'\n",
    "                                    ]\n",
    "                                    \n",
    "                                    instagram_link_selectors = [\n",
    "                                        'a[href*=\"/p/\"]',\n",
    "                                        'a[role=\"link\"][href*=\"/p/\"]'\n",
    "                                    ]\n",
    "                                    \n",
    "                                    instagram_articles = []\n",
    "                                    for selector in instagram_post_selectors:\n",
    "                                        instagram_articles = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                                        if instagram_articles:\n",
    "                                            break\n",
    "                                    \n",
    "                                    instagram_links = []\n",
    "                                    for article in instagram_articles[:5]:\n",
    "                                        for link_selector in instagram_link_selectors:\n",
    "                                            try:\n",
    "                                                post_link = article.find_element(By.CSS_SELECTOR, link_selector)\n",
    "                                                insta_url = post_link.get_attribute('href')\n",
    "                                                if insta_url and insta_url not in instagram_links:\n",
    "                                                    instagram_links.append(insta_url)\n",
    "                                                    break\n",
    "                                            except Exception as insta_link_error:\n",
    "                                                continue\n",
    "                                    \n",
    "                                    search_results.extend(instagram_links)\n",
    "                                    logger.info(f\"Found {len(instagram_links)} Instagram post links\")\n",
    "                                \n",
    "                                except Exception as instagram_error:\n",
    "                                    logger.error(f\"Instagram link extraction error: {str(instagram_error)}\")\n",
    "                                    try:\n",
    "                                        driver.save_screenshot(\"instagram_error_screenshot.png\")\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                        logger.info(f\"Found {len(search_results)} ASU Social Media results\")\n",
    "                    \n",
    "                    if 'https://goglobal.asu.edu/scholarship-search' in search_url or 'https://onsa.asu.edu/scholarships'in search_url:\n",
    "                        try:\n",
    "                            # Get base domain based on URL\n",
    "                            base_url = \"https://goglobal.asu.edu\" if \"goglobal\" in search_url else \"https://onsa.asu.edu\"\n",
    "                            \n",
    "                            driver.get(search_url)\n",
    "                            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "                            \n",
    "                            # Handle cookie consent for goglobal\n",
    "                            try:\n",
    "                                cookie_button = WebDriverWait(driver, 5).until(\n",
    "                                    EC.element_to_be_clickable((By.CSS_SELECTOR, '.accept-btn'))\n",
    "                                )\n",
    "                                driver.execute_script(\"arguments[0].click();\", cookie_button)\n",
    "                                time.sleep(2)\n",
    "                            except Exception as cookie_error:\n",
    "                                logger.warning(f\"Cookie consent handling failed: {cookie_error}\")\n",
    "                            \n",
    "                            if optional_query:\n",
    "                                logger.info(\"\\nOptional query :: %s\" % optional_query)\n",
    "                                \n",
    "                                # Parse query parameters\n",
    "                                query_params = dict(param.split('=') for param in optional_query.split('&') if '=' in param)\n",
    "                                \n",
    "                                # Define filter mappings based on site\n",
    "                                filter_mapping = {\n",
    "                                    'goglobal.asu.edu': {\n",
    "                                        'academiclevel': '#edit-field-ss-student-type-target-id',\n",
    "                                        'citizenship_status': '#edit-field-ss-citizenship-status-target-id',\n",
    "                                        'gpa': '#edit-field-ss-my-gpa-target-id',\n",
    "                                        # 'college': '#edit-field-college-ss-target-id',\n",
    "                                    },\n",
    "                                    'onsa.asu.edu': {\n",
    "                                        'search_bar_query': 'input[name=\"combine\"]',\n",
    "                                        'citizenship_status': 'select[name=\"field_citizenship_status\"]',\n",
    "                                        'eligible_applicants': 'select[name=\"field_eligible_applicants\"]',\n",
    "                                        'focus': 'select[name=\"field_focus\"]',\n",
    "                                    }\n",
    "                                }\n",
    "                                \n",
    "                                # Determine which site's filter mapping to use\n",
    "                                site_filters = filter_mapping['goglobal.asu.edu'] if 'goglobal.asu.edu' in search_url else filter_mapping['onsa.asu.edu']\n",
    "                                \n",
    "                                # Apply filters with robust error handling\n",
    "                                for param, value in query_params.items():\n",
    "                                    if param in site_filters and value:\n",
    "                                        try:\n",
    "                                            filter_element = WebDriverWait(driver, 10).until(\n",
    "                                                EC.element_to_be_clickable((By.CSS_SELECTOR, site_filters[param]))\n",
    "                                            )\n",
    "                                            \n",
    "                                            # Scroll element into view\n",
    "                                            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", filter_element)\n",
    "                                            time.sleep(1)\n",
    "                                            \n",
    "                                            # Handle different input types\n",
    "                                            if filter_element.tag_name == 'select':\n",
    "                                                Select(filter_element).select_by_visible_text(value)\n",
    "                                            elif filter_element.tag_name == 'input':\n",
    "                                                filter_element.clear()\n",
    "                                                filter_element.send_keys(value)\n",
    "                                                filter_element.send_keys(Keys.ENTER)\n",
    "                                            \n",
    "                                            time.sleep(1)\n",
    "                                        except Exception as filter_error:\n",
    "                                            logger.warning(f\"Could not apply filter {param}: {filter_error}\")\n",
    "                                \n",
    "                                # Click search button with multiple retry mechanism\n",
    "                                search_button_selectors = ['input[type=\"submit\"]', 'button[type=\"submit\"]', '.search-button']\n",
    "                                for selector in search_button_selectors:\n",
    "                                    try:\n",
    "                                        search_button = WebDriverWait(driver, 10).until(\n",
    "                                            EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                                        )\n",
    "                                        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", search_button)\n",
    "                                        time.sleep(1)\n",
    "                                        driver.execute_script(\"arguments[0].click();\", search_button)\n",
    "                                        break\n",
    "                                    except Exception as e:\n",
    "                                        logger.warning(f\"Search button click failed for selector {selector}: {e}\")\n",
    "                            \n",
    "                            # Extract scholarship links with improved URL construction\n",
    "                            link_selectors = {\n",
    "                                'goglobal': 'td[headers=\"view-title-table-column\"] a',\n",
    "                                'onsa': 'td a'\n",
    "                            }\n",
    "                            \n",
    "                            current_selector = link_selectors['goglobal'] if \"goglobal\" in search_url else link_selectors['onsa']\n",
    "                            \n",
    "                            scholarship_links = WebDriverWait(driver, 10).until(\n",
    "                                EC.presence_of_all_elements_located((By.CSS_SELECTOR, current_selector))\n",
    "                            )\n",
    "                            \n",
    "                            for link in scholarship_links[:5]:\n",
    "                                href = link.get_attribute('href')\n",
    "                                if href:\n",
    "                                    if href.startswith('/'):\n",
    "                                        search_results.append(f\"{base_url}{href}\")\n",
    "                                    elif href.startswith('http'):\n",
    "                                        search_results.append(href)\n",
    "                                    else:\n",
    "                                        search_results.append(f\"{base_url}/{href}\")\n",
    "                            \n",
    "                            logger.info(f\"Found {len(search_results)} scholarship links - \")\n",
    "                            logger.info(f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "                            logger.info(f\"{search_results}\")\n",
    "                            logger.info(f\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            logger.error(f\"Error in scholarship search: {str(e)}\")\n",
    "                            try:\n",
    "                                driver.save_screenshot(f\"error_screenshot_{int(time.time())}.png\")\n",
    "                            except:\n",
    "                                pass\n",
    "                    \n",
    "                    if 'catalog.apps.asu.edu' in search_url or  'search.lib.asu.edu' in search_url :\n",
    "                        await self.scrape_content(search_url, selenium=True)\n",
    "                        return self.text_content\n",
    "                    \n",
    "                    if 'https://app.joinhandshake.com/stu/postings' in search_url or 'lib.asu.edu' in search_url or \"asu.libcal.com\" in search_url or \"asu-shuttles.rider.peaktransit.com\" in search_url:                    \n",
    "                        await self.scrape_content(search_url, selenium=True, optional_query=optional_query)\n",
    "                        return self.text_content\n",
    "                        \n",
    "                finally:\n",
    "                    driver.quit()\n",
    "                \n",
    "                for url in search_results:\n",
    "                    await self.scrape_content(url=url)\n",
    "            \n",
    "            return self.text_content\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in search: {str(e)}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_scraper = ASUWebScraper()\n",
    "\n",
    "\n",
    "logger.info(\"\\nInitialized ASUWebScraper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Gemini Agents\n",
    "\n",
    "This section outlines the setup for Gemini Agents, focusing on defining function parameters for tool functions and establishing a global instance for action commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Types of Function Parameters\n",
    "\n",
    "#### String Parameter\n",
    "For a simple string input:\n",
    "\n",
    "```python\n",
    "\"search_bar_query\": content.Schema(\n",
    "    type=content.Type.STRING,\n",
    "    description=\"Optional search query to filter social media posts\"\n",
    "),\n",
    "```\n",
    "\n",
    "#### Array Parameter\n",
    "For an array of string options:\n",
    "\n",
    "```python\n",
    "\"class_subject\": content.Schema(\n",
    "    type=content.Type.ARRAY,\n",
    "    items=content.Schema(\n",
    "        type=content.Type.STRING,\n",
    "        enum=[\n",
    "            \"@ArizonaState\", \n",
    "            \"@SunDevilAthletics\", \n",
    "            \"@SparkySunDevil\", \n",
    "            \"@SunDevilFootball\", \n",
    "            \"@ASUFootball\", \n",
    "            \"@SunDevilFB\"\n",
    "        ]\n",
    "    ),\n",
    "    description=\"Pick from the List of ASU social media account names to search\"\n",
    "),\n",
    "```\n",
    "\n",
    "#### Enumerated String Parameter\n",
    "For a string parameter with predefined options:\n",
    "\n",
    "```python\n",
    "\"class_subject\": content.Schema(\n",
    "    type=content.Type.STRING,\n",
    "    description=\"Program Type\",\n",
    "    enum=[\n",
    "        \"Exchange\",\n",
    "        \"Faculty-Directed\",\n",
    "        \"Global Intensive Experience\",\n",
    "        \"Partnership\",\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when tool function parameter is a string - \n",
    "\n",
    "```\n",
    "\"search_bar_query\": content.Schema(\n",
    "    type=content.Type.STRING,\n",
    "    description=\"Optional search query to filter social media posts\"\n",
    "),\n",
    "```\n",
    "when tool function parameter is an array - \n",
    "```\n",
    "\"class_subject\": content.Schema(\n",
    "    type=content.Type.ARRAY,\n",
    "    items=content.Schema(\n",
    "        type=content.Type.STRING,\n",
    "        enum=[\n",
    "            \"@ArizonaState\", \n",
    "            \"@SunDevilAthletics\", \n",
    "            \"@SparkySunDevil\", \n",
    "            \"@SunDevilFootball\", \n",
    "            \"@ASUFootball\", \n",
    "            \"@SunDevilFB\"\n",
    "        ]\n",
    "    ),\n",
    "    description=\"Pick from the List of ASU social media account names to search\"\n",
    "),\n",
    "```\n",
    "when tool function parameter is a string and you want model to pick from something - \n",
    "```\n",
    "\"class_subject\": content.Schema(\n",
    "    type=content.Type.STRING,\n",
    "    description=\"Program Type\",\n",
    "    enum=[\n",
    "        \"Exchange\",\n",
    "        \"Faculty-Directed\",\n",
    "        \"Global Intensive Experience\",\n",
    "        \"Partnership\",\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Action Command Instance\n",
    "\n",
    "To maintain action commands across different agents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global action_command\n",
    "action_command = None\n",
    "\n",
    "\n",
    "logger.info(\"\\nInitialized ActionCommands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model\n",
    "\n",
    "This `DataModel` class serves as a crucial component for enhancing the quality and structure of text data, particularly useful in the context of the ASU Discord Research Assistant Bot for refining search results and improving information presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "- The class is initialized with an optional `model` parameter, which is expected to be an instance of Google's Gemini model.\n",
    "\n",
    "#### Text Refinement\n",
    "- The `refine` method is the core function for processing text:\n",
    "  - It takes a `search_context` and `text` as input.\n",
    "  - Constructs a prompt using a predefined template from `app_config.get_data_agent_prompt()`.\n",
    "  - Sends the prompt to the Gemini model for processing.\n",
    "\n",
    "#### Response Handling\n",
    "- The method attempts to generate content using the Gemini model.\n",
    "- If successful, it parses the JSON response using the `parse_json_response` method.\n",
    "- Returns the refined title extracted from the parsed response.\n",
    "\n",
    "#### Error Handling\n",
    "- Implements comprehensive error logging for various scenarios:\n",
    "  - Gemini model errors\n",
    "  - JSON parsing errors\n",
    "  - Missing required fields in the response\n",
    "\n",
    "#### JSON Parsing\n",
    "- The `parse_json_response` method processes the model's output:\n",
    "  - Cleans the response text by removing markdown code block indicators.\n",
    "  - Parses the cleaned text as JSON.\n",
    "  - Validates the presence of required fields (currently only 'title').\n",
    "  - Returns a dictionary with the parsed data or default values if parsing fails.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModel:\n",
    "    def __init__(self, model=None):\n",
    "        self.model = model\n",
    "  \n",
    "    def refine(self, search_context: str, text: str) -> tuple[str, str, str]:\n",
    "        prompt = f\"\"\"{app_config.get_data_agent_prompt()}        \n",
    "        Search Context: {search_context}\n",
    "        Input Text: {text}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Data Model: Refining Data with context : {search_context} \\n and data : {text}\")\n",
    "            response = self.model.generate_content(prompt)\n",
    "            if response and hasattr(response, 'text'):\n",
    "                parsed = self.parse_json_response(response.text)\n",
    "                return (\n",
    "                    # parsed.get('refined_content', ''),\n",
    "                    parsed.get('title', ''),\n",
    "                )\n",
    "            return None, None, None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gemini refinement error: {str(e)}\")\n",
    "            return None, None, None\n",
    "\n",
    "    def parse_json_response(self, response_text: str) -> dict:\n",
    "        \"\"\"Parse the JSON response into components.\"\"\"\n",
    "        try:\n",
    "            # Remove any potential markdown code block indicators\n",
    "            cleaned_response = response_text.replace('```json', '').replace('```', '').strip()\n",
    "\n",
    "            # Parse the JSON string into a dictionary\n",
    "            parsed_data = json.loads(cleaned_response)\n",
    "\n",
    "            # Validate required fields\n",
    "            required_fields = { 'title'}\n",
    "            if not all(field in parsed_data for field in required_fields):\n",
    "                logger.error(\"Missing required fields in JSON response\")\n",
    "                return { 'title': ''}\n",
    "\n",
    "            return parsed_data\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(f\"JSON parsing error: {str(e)}\")\n",
    "            return { 'title': '', 'category': ''}\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error parsing response: {str(e)}\")\n",
    "            return {'title': '', 'category': ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_data_agent = DataModel(dir_Model)\n",
    "\n",
    "logger.info(\"\\nInitialized DataModel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live_Status Model\n",
    "\n",
    "The `Live_Status_Model` class is designed to handle real-time status queries for ASU services, particularly focusing on library and shuttle statuses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "- Initializes with a model (`live_status_model`), functions (`Live_Status_Model_Functions`), and conversation tracking.\n",
    "- Implements rate limiting and request counting.\n",
    "\n",
    "#### Function Execution\n",
    "- `execute_function` method dynamically calls the appropriate function based on the function name.\n",
    "- Supports `get_live_library_status` and `get_live_shuttle_status` functions.\n",
    "- Implements error handling and logging for function execution.\n",
    "\n",
    "#### Model Initialization\n",
    "- `_initialize_model` method sets up the chat model with automatic function calling enabled.\n",
    "- Implements rate limiting to prevent excessive requests.\n",
    "\n",
    "#### Action Determination\n",
    "- `determine_action` method processes user queries and special instructions.\n",
    "- Constructs a prompt with current context, user query, and agent instructions.\n",
    "- Handles both text responses and function calls from the model.\n",
    "\n",
    "#### Response Processing\n",
    "- Iterates through model response parts, handling both text and function calls.\n",
    "- Executes functions when called and formats the final response.\n",
    "\n",
    "#### Error Handling\n",
    "- Comprehensive error logging throughout the class.\n",
    "- Fallback responses for various error scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Live_Status_Model_Functions:\n",
    "    def __init__(self):\n",
    "        self.visited_urls = set()\n",
    "        self.max_depth = 2\n",
    "        self.max_links_per_page = 3\n",
    "                \n",
    "    async def get_live_library_status(self, status_type : [] = None, date : str = None, library_names: [] = None):\n",
    "        \"\"\"\n",
    "        Retrieve ASU Library Status using ASU Library Search with robust parameter handling.\n",
    "\n",
    "        Args:\n",
    "            status_type ([]): Open or Close & Study Room Availability.\n",
    "            library_names ([], optional): Name of library.\n",
    "            date (str): Dec 01 (Month_prefix + Date).\n",
    "\n",
    "        Returns:\n",
    "            Union[str, dict]: Search results or error message.\n",
    "            \n",
    "        Notes:\n",
    "        Example URL- \n",
    "        https://asu.libcal.com/r/accessible/availability?lid=13858&gid=28619&zone=0&space=0&capacity=2&date=2024-12-04\n",
    "        \"\"\"\n",
    "        \n",
    "        if not (library_names or status_type or date):\n",
    "            return \"Error: Atleast one parameter required\"\n",
    "        \n",
    "        search_url=None\n",
    "        query=None\n",
    "        result =\"\"\n",
    "        doc_title = \" \".join(library_names)\n",
    "        if \"Availability\" in status_type:\n",
    "            search_url=f\"https://lib.asu.edu/hours\"\n",
    "            query = f\"library_names={library_names}&date={date}\"\n",
    "            result+=await utils.perform_web_search(search_url, query,doc_title=doc_title, doc_category =\"libraries_status\")\n",
    "        \n",
    "        library_map = {\n",
    "            \"Tempe Campus - Hayden Library\": \"13858\",\n",
    "            \"Tempe Campus - Noble Library\": \"1702\",\n",
    "            \"Downtown Phoenix Campus - Fletcher Library\": \"1703\",\n",
    "            \"West Campus - Library\": \"1707\",\n",
    "            \"Polytechnic Campus - Library\": \"1704\"\n",
    "        }\n",
    "        \n",
    "        gid_map={\n",
    "            \"13858\": \"28619\",\n",
    "             \"1702\": \"2897\",\n",
    "            \"1703\": \"2898\",\n",
    "            \"1707\": \"28611\",\n",
    "            \"1704\": \"2899\"\n",
    "        }\n",
    "             \n",
    "        if \"StudyRoomsAvailability\" in status_type:\n",
    "            transformed_date = datetime.strptime(date, '%b %d').strftime('2024-%m-%d')\n",
    "            for library in library_names:\n",
    "                query= library_map[library]\n",
    "                search_url = f\"https://asu.libcal.com/r/accessible/availability?lid={library_map[library]}&gid={gid_map[library_map[library]]}&zone=0&space=0&capacity=2&date={transformed_date}\"\n",
    "                result+=await utils.perform_web_search(search_url, query,doc_title=doc_title, doc_category =\"libraries_status\")\n",
    "            \n",
    "        return result\n",
    "        \n",
    "    async def get_live_shuttle_status(self, shuttle_route: [] = None):\n",
    "        if not shuttle_route:\n",
    "            return \"Error: At least one route is required\"\n",
    "        \n",
    "        shuttle_route = set(shuttle_route)\n",
    "        \n",
    "        doc_title = \" \".join(shuttle_route)\n",
    "        search_url=\"https://asu-shuttles.rider.peaktransit.com/\"\n",
    "\n",
    "        logger.info(shuttle_route)\n",
    "        \n",
    "        if len(shuttle_route) == 1:\n",
    "            logger.info(\"\\nOnly one route\")\n",
    "            route = next(iter(shuttle_route))\n",
    "            return await utils.perform_web_search(search_url, optional_query=route,doc_title=doc_title, doc_category =\"shuttles_status\")\n",
    "\n",
    "        # Multiple routes handling\n",
    "        result = \"\"\n",
    "        try:\n",
    "            for route in shuttle_route:\n",
    "                result += await utils.perform_web_search(search_url, optional_query=route,doc_title=doc_title, doc_category =\"shuttles_status\")\n",
    "            logger.info(\"\\nDone\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"Error performing shuttle search: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Live_Status_Model:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = live_status_model\n",
    "        self.chat=None\n",
    "        self.functions = Live_Status_Model_Functions()\n",
    "        self.last_request_time = time.time()\n",
    "        self.request_counter = 0\n",
    "        self.conversations: Dict[str, List[Dict[str, str]]] = {}\n",
    "        \n",
    "    async def execute_function(self, function_call):\n",
    "        \"\"\"Execute the called function and return its result\"\"\"\n",
    "        function_name = function_call.name\n",
    "        function_args = function_call.args\n",
    "        \n",
    "        function_mapping = {\n",
    "            \n",
    "            'get_live_library_status': self.functions.get_live_library_status,\n",
    "            'get_live_shuttle_status': self.functions.get_live_shuttle_status,\n",
    "        }\n",
    "        \n",
    "            \n",
    "        if function_name in function_mapping:\n",
    "            function_to_call = function_mapping[function_name]\n",
    "            func_response = await function_to_call(**function_args)\n",
    "            # response = await self.chat.send_message_async(f\"{function_name} response : {func_response}\")\n",
    "            logger.info(f\"Live Status : Function loop response : {func_response}\")\n",
    "            \n",
    "            if func_response:\n",
    "                return func_response\n",
    "            else:\n",
    "                logger.error(f\"Error extracting text from response: {e}\")\n",
    "                return \"Error processing response\"\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown function: {function_name}\")\n",
    "        \n",
    "    def _initialize_model(self):\n",
    "        if not self.model:\n",
    "            return logger.error(\"Model not initialized at ActionFunction\")\n",
    "            \n",
    "        # Rate limiting check\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_request_time < 1.0: \n",
    "            raise Exception(\"Rate limit exceeded\")\n",
    "            \n",
    "        self.last_request_time = current_time\n",
    "        self.request_counter += 1\n",
    "        user_id = discord_state.get(\"user_id\")\n",
    "        self.chat = self.model.start_chat(history=self._get_chat_history(user_id),enable_automatic_function_calling=True)\n",
    "\n",
    "    def _get_chat_history(self, user_id: str) -> List[Dict[str, str]]:\n",
    "        return self.conversations.get(user_id, [])\n",
    "\n",
    "    def _save_message(self, user_id: str, role: str, content: str):\n",
    "        if user_id not in self.conversations:\n",
    "            self.conversations[user_id] = []\n",
    "        \n",
    "        self.conversations[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": content}]\n",
    "        })\n",
    "        \n",
    "        # Limit the conversation length to 3 messages per user\n",
    "        if len(self.conversations[user_id]) > 3:\n",
    "            self.conversations[user_id].pop(0)\n",
    "        \n",
    "    async def determine_action(self, query: str,special_instructions:str) -> str:\n",
    "        \"\"\"Determines and executes the appropriate action based on the user query\"\"\"\n",
    "        try:\n",
    "            self._initialize_model()\n",
    "            user_id = discord_state.get(\"user_id\")\n",
    "            self._save_message(user_id, \"user\", query)\n",
    "            final_response = \"\"\n",
    "            \n",
    "            global action_command\n",
    "            action_command = query\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "                ### Context:\n",
    "                - Current Date and Time: {datetime.now().strftime('%H:%M %d') + ('th' if 11<=int(datetime.now().strftime('%d'))<=13 else {1:'st',2:'nd',3:'rd'}.get(int(datetime.now().strftime('%d'))%10,'th')) + datetime.now().strftime(' %B, %Y') }\n",
    "                - Superior Agent Instruction: {action_command}\n",
    "                - Superior Agent Remarks: {special_instructions}\n",
    "\n",
    "                {app_config.get_live_status_agent_prompt()}\n",
    "                \n",
    "                \"\"\"\n",
    "\n",
    "            response = await self.chat.send_message_async(prompt)\n",
    "            logger.info(self._get_chat_history)\n",
    "            self._save_message(user_id, \"model\", f\"{response.parts}\" )\n",
    "            logger.info(f\"Internal response @ Live Status Model : {response}\")\n",
    "            \n",
    "            for part in response.parts:\n",
    "                if hasattr(part, 'function_call') and part.function_call:\n",
    "                    \n",
    "                    final_response = await self.execute_function(part.function_call)\n",
    "                    firestore.update_message(\"live_status_agent_message\", f\"Function called {part.function_call}\\n Function Response {final_response} \")\n",
    "                elif hasattr(part, 'text') and part.text.strip():\n",
    "                    text = part.text.strip()\n",
    "                    firestore.update_message(\"live_status_agent_message\", f\"Text Response : {text}\")\n",
    "                    if not text.startswith(\"This query\") and not \"can be answered directly\" in text:\n",
    "                        final_response = text.strip()\n",
    "                        logger.info(f\"text response : {final_response}\")\n",
    "        \n",
    "        # Return only the final message\n",
    "            return final_response if final_response else \"Live Status agent fell off! Error 404\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Internal Error @ Live Status Model : {str(e)}\")\n",
    "            return \"I apologize, but I couldn't generate a response at this time. Please try again.\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_status_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 0.1,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 2500,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    },\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    },\n",
    "    system_instruction = f\"\"\"\n",
    "    {app_config.get_live_status_agent_instruction}\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        genai.protos.Tool(\n",
    "            function_declarations=[\n",
    "\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_live_library_status\",\n",
    "                    description=\"Retrieves Latest Information regarding ASU Library Status\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "\n",
    "                            \"status_type\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"Availability\", \n",
    "                                        \"StudyRoomsAvailability\", \n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Checks if library is open or close and study rooms availability\"\n",
    "                            ),\n",
    "                            \"library_names\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                \"Tempe Campus - Noble Library\",\n",
    "                                \"Tempe Campus - Hayden Library\",\n",
    "                                \"Downtown Phoenix Campus - Fletcher Library\",\n",
    "                                \"West Campus - Library\",\n",
    "                                \"Polytechnic Campus - Library\",      \n",
    "                                ]\n",
    "                                ),\n",
    "                                description=\"Library Name\"\n",
    "                            ),\n",
    "                             \"date\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"[ Month Prefix + Date ] (ex. DEC 09, JAN 01, FEB 21, MAR 23)\",\n",
    "                            ),\n",
    "                        },\n",
    "                            required=[\"status_type\",\"library_names\",\"date\"]\n",
    "                    )\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_live_shuttle_status\",\n",
    "                    description=\"Searches for shuttle status and routes\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"shuttle_route\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"Mercado\", \n",
    "                                        \"Polytechnic-Tempe\", \n",
    "                                        \"Tempe-Downtown Phoenix-West\", \n",
    "                                        \"Tempe-West Express\", \n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"The Route of Buses\"\n",
    "                            ),\n",
    "                        },\n",
    "                    required= [\"shuttle_route\"]\n",
    "                    ),\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    tool_config={'function_calling_config': 'ANY'},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_live_status_agent = Live_Status_Model()\n",
    "logger.info(\"\\nInitialized LiveStatusAgent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Model\n",
    "\n",
    "The `SearchModel` class is designed to handle complex search operations using Google's Generative AI model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Initialization\n",
    "- Initializes with configurable rate limiting parameters:\n",
    "  - `rate_limit_window`: Time window for rate limiting\n",
    "  - `max_requests`: Maximum number of requests allowed in the window\n",
    "  - `retry_attempts`: Number of retry attempts for function calls\n",
    "- Sets up conversation tracking and request counting\n",
    "\n",
    "#### Function Execution\n",
    "- `execute_function` method dynamically calls the appropriate function based on the function name\n",
    "- Supports various search functions like Google search, accessing deep search agent, and retrieving updates for clubs, events, news, sports, and social media\n",
    "\n",
    "#### Model Configuration\n",
    "- Uses the \"gemini-1.5-flash\" model with specific generation config settings\n",
    "- Implements safety settings to block low and above levels of hate speech and harassment\n",
    "\n",
    "#### Search Functionality\n",
    "- `determine_action` method processes user queries and special instructions\n",
    "- Constructs prompts with current context, user query, and agent instructions\n",
    "- Handles both text responses and function calls from the model\n",
    "\n",
    "#### Rate Limiting and Retry Mechanism\n",
    "- Implements a sophisticated rate limiting system to prevent excessive requests\n",
    "- Includes a retry mechanism for failed function calls\n",
    "\n",
    "#### Error Handling\n",
    "- Comprehensive error logging throughout the class\n",
    "- Fallback responses for various error scenarios\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search_Model_Functions:\n",
    "    def __init__(self):\n",
    "        self.visited_urls = set()\n",
    "        self.max_depth = 2\n",
    "        self.max_links_per_page = 3\n",
    "        \n",
    "    async def get_latest_club_information(self, search_bar_query: str = None, organization_category: list = None, organization_campus: list = None):\n",
    "        if not any([search_bar_query, organization_category, organization_campus]):\n",
    "            return \"At least one parameter of this function is required. Neither Search query and organization category and organization campus received. Please provide at least one parameter to perform search.\"\n",
    "        \n",
    "        search_url = \"https://asu.campuslabs.com/engage/organizations\"\n",
    "        params = []\n",
    "        organization_campus_ids = { \"ASU Downtown\":\"257211\",\n",
    "                                   \"ASU Online\":\"257214\",\n",
    "                                   \"ASU Polytechnic\":\"257212\",\n",
    "                                   \"ASU Tempe\":\"254417\",\n",
    "                                   \"ASU West Valley\":\"257213\",\n",
    "                                   \"Fraternity & Sorority Life\":\"257216\",\n",
    "                                   \"Housing & Residential Life\":\"257215\"}\n",
    "        \n",
    "        organization_category_ids = {\"Academic\":\"13382\",\"Barrett\":\"14598\",\"Creative/Performing Arts\":\"13383\",\"Cultural/Ethnic\":\"13384\",\"Distinguished Student Organization\":\"14549\",\"Fulton Organizations\":\"14815\",\"Graduate\":\"13387\",\"Health/Wellness\":\"13388\",\"International\":\"13389\",\"LGBTQIA+\":\"13391\",\"Political\":\"13392\",\"Professional\":\"13393\",\"Religious/Faith/Spiritual\":\"13395\",\"Service\":\"13396\",\"Social Awareness\":\"13398\",\"Special Interest\":\"13399\",\"Sports/Recreation\":\"13400\",\"Sustainability\":\"13402\",\"Technology\":\"13403\", \"Veteran Groups\":\"14569\",\"W.P. Carey Organizations\":\"14814\",\"Women\":\"13405\"}\n",
    "        doc_title=\"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif organization_category:\n",
    "            doc_title = \" \".join(organization_category)\n",
    "        elif organization_campus:\n",
    "            doc_title = \" \".join(organization_campus)\n",
    "        else:\n",
    "            doc_title = None\n",
    "\n",
    " \n",
    "        if organization_campus:\n",
    "            campus_id_array = [organization_campus_ids[campus] for campus in organization_campus if campus in organization_campus_ids]\n",
    "            if campus_id_array:\n",
    "                params.extend([f\"branches={campus_id}\" for campus_id in campus_id_array])\n",
    "        \n",
    "        if organization_category:\n",
    "            category_id_array = [organization_category_ids[category] for category in organization_category if category in organization_category_ids]\n",
    "            if category_id_array:\n",
    "                params.extend([f\"categories={category_id}\" for category_id in category_id_array])\n",
    "        \n",
    "        if search_bar_query:\n",
    "            params.append(f\"query={search_bar_query.lower().replace(' ', '%20')}\")\n",
    "        \n",
    "        if params:\n",
    "            search_url += \"?\" + \"&\".join(params)\n",
    "        \n",
    "        return await utils.perform_web_search(search_url, doc_title=doc_title, doc_category =\"clubs_info\")\n",
    "        \n",
    "    async def get_latest_event_updates(self, search_bar_query: str = None, event_category: list = None, \n",
    "                               event_theme: list = None, event_campus: list = None, \n",
    "                               shortcut_date: str = None, event_perk: list = None):\n",
    "        \n",
    "        if not any([search_bar_query, event_category, event_theme, event_campus]):\n",
    "            return \"At least one parameter of this function is required. Neither Search query and organization category and organization campus received. Please provide at least one parameter to perform search.\"\n",
    "        \n",
    "        search_url = \"https://asu.campuslabs.com/engage/events\"\n",
    "        params = []\n",
    "        \n",
    "        event_campus_ids = {\n",
    "            \"ASU Downtown\": \"257211\",\n",
    "            \"ASU Online\": \"257214\",\n",
    "            \"ASU Polytechnic\": \"257212\",\n",
    "            \"ASU Tempe\": \"254417\",\n",
    "            \"ASU West Valley\": \"257213\",\n",
    "            \"Fraternity & Sorority Life\": \"257216\",\n",
    "            \"Housing & Residential Life\": \"257215\"\n",
    "        }\n",
    "        \n",
    "        event_category_ids = {\n",
    "            \"ASU New Student Experience\": \"18002\",\n",
    "            \"ASU Sync\": \"15695\",\n",
    "            \"ASU Welcome Event\": \"12897\",\n",
    "            \"Barrett Student Organization\": \"12902\",\n",
    "            \"Black History Month\": \"21730\",\n",
    "            \"C3\": \"19049\",\n",
    "            \"Career and Professional Development\": \"12885\",\n",
    "            \"Change The World\": \"12887\",\n",
    "            \"Changemaker Central\": \"12886\",\n",
    "            \"Civic Engagement\": \"17075\",\n",
    "            \"Club Meetings\": \"12887\",\n",
    "            \"Clubs and Organization Information\": \"12888\",\n",
    "            \"Community Service\": \"12903\",\n",
    "            \"Cultural Connections and Multicultural community of Excellence\": \"21719\",\n",
    "            \"Culture @ ASU\": \"12898\",\n",
    "            \"DeStress Fest\": \"19518\",\n",
    "            \"Entrepreneurship & Innovation\": \"17119\",\n",
    "            \"General\": \"12889\",\n",
    "            \"Graduate\": \"12906\",\n",
    "            \"Hispanic Heritage Month\": \"21723\",\n",
    "            \"Homecoming\": \"20525\",\n",
    "            \"In-Person Event\": \"17447\",\n",
    "            \"International\": \"12899\",\n",
    "            \"Memorial Union & Student Pavilion Programs\": \"12900\",\n",
    "            \"Multicultural community of Excellence\": \"19389\",\n",
    "            \"PAB Event\": \"12890\",\n",
    "            \"Salute to Service\": \"12891\",\n",
    "            \"Student Engagement Event\": \"12892\",\n",
    "            \"Student Organization Event\": \"12893\",\n",
    "            \"Sun Devil Athletics\": \"12894\",\n",
    "            \"Sun Devil Civility\": \"12901\",\n",
    "            \"Sun Devil Fitness/Wellness\": \"12895\",\n",
    "            \"Sustainability\": \"12905\",\n",
    "            \"University Signature Event\": \"12904\",\n",
    "            \"W.P. Carey Event\": \"17553\"\n",
    "        }\n",
    "        \n",
    "        event_theme_ids = {\n",
    "            \"Arts\": \"arts\",\n",
    "            \"Athletics\": \"athletics\",\n",
    "            \"Community Service\": \"community_service\",\n",
    "            \"Cultural\": \"cultural\",\n",
    "            \"Fundraising\": \"fundraising\",\n",
    "            \"GroupBusiness\": \"group_business\",\n",
    "            \"Social\": \"social\",\n",
    "            \"Spirituality\": \"spirituality\",\n",
    "            \"ThoughtfulLearning\": \"thoughtful_learning\"\n",
    "        }\n",
    "        \n",
    "        event_perk_ids = {\n",
    "            \"Credit\": \"Credit\",\n",
    "            \"Free Food\": \"FreeFood\",\n",
    "            \"Free Stuff\": \"FreeStuff\"\n",
    "        }\n",
    "        \n",
    "        if event_campus:\n",
    "            campus_id_array = [event_campus_ids[campus] for campus in event_campus if campus in event_campus_ids]\n",
    "            if campus_id_array:\n",
    "                params.extend([f\"branches={campus_id}\" for campus_id in campus_id_array])\n",
    "        \n",
    "        if event_category:\n",
    "            category_id_array = [event_category_ids[category] for category in event_category if category in event_category_ids]\n",
    "            if category_id_array:\n",
    "                params.extend([f\"categories={category_id}\" for category_id in category_id_array])\n",
    "        \n",
    "        if event_theme:\n",
    "            theme_id_array = [event_theme_ids[theme] for theme in event_theme if theme in event_theme_ids]\n",
    "            if theme_id_array:\n",
    "                params.extend([f\"themes={theme_id}\" for theme_id in theme_id_array])\n",
    "        \n",
    "        if event_perk:\n",
    "            perk_id_array = [event_perk_ids[perk] for perk in event_perk if perk in event_perk_ids]\n",
    "            if perk_id_array:\n",
    "                params.extend([f\"perks={perk_id}\" for perk_id in perk_id_array])\n",
    "        \n",
    "        if shortcut_date:\n",
    "            valid_dates = [\"tomorrow\", \"this_weekend\"]\n",
    "            if shortcut_date.lower() in valid_dates:\n",
    "                params.append(f\"shortcutdate={shortcut_date.lower()}\")\n",
    "        \n",
    "        if search_bar_query:\n",
    "            params.append(f\"query={search_bar_query.lower().replace(' ', '%20')}\")\n",
    "        \n",
    "        if params:\n",
    "            search_url += \"?\" + \"&\".join(params)\n",
    "        \n",
    "        doc_title=\"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif event_category:\n",
    "            doc_title = \" \".join(event_category)\n",
    "        elif event_theme:\n",
    "            doc_title = \" \".join(event_theme)\n",
    "        elif event_campus:\n",
    "            doc_title = \" \".join(event_campus)\n",
    "        elif shortcut_date:\n",
    "            doc_title = shortcut_date\n",
    "        elif event_perk:\n",
    "            doc_title = \" \".join(event_perk)\n",
    "        else:\n",
    "            doc_title = None\n",
    "        \n",
    "        return await utils.perform_web_search(search_url, doc_title=doc_title, doc_category = \"events_info\")\n",
    "        \n",
    "    async def get_latest_news_updates(self, news_campus : list = None, search_bar_query: str = None,):\n",
    "        if not any([search_bar_query, news_campus]):\n",
    "            return \"At least one parameter of this function is required. Neither Search query and news campus received. Please provide at least one parameter to perform search.\"\n",
    "        \n",
    "        search_url = \"https://asu.campuslabs.com/engage/organizations\"\n",
    "        params = []\n",
    "        news_campus_ids = { \"ASU Downtown\":\"257211\",\"ASU Online\":\"257214\",\"ASU Polytechnic\":\"257212\",\"ASU Tempe\":\"254417\",\"ASU West Valley\":\"257213\",\"Fraternity & Sorority Life\":\"257216\",\"Housing & Residential Life\":\"257215\"}\n",
    "        doc_title=\"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif news_campus:\n",
    "            doc_title = \" \".join(news_campus)\n",
    "        else:\n",
    "            doc_title = None\n",
    "\n",
    "        if news_campus:\n",
    "            campus_id_array = [news_campus_ids[campus] for campus in news_campus if campus in news_campus_ids]\n",
    "            if campus_id_array:\n",
    "                params.extend([f\"branches={campus_id}\" for campus_id in campus_id_array])\n",
    "                \n",
    "        if search_bar_query:\n",
    "            params.append(f\"query={search_bar_query.lower().replace(' ', '%20')}\")\n",
    "        \n",
    "        if params:\n",
    "            search_url += \"?\" + \"&\".join(params)\n",
    "        \n",
    "        return await utils.perform_web_search(search_url,doc_title=doc_title, doc_category=\"news_info\")\n",
    "    \n",
    "    async def get_latest_social_media_updates(self,  account_name: list, search_bar_query: str = None,):\n",
    "        if not any([search_bar_query, account_name]):\n",
    "            return \"At least one parameter of this function is required. Neither Search query and news campus received. Please provide at least one parameter to perform search.\"\n",
    "        doc_title=\"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif account_name:\n",
    "            doc_title = \" \".join(account_name)\n",
    "        else:\n",
    "            doc_title = None\n",
    "        account_OBJECTs = {\n",
    "            \"@ArizonaState\": [\n",
    "                \"https://x.com/ASU\", \n",
    "                \"https://www.instagram.com/arizonastate\"\n",
    "            ],\n",
    "            \"@SunDevilAthletics\": [\n",
    "                \"https://x.com/TheSunDevils\", \n",
    "            ],\n",
    "            \"@SparkySunDevil\": [\n",
    "                \"https://x.com/SparkySunDevil\", \n",
    "                \"https://www.instagram.com/SparkySunDevil\"\n",
    "            ],\n",
    "            \"@ASUFootball\": [\n",
    "                \"https://x.com/ASUFootball\", \n",
    "                \"https://www.instagram.com/sundevilfb/\"\n",
    "            ],\n",
    "            \"@ASUFootball\": [\n",
    "                \"https://x.com/ASUFootball\", \n",
    "                \"https://www.instagram.com/sundevilfb/\"\n",
    "            ],\n",
    "        }\n",
    "        \n",
    "        # Collect URLs for specified account names\n",
    "        final_search_array = []\n",
    "        for name in account_name:\n",
    "            if name in account_OBJECTs:\n",
    "                final_search_array.extend(account_OBJECTs[name])\n",
    "        \n",
    "        # If no URLs found for specified accounts, return empty list\n",
    "        if not final_search_array:\n",
    "            return []\n",
    "        \n",
    "        # Perform web search on each URL asynchronously\n",
    "        search_results = []\n",
    "        for url in final_search_array:\n",
    "            search_result = await utils.perform_web_search(url,search_bar_query,doc_title=doc_title, doc_category=\"social_media_updates\")\n",
    "            search_results.extend(search_result)\n",
    "        return search_results\n",
    "    \n",
    "    async def get_latest_sport_updates(self, search_bar_query: str = None, sport: str = None, league: str = None, match_date: str = None):\n",
    "        \"\"\"\n",
    "        Comprehensive function to retrieve ASU sports updates using multiple data sources.\n",
    "        \n",
    "        Args:\n",
    "            query: General search query for sports updates\n",
    "            sport: Specific sport to search\n",
    "            league: Sports league\n",
    "            match_date: Specific match date\n",
    "        \n",
    "        \n",
    "        Returns:\n",
    "            List of sports updates or detailed information\n",
    "        \"\"\"\n",
    "        # Validate input parameters\n",
    "        if not any([search_bar_query, sport, league, match_date]):\n",
    "            return \"Please provide at least one parameter to perform the search.\"\n",
    "        \n",
    "        \n",
    "        dynamic_query = f\"ASU {sport if sport else ''} {search_bar_query if search_bar_query else ''} {league if league else ''} {match_date} site:(sundevils.com OR espn.com) -inurl:video\"\n",
    "        search_url=f\"https://www.google.com/search?q={urllib.parse.quote(dynamic_query)}\"\n",
    "         \n",
    "        \n",
    "        return await utils.perform_web_search(search_url)\n",
    "\n",
    "    async def get_library_resources(self, search_bar_query: str = None, resource_type: str = 'All Items'):\n",
    "        \"\"\"\n",
    "        Retrieve ASU Library resources using ASU Library Search with robust parameter handling.\n",
    "\n",
    "        Args:\n",
    "            search_bar_query (str, optional): Search term for library resources.\n",
    "            resource_type (str, optional): Type of resource to search. Defaults to 'All Items'.\n",
    "\n",
    "        Returns:\n",
    "            Union[str, dict]: Search results or error message.\n",
    "        \"\"\"\n",
    "        # Comprehensive input validation with improved error handling\n",
    "        if not search_bar_query:\n",
    "            return \"Error: Search query is required.\"\n",
    "        \n",
    "        # Use class-level constants for mappings to improve maintainability\n",
    "        RESOURCE_TYPE_MAPPING = {\n",
    "            'All Items': 'any', 'Books': 'books', 'Articles': 'articles', \n",
    "            'Journals': 'journals', 'Images': 'images', 'Scores': 'scores', \n",
    "            'Maps': 'maps', 'Sound recordings': 'audios', 'Video/Film': 'videos'\n",
    "        }\n",
    "        \n",
    "        # Validate resource type and language with more graceful handling\n",
    "        resource_type = resource_type if resource_type in RESOURCE_TYPE_MAPPING else 'All Items'\n",
    "        \n",
    "        # URL encode the search query to handle special characters\n",
    "        encoded_query = urllib.parse.quote(search_bar_query)\n",
    "        \n",
    "        # Construct search URL with more robust parameter handling\n",
    "        search_url = (\n",
    "            f\"https://search.lib.asu.edu/discovery/search\"\n",
    "            f\"?query=any,contains,{encoded_query}\"\n",
    "            f\",AND&pfilter=rtype,exact,{RESOURCE_TYPE_MAPPING[resource_type]}\"\n",
    "            \"&tab=LibraryCatalog\"\n",
    "            \"&search_scope=MyInstitution\"\n",
    "            \"&vid=01ASU_INST:01ASU\"\n",
    "            \"&lang=en\"\n",
    "            \"&mode=advanced\"\n",
    "            \"&offset=0\"\n",
    "        )\n",
    "        doc_title=\"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif resource_type:\n",
    "            doc_title = resource_type\n",
    "        else:\n",
    "            doc_title = None\n",
    "        try:\n",
    "            # Add error handling for web search\n",
    "            return await utils.perform_web_search(search_url,doc_title=doc_title, doc_category =\"library_resources\")\n",
    "        except Exception as e:\n",
    "            return f\"Error performing library search: {str(e)}\"\n",
    "        \n",
    "    async def get_latest_scholarships(self, search_bar_query: str = None, academic_level:str = None,eligible_applicants: str =None, citizenship_status: str = None, gpa: str = None, focus : str = None):\n",
    "    \n",
    "        if not any([search_bar_query, academic_level, citizenship_status, gpa,  eligible_applicants, focus]):\n",
    "            return \"Please provide at least one parameter to perform the search.\"\n",
    "        \n",
    "        results =[]\n",
    "        doc_title = \"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif academic_level:\n",
    "            doc_title = academic_level\n",
    "        elif citizenship_status:\n",
    "            doc_title = citizenship_status\n",
    "        # elif college:\n",
    "        #     doc_title = college\n",
    "        elif focus:\n",
    "            doc_title = focus\n",
    "        else:\n",
    "            doc_title = None\n",
    "            \n",
    "        \n",
    "        search_url = f\"https://goglobal.asu.edu/scholarship-search\"\n",
    "        \n",
    "        query = f\"academiclevel={academic_level}&citizenship_status={citizenship_status}&gpa={gpa}\"\n",
    "        # &college={college}\n",
    "        \n",
    "        result = await utils.perform_web_search(search_url,query, doc_title=doc_title, doc_category =\"scholarships_info\")\n",
    "        \n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        \n",
    "        search_url = f\"https://onsa.asu.edu/scholarships\"\n",
    "        \n",
    "        query = f\"search_bar_query={search_bar_query}&citizenship_status={citizenship_status}&eligible_applicants={eligible_applicants}&focus={focus}\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        result = await utils.perform_web_search(search_url,query, doc_title=doc_title,doc_category =\"scholarships_info\")\n",
    "        \n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "            \n",
    "        \n",
    "        return results\n",
    "       \n",
    "    async def get_latest_job_updates( self, search_bar_query: Optional[Union[str, List[str]]] = None, job_type: Optional[Union[str, List[str]]] = None, job_location: Optional[Union[str, List[str]]] = None):\n",
    "        \"\"\"\n",
    "        Comprehensive function to retrieve ASU Job updates using multiple data sources.\n",
    "        \n",
    "        Args:\n",
    "            Multiple search parameters for job filtering with support for both string and list inputs\n",
    "        \n",
    "        Returns:\n",
    "            List of search results\n",
    "        \"\"\"\n",
    "        # Helper function to normalize input to list\n",
    "        def normalize_to_list(value):\n",
    "            if value is None:\n",
    "                return None\n",
    "            return value if isinstance(value, list) else [value]\n",
    "        \n",
    "        # Normalize all inputs to lists\n",
    "        query_params = {\n",
    "            'search_bar_query': normalize_to_list(search_bar_query),\n",
    "            'job_type': normalize_to_list(job_type),\n",
    "            'job_location': normalize_to_list(job_location),\n",
    "        }\n",
    "        \n",
    "        # Remove None values\n",
    "        query_params = {k: v for k, v in query_params.items() if v is not None}\n",
    "        \n",
    "        # Validate that at least one parameter is provided\n",
    "        if not query_params:\n",
    "            return \"Please provide at least one parameter to perform the search.\"\n",
    "        \n",
    "        # Convert query parameters to URL query string\n",
    "        # Ensure each parameter is converted to a comma-separated string if it's a list\n",
    "        query_items = []\n",
    "        for k, v in query_params.items():\n",
    "            if isinstance(v, list):\n",
    "                query_items.append(f\"{k}={','.join(map(str, v))}\")\n",
    "            else:\n",
    "                query_items.append(f\"{k}={v}\")\n",
    "        \n",
    "        query = '&'.join(query_items)\n",
    "        \n",
    "        search_url = \"https://app.joinhandshake.com/stu/postings\"\n",
    "        \n",
    "        results = []\n",
    "        logger.info(f\"Requested search query : {query}\")\n",
    "        doc_title = \"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = \" \".join(search_bar_query) if isinstance(search_bar_query, list) else search_bar_query\n",
    "        elif job_type:\n",
    "            doc_title = \" \".join(job_type) if isinstance(job_type, list) else job_type\n",
    "        elif job_location:\n",
    "            doc_title = \" \".join(job_location) if isinstance(job_location, list) else job_location\n",
    "        else:\n",
    "            doc_title = None\n",
    "            \n",
    "        result = await utils.perform_web_search(search_url, query, doc_title=doc_title, doc_category =\"job_updates\")\n",
    "        results.append(result)\n",
    "        \n",
    "        return results       \n",
    "    \n",
    "    async def get_latest_class_information(self,search_bar_query: Optional[str] = None,class_term: Optional[str] = None,subject_name: Optional[Union[str, List[str]]] = None, \n",
    "    num_of_credit_units: Optional[Union[str, List[str]]] = None, \n",
    "    class_level: Optional[Union[str, List[str]]] = None,\n",
    "    class_session: Optional[Union[str, List[str]]] = None,\n",
    "    class_days: Optional[Union[str, List[str]]] = None,\n",
    "    class_location: Optional[Union[str, List[str]]] = None,\n",
    "    class_seat_availability : Optional[str] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Optimized function to generate a search URL for ASU class catalog with flexible input handling.\n",
    "        \n",
    "        Args:\n",
    "            Multiple optional parameters for filtering class search\n",
    "        \n",
    "        Returns:\n",
    "            Constructed search URL for class catalog\n",
    "        \"\"\"\n",
    "        \n",
    "        # Helper function to convert input to query string\n",
    "        \n",
    "        \n",
    "        \n",
    "        DAYS_MAP = {\n",
    "            'Monday': 'MON',\n",
    "            'Tuesday': 'TUES', \n",
    "            'Wednesday': 'WED', \n",
    "            'Thursday': 'THURS', \n",
    "            'Friday': 'FRI', \n",
    "            'Saturday': 'SAT', \n",
    "            'Sunday': 'SUN'\n",
    "        }\n",
    "        \n",
    "        \n",
    "        CLASS_LEVEL_MAP = {\n",
    "        'Lower division': 'lowerdivision',\n",
    "        'Upper division': 'upperdivision', \n",
    "        'Undergraduate': 'undergrad',\n",
    "        'Graduate': 'grad',\n",
    "        '100-199': '100-199',\n",
    "        '200-299': '200-299',\n",
    "        '300-399': '300-399',\n",
    "        '400-499': '400-499'\n",
    "        }\n",
    "        \n",
    "        SESSION_MAP = {\n",
    "            'A': 'A',\n",
    "            'B': 'B', \n",
    "            'C': 'C',\n",
    "            'Other': 'DYN'\n",
    "        }\n",
    "        \n",
    "       \n",
    "\n",
    "        TERM_MAP= {\n",
    "            'Spring 2025': '2251',\n",
    "            'Fall 2024': '2247', \n",
    "            'Summer 2024': '2244',\n",
    "            'Spring 2024': '2241',\n",
    "            'Fall 2023': '2237', \n",
    "            'Summer 2023': '2234'\n",
    "        }\n",
    "        \n",
    "        CREDIT_UNITS_MAP = {\n",
    "            '0': 'Less than 1',\n",
    "            '1': '1',\n",
    "            '2': '2',\n",
    "            '3': '3',\n",
    "            '4': '4',\n",
    "            '5': '5',\n",
    "            '6': '6',\n",
    "            '7': '7 or more'\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "        unmapped_items = []\n",
    "        \n",
    "        def _convert_to_query_string(input_value: Optional[Union[str, List[str]]], mapping: Dict[str, str]) -> str:\n",
    "            global unmapped_items\n",
    "            unmapped_items = []\n",
    "            \n",
    "            # Handle None input\n",
    "            if input_value is None:\n",
    "                return ''\n",
    "            \n",
    "            # Ensure input is a list\n",
    "            if isinstance(input_value, str):\n",
    "                input_value = [input_value]\n",
    "            \n",
    "            # Process each input value\n",
    "            mapped_values = []\n",
    "            for value in input_value:\n",
    "                # Check if value exists in mapping\n",
    "                if value in mapping:\n",
    "                    mapped_values.append(mapping[value])\n",
    "                else:\n",
    "                    # Add unmapped items to global list\n",
    "                    unmapped_items.append(value)\n",
    "            \n",
    "            # Join mapped values with URL-encoded comma\n",
    "            return '%2C'.join(mapped_values) if mapped_values else ''\n",
    "        \n",
    "        \n",
    "        \n",
    "        search_bar_query = (search_bar_query or '') + ' ' + ' '.join(unmapped_items)\n",
    "        search_bar_query+=subject_name\n",
    "        search_bar_query = search_bar_query.strip().replace(\" \", \"%20\")\n",
    "        \n",
    "        \n",
    "        params = {\n",
    "            'advanced': 'true',\n",
    "            'campus': _convert_to_query_string(class_location, LOCATION_MAP),\n",
    "            'campusOrOnlineSelection': 'A',\n",
    "            'daysOfWeek': _convert_to_query_string(class_days, DAYS_MAP),\n",
    "            'honors': 'F',\n",
    "            'keywords': search_bar_query,\n",
    "            'level': _convert_to_query_string(class_level, CLASS_LEVEL_MAP),\n",
    "            'promod': 'F',\n",
    "            'searchType': \"open\" if class_seat_availability == \"Open\" else \"all\",\n",
    "            'session': _convert_to_query_string(class_session, SESSION_MAP),\n",
    "            'term': _convert_to_query_string(class_term, TERM_MAP),\n",
    "            'units': _convert_to_query_string(num_of_credit_units, CREDIT_UNITS_MAP)\n",
    "        }\n",
    "        \n",
    "        logger.info(params)\n",
    "\n",
    "        # Remove None values and construct URL\n",
    "        search_url = 'https://catalog.apps.asu.edu/catalog/classes/classlist?' + '&'.join(\n",
    "            f'{key}={value}' \n",
    "            for key, value in params.items() \n",
    "            if value is not None and value != ''\n",
    "        )\n",
    "        \n",
    "        doc_title=\"\"\n",
    "        if search_bar_query:\n",
    "            doc_title = search_bar_query\n",
    "        elif subject_name:\n",
    "            doc_title = \" \".join(subject_name) if isinstance(subject_name, list) else subject_name\n",
    "        elif class_term:\n",
    "            doc_title = class_term\n",
    "        elif class_level:\n",
    "            doc_title = \" \".join(class_level) if isinstance(class_level, list) else class_level\n",
    "        elif class_location:\n",
    "            doc_title = \" \".join(class_location) if isinstance(class_location, list) else class_location\n",
    "        elif class_session:\n",
    "            doc_title = \" \".join(class_session) if isinstance(class_session, list) else class_session\n",
    "        elif num_of_credit_units:\n",
    "            doc_title = \" \".join(num_of_credit_units) if isinstance(num_of_credit_units, list) else num_of_credit_units\n",
    "        elif class_days:\n",
    "            doc_title = \" \".join(class_days) if isinstance(class_days, list) else class_days\n",
    "\n",
    "        elif class_seat_availability:\n",
    "            doc_title = class_seat_availability\n",
    "        else:\n",
    "            doc_title = None\n",
    "\n",
    "        return await utils.perform_web_search(search_url,doc_title=doc_title, doc_category =\"classes_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchModel:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 rate_limit_window: float = 1.0, \n",
    "                 max_requests: int = 100,\n",
    "                 retry_attempts: int = 3):\n",
    "        \"\"\"\n",
    "        Initialize SearchModel with advanced configuration options.\n",
    "        \n",
    "        Args:\n",
    "            rate_limit_window (float): Time window for rate limiting\n",
    "            max_requests (int): Maximum number of requests allowed in the window\n",
    "            retry_attempts (int): Number of retry attempts for function calls\n",
    "        \"\"\"\n",
    "        self.model = search_model\n",
    "        self.chat = None\n",
    "        self.functions = Search_Model_Functions()\n",
    "        self.last_request_time = time.time()\n",
    "        self.request_counter = 0\n",
    "        self.rate_limit_window = rate_limit_window\n",
    "        self.max_requests = max_requests\n",
    "        self.retry_attempts = retry_attempts\n",
    "        self.conversations: Dict[str, List[Dict[str, str]]] = {}\n",
    "        logger.info(f\"SearchModel initialized with rate limit: {rate_limit_window}s, max requests: {max_requests}\")\n",
    "\n",
    "    async def execute_function(self, function_call):\n",
    "        \"\"\"\n",
    "        Execute the called function with comprehensive error handling and retry mechanism.\n",
    "        \n",
    "        Args:\n",
    "            function_call: Function call OBJECT to execute\n",
    "        \n",
    "        Returns:\n",
    "            str: Processed function response\n",
    "        \"\"\"\n",
    "        function_name = function_call.name\n",
    "        function_args = function_call.args\n",
    "        \n",
    "        function_mapping = {\n",
    "            'get_latest_club_information': self.functions.get_latest_club_information,\n",
    "            'get_latest_event_updates': self.functions.get_latest_event_updates,\n",
    "            'get_latest_news_updates': self.functions.get_latest_news_updates,\n",
    "            'get_latest_social_media_updates': self.functions.get_latest_social_media_updates,\n",
    "            'get_latest_sport_updates': self.functions.get_latest_sport_updates,\n",
    "           'get_library_resources': self.functions.get_library_resources,\n",
    "              'get_latest_scholarships': self.functions.get_latest_scholarships,\n",
    "            'get_latest_job_updates': self.functions.get_latest_job_updates,\n",
    "            'get_latest_class_information': self.functions.get_latest_class_information\n",
    "        }\n",
    "        \n",
    "        if function_name not in function_mapping:\n",
    "            logger.error(f\"Unknown function: {function_name}\")\n",
    "            raise ValueError(f\"Unknown function: {function_name}\")\n",
    "        \n",
    "        function_to_call = function_mapping[function_name]\n",
    "        \n",
    "        for attempt in range(self.retry_attempts):\n",
    "            try:\n",
    "                func_response = await function_to_call(**function_args)\n",
    "                \n",
    "                logger.info(f\"Function '{function_name}' response (Attempt {attempt + 1}): {func_response}\")\n",
    "                \n",
    "                if func_response:\n",
    "                    return func_response\n",
    "                \n",
    "                logger.warning(f\"Empty response from {function_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Function call error (Attempt {attempt + 1}): {str(e)}\")\n",
    "                \n",
    "                if attempt == self.retry_attempts - 1:\n",
    "                    logger.critical(f\"All retry attempts failed for {function_name}\")\n",
    "                    return f\"Error processing {function_name}\"\n",
    "                \n",
    "                # Exponential backoff\n",
    "                await asyncio.sleep(2 ** attempt)\n",
    "        \n",
    "        return \"No valid response from function\"\n",
    "    \n",
    "    def _initialize_model(self):\n",
    "        \"\"\"\n",
    "        Initialize the search model with advanced rate limiting and error checking.\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            logger.critical(\"Model not initialized\")\n",
    "            raise RuntimeError(\"Search model is not configured\")\n",
    "        \n",
    "        current_time = time.time()\n",
    "        \n",
    "        if current_time - self.last_request_time < self.rate_limit_window:\n",
    "            self.request_counter += 1\n",
    "            if self.request_counter > self.max_requests:\n",
    "                wait_time = self.rate_limit_window - (current_time - self.last_request_time)\n",
    "                logger.warning(f\"Rate limit exceeded. Waiting {wait_time:.2f} seconds\")\n",
    "                raise Exception(f\"Rate limit exceeded. Please wait {wait_time:.2f} seconds\")\n",
    "        else:\n",
    "            # Reset counter if outside the rate limit window\n",
    "            self.request_counter = 1\n",
    "            self.last_request_time = current_time\n",
    "        \n",
    "        try:\n",
    "            user_id = discord_state.get('user_id')\n",
    "            self.chat = self.model.start_chat(history=self._get_chat_history(user_id),enable_automatic_function_calling=True)\n",
    "            logger.info(\"\\nSearch model chat session initialized successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to initialize chat session: {str(e)}\")\n",
    "            raise RuntimeError(\"Could not start chat session\")\n",
    "        \n",
    "    def _get_chat_history(self, user_id: str) -> List[Dict[str, str]]:\n",
    "        return self.conversations.get(user_id, [])\n",
    "\n",
    "    def _save_message(self, user_id: str, role: str, content: str):\n",
    "        if user_id not in self.conversations:\n",
    "            self.conversations[user_id] = []\n",
    "        \n",
    "        self.conversations[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": content}]\n",
    "        })\n",
    "        \n",
    "        # Limit the conversation length to 3 messages per user\n",
    "        if len(self.conversations[user_id]) > 3:\n",
    "            self.conversations[user_id].pop(0)\n",
    "\n",
    "        \n",
    "    async def determine_action(self, query: str,special_instructions:str) -> str:\n",
    "        \"\"\"\n",
    "        Advanced query processing with comprehensive error handling and logging.\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query to process\n",
    "        \n",
    "        Returns:\n",
    "            str: Processed query response\n",
    "        \"\"\"\n",
    "        try:\n",
    "            user_id = discord_state.get(\"user_id\")\n",
    "            self._initialize_model()\n",
    "            final_response = \"\"\n",
    "            self._save_message(user_id, \"user\", query)\n",
    "            action_command = query\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "             ### Context:\n",
    "                - Current Date and Time: {datetime.now().strftime('%H:%M %d') + ('th' if 11<=int(datetime.now().strftime('%d'))<=13 else {1:'st',2:'nd',3:'rd'}.get(int(datetime.now().strftime('%d'))%10,'th')) + datetime.now().strftime(' %B, %Y') }\n",
    "                - Superior Agent Instruction: {action_command}\n",
    "                - Superior Agent Remarks: {special_instructions}\n",
    "                {app_config.get_search_agent_prompt()}\n",
    "                \n",
    "                \"\"\"\n",
    "                \n",
    "            logger.debug(f\"Generated prompt: {prompt}\")\n",
    "            \n",
    "            try:\n",
    "                response = await self.chat.send_message_async(prompt)\n",
    "                logger.info(self._get_chat_history)\n",
    "                self._save_message(user_id, \"model\", f\"{response.parts}\" )\n",
    "                for part in response.parts:\n",
    "                    if hasattr(part, 'function_call') and part.function_call: \n",
    "                        final_response = await self.execute_function(part.function_call)\n",
    "                        firestore.update_message(\"search_agent_message\", f\"Function called {part.function_call}\\n Function Response {final_response} \")\n",
    "                    elif hasattr(part, 'text') and part.text.strip():\n",
    "                        text = part.text.strip()\n",
    "                        firestore.update_message(\"search_agent_message\", f\"Text Response : {text} \")\n",
    "                        if not text.startswith(\"This query\") and \"can be answered directly\" not in text:\n",
    "                            final_response = text.strip()\n",
    "            \n",
    "            except Exception as response_error:\n",
    "                logger.error(f\"Response generation error: {str(response_error)}\")\n",
    "                final_response = \"Unable to generate a complete response\"\n",
    "            \n",
    "            return final_response or \"Search agent encountered an unexpected issue\"\n",
    "        \n",
    "        except Exception as critical_error:\n",
    "            logger.critical(f\"Critical error in determine_action: {str(critical_error)}\")\n",
    "            return \"I'm experiencing technical difficulties. Please try again later.\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 0.1,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 2500,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    },\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    },\n",
    "    system_instruction = f\"\"\"\n",
    "    {app_config.get_search_agent_instruction()}\n",
    "    \"\"\",\n",
    "\n",
    "    tools=[\n",
    "        genai.protos.Tool(\n",
    "            function_declarations=[\n",
    "            \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_club_information\",\n",
    "                    description=\"Searches for clubs or organizations information with Sun Devil Search Engine\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Search Query\",\n",
    "                            ),\n",
    "                            \"organization_campus\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                ),\n",
    "                                description=\"Club/Organization campus pick from [ASU Downtown, ASU Online, ASU Polytechnic, ASU Tempe, ASU West Valley, Fraternity & Sorority Life, Housing & Residential Life]\"\n",
    "                            ),\n",
    "                            \"organization_category\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                ),\n",
    "                                description=\"Club/Organization Category, pick from [Academic, Barrett, Creative/Performing Arts, Cultural/Ethnic, Distinguished Student Organization, Fulton Organizations, Graduate, Health/Wellness, International, LGBTQIA+, Political, Professional, Religious/Faith/Spiritual, Service, Social Awareness, Special Interest, Sports/Recreation, Sustainability, Technology, Veteran Groups, W.P. Carey Organizations, Women]\"\n",
    "                            ),\n",
    "                        },\n",
    "                            required=[\"search_bar_query\", \"organization_category\"]\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_event_updates\",\n",
    "                    description=\"Searches for events information with Sun Devil Search Engine\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Search Query\"\n",
    "                            ),\n",
    "                            \"event_campus\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                ),\n",
    "                                description=\"Event campus pick from [ASU Downtown, ASU Online, ASU Polytechnic, ASU Tempe, ASU West Valley, Fraternity & Sorority Life, Housing & Residential Life]\"\n",
    "                            ),\n",
    "                            \"event_category\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                ),\n",
    "                                description=\"Event Category, pick from [ASU New Student Experience, ASU Sync, ASU Welcome Event, Barrett Student Organization, Career and Professional Development, Club Meetings, Community Service, Cultural, DeStress Fest, Entrepreneurship & Innovation, Graduate, International, Social, Sports/Recreation, Sustainability]\"\n",
    "                            ),\n",
    "                            \"event_theme\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                ),\n",
    "                                description=\"Event Theme, pick from [Arts, Athletics, Community Service, Cultural, Fundraising, GroupBusiness, Social, Spirituality, ThoughtfulLearning]\"\n",
    "                            ),\n",
    "                            \"event_perk\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                ),\n",
    "                                description=\"Event Perk, pick from [Credit, Free Food, Free Stuff]\"\n",
    "                            ),\n",
    "                            \"shortcut_date\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Event Shortcut date, pick from [tomorrow, this_weekend]\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required=[\"search_bar_query\", \"event_category\"]\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_news_updates\",\n",
    "                    description=\"Searches for news information with Sun Devil Search Engine\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Search query\"\n",
    "                            ),\n",
    "                            \"news_campus\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"News Campus\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required=[\"search_bar_query\"]\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_sport_updates\",\n",
    "                    description=\"Fetches comprehensive sports information for Arizona State University across various sports and leagues.\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"search query to filter sports information\"\n",
    "                            ),\n",
    "                            \"sport\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Specific sport to search (e.g., 'football', 'basketball', 'baseball', 'soccer')\",\n",
    "                                enum=[\n",
    "                                    \"football\", \"basketball\", \"baseball\", \n",
    "                                    \"soccer\", \"volleyball\", \"softball\", \n",
    "                                    \"hockey\", \"tennis\", \"track and field\"\n",
    "                                ]\n",
    "                            ),\n",
    "                            \"league\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"League for the sport (NCAA, Pac-12, etc.)\",\n",
    "                                enum=[\"NCAA\", \"Pac-12\", \"Big 12\", \"Mountain West\"]\n",
    "                            ),\n",
    "                            \"match_date\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Specific match date in YYYY-MM-DD format\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required=[\"search_bar_query\",\"sport\"]\n",
    "                    )\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_social_media_updates\",\n",
    "                    description=\"Searches for ASU social media posts from specified accounts\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Optional search query to filter social media posts\"\n",
    "                            ),\n",
    "                            \"account_name\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"@ArizonaState\", \n",
    "                                        \"@SunDevilAthletics\", \n",
    "                                        \"@SparkySunDevil\", \n",
    "                                        \"@SunDevilFootball\", \n",
    "                                        \"@ASUFootball\", \n",
    "                                        \"@SunDevilFB\"\n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of ASU social media account names to search\"\n",
    "                            )\n",
    "                        },\n",
    "                        required=[\"account_name\"]\n",
    "                    )\n",
    "                ),\n",
    "                \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_library_resources\",\n",
    "                    description=\"Searches for Books, Articles, Journals, Etc Within ASU Library\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"search query to filter resources\"\n",
    "                            ),\n",
    "                           \n",
    "                            \"resource_type\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Pick Resource Type from the List\",\n",
    "                                enum=[\n",
    "                                    \"All Items\",\n",
    "                                    \"Books\",\n",
    "                                    \"Articles\",\n",
    "                                    \"Journals\",\n",
    "                                    \"Images\",\n",
    "                                    \"Scores\",\n",
    "                                    \"Maps\",\n",
    "                                    \"Sound recordings\",\n",
    "                                    \"Video/Film\",\n",
    "                                ]\n",
    "                            ),\n",
    "                         \n",
    "                        },\n",
    "                        required = [\"search_bar_query\", \"resource_type\"],\n",
    "                    )\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_scholarships\",\n",
    "                    description=\"Fetches comprehensive scholarship information for Arizona State University across various programs.\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"General search terms for scholarships\"\n",
    "                            ),\n",
    "                            \"academic_level\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Academic level of the student\",\n",
    "                                enum=[\n",
    "                                    \"Graduate\",\n",
    "                                    \"Undergraduate\"\n",
    "                                ]\n",
    "                            ),\n",
    "                            \"citizenship_status\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Citizenship status of the applicant\",\n",
    "                                enum=[\n",
    "                                    \"US Citizen\",\n",
    "                                    \"US Permanent Resident\", \n",
    "                                    \"DACA/Dreamer\",\n",
    "                                    \"International Student (non-US citizen)\"\n",
    "                                ]\n",
    "                            ),\n",
    "                            \"gpa\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Student's GPA range\",\n",
    "                                enum=[\n",
    "                                    \"2.0 – 2.24\",\n",
    "                                    \"2.25 – 2.49\",\n",
    "                                    \"2.50 – 2.74\", \n",
    "                                    \"2.75 - 2.99\",\n",
    "                                    \"3.00 - 3.24\",\n",
    "                                    \"3.25 - 3.49\", \n",
    "                                    \"3.50 - 3.74\",\n",
    "                                    \"3.75 - 3.99\",\n",
    "                                    \"4.00\"\n",
    "                                ]\n",
    "                            ),\n",
    "                           \n",
    "                            \"eligible_applicants\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Student academic standing\",\n",
    "                                enum=[\n",
    "                                    \"First-year Undergrads\",\n",
    "                                    \"Second-year Undergrads\", \n",
    "                                    \"Third-year Undergrads\",\n",
    "                                    \"Fourth-year+ Undergrads\",\n",
    "                                    \"Graduate Students\",\n",
    "                                    \"Undergraduate Alumni\",\n",
    "                                    \"Graduate Alumni\"\n",
    "                                ]\n",
    "                            ),\n",
    "                            \"focus\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Scholarship focus area\",\n",
    "                                enum=[\n",
    "                                    \"STEM\",\n",
    "                                    \"Business and Entrepreneurship\",\n",
    "                                    \"Creative and Performing Arts\",\n",
    "                                    \"Environment and Sustainability\",\n",
    "                                    \"Health and Medicine\",\n",
    "                                    \"Social Science\",\n",
    "                                    \"International Affairs\",\n",
    "                                    \"Public Policy\",\n",
    "                                    \"Social Justice\",\n",
    "                                    \"Journalism and Media\",\n",
    "                                    \"Humanities\"\n",
    "                                ]\n",
    "                            ),\n",
    "                              # \"college\": content.Schema(\n",
    "                        #         type=content.Type.STRING,\n",
    "                        #         description=\"ASU College or School\",\n",
    "                        #         enum=[\n",
    "                        #             \"Applied Arts and Sciences, School of\",\n",
    "                        #             \"Business, W. P. Carey School of\",\n",
    "                        #             \"Design & the Arts, Herberger Institute for\",\n",
    "                        #             \"Education, Mary Lou Fulton Institute and Graduate School of\",\n",
    "                        #             \"Engineering, Ira A. Fulton Schools of\",\n",
    "                        #             \"Future of Innovation in Society, School for the\",\n",
    "                        #             \"Global Management, Thunderbird School of\",\n",
    "                        #             \"Graduate College\",\n",
    "                        #             \"Health Solutions, College of\",\n",
    "                        #             \"Human Services, College of\",\n",
    "                        #             \"Integrative Sciences and Arts, College of\",\n",
    "                        #             \"Interdisciplinary Arts & Sciences, New College of\",\n",
    "                        #             \"Journalism & Mass Communication, Walter Cronkite School of\",\n",
    "                        #             \"Law, Sandra Day O'Connor College of\",\n",
    "                        #             \"Liberal Arts and Sciences, The College of\",\n",
    "                        #             \"Nursing and Health Innovation, Edson College of\",\n",
    "                        #             \"Public Service and Community Solutions, Watts College of\",\n",
    "                        #             \"Sustainability, School of\",\n",
    "                        #             \"Teachers College, Mary Lou Fulton\",\n",
    "                        #             \"University College\"\n",
    "                        #         ]\n",
    "                        #     ),\n",
    "                        }, \n",
    "                    )\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_job_updates\",\n",
    "                    description=\"Searches for jobs from ASU Handshake\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Optional search query to filter jobs\"\n",
    "                            ),\n",
    "                            \"job_type\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"Full-Time\", \n",
    "                                        \"Part-Time\", \n",
    "                                        \"Internship\", \n",
    "                                        \"On-Campus\"\n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of Job Types to search\"\n",
    "                            ),\n",
    "                            \"job_location\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"Tempe, Arizona, United States\",\n",
    "\n",
    "                                        \"Mesa, Arizona, United States\",\n",
    "\n",
    "                                        \"Phoenix, Arizona, United States\",\n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of ASU Locations to search\"\n",
    "                            ),\n",
    "                        },\n",
    "                        \n",
    "                    )\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_latest_class_information\",\n",
    "                    description=\"Searches for ASU Classes information indepth with ASU Catalog Search\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"search_bar_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\" search query to filter classes\"\n",
    "                            ),\n",
    "                           \n",
    "                            \"class_seat_availability\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Class Availability : Open | All\",\n",
    "                                enum=[\n",
    "                                    \"Open\",\n",
    "                                    \"All\"\n",
    "                                ]\n",
    "                            ),\n",
    "                            \"class_term\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Pick from this list for Class Term\",\n",
    "                                enum=[\n",
    "                                \"Fall 2026\",\n",
    "                                \"Summer 2026\",\n",
    "                                \"Spring 2026\",\n",
    "                                \"Fall 2025\",\n",
    "                                \"Summer 2025\",\n",
    "                                \"Spring 2025\",\n",
    "                                ]\n",
    "\n",
    "                            ),\n",
    "                            \"subject_name\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"\"\"Class/Course Name \"\"\",\n",
    "                                \n",
    "                            ),\n",
    "                            \n",
    "                            \"num_of_credit_units\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"1\", \n",
    "                                        \"2\", \n",
    "                                        \"3\", \n",
    "                                        \"4\", \n",
    "                                        \"5\", \n",
    "                                        \"6\",\n",
    "                                        \"7\",\n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of Class Credits\"\n",
    "                            ),\n",
    "                            \"class_session\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"A\", \n",
    "                                        \"B\", \n",
    "                                        \"C\", \n",
    "                                        \"Other\", \n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of Class Sessions\"\n",
    "                            ),\n",
    "                            \"class_days\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"Monday\", \n",
    "                                        \"Tuesday\", \n",
    "                                        \"Wednesday\", \n",
    "                                        \"Thursday\", \n",
    "                                        \"Friday\", \n",
    "                                        \"Saturday\", \n",
    "                                        \"Sunday\", \n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of Class Sessions\"\n",
    "                            ),\n",
    "                            \"class_location\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"TEMPE\",\n",
    "                                        \"WEST\",\n",
    "                                        \"POLY\",\n",
    "                                        \"OFFCAMP\",\n",
    "                                        \"PHOENIX\",\n",
    "                                        \"LOSANGELES\",\n",
    "                                        \"CALHC\",\n",
    "                                        \"ASUSYNC\",\n",
    "                                        \"ASUONLINE\",\n",
    "                                        \"ICOURSE\"\n",
    "                                        ]\n",
    "                                ),\n",
    "                                description=\"Pick from the List of Class Locations\"\n",
    "                            ),\n",
    "                          \n",
    "                        },\n",
    "                            \n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    tool_config={'function_calling_config': 'AUTO'},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_search_agent = SearchModel()\n",
    "logger.info(\"\\nInitialized SearchModel Instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discord Model\n",
    "\n",
    "The `DiscordModel` class is designed to handle Discord-specific interactions and commands using Google's Generative AI model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Initialization\n",
    "- Initializes with a `discordmodel`, functions (`DiscordModelFunctions`), and conversation tracking.\n",
    "- Implements rate limiting and request counting.\n",
    "\n",
    "#### Model Configuration\n",
    "- Uses the \"gemini-1.5-flash\" model with specific generation config settings.\n",
    "- Implements safety settings to block low and above levels of hate speech and harassment.\n",
    "\n",
    "#### Function Declarations\n",
    "- Defines various function declarations for Discord-specific actions:\n",
    "  - Notifying moderators and helpers\n",
    "  - Creating forum posts and events\n",
    "  - Sending bot feedback\n",
    "  - Accessing server information\n",
    "\n",
    "#### Discord Interactions\n",
    "- `handle_discord_server_info`: Provides information about the Sparky Discord Server and Bot.\n",
    "- `access_live_status_agent`: Interfaces with a live status agent for real-time information.\n",
    "- `send_bot_feedback`: Handles user feedback about the bot.\n",
    "\n",
    "#### Conversation Management\n",
    "- Implements methods to save and retrieve chat history for users.\n",
    "- Manages conversations in a dictionary format.\n",
    "\n",
    "#### Action Determination\n",
    "- `determine_action` method processes user queries and special instructions.\n",
    "- Constructs prompts with current context, user query, and agent instructions.\n",
    "- Handles both text responses and function calls from the model.\n",
    "\n",
    "#### Rate Limiting\n",
    "- Implements a sophisticated rate limiting system to prevent excessive requests.\n",
    "\n",
    "#### Error Handling\n",
    "- Comprehensive error logging throughout the class.\n",
    "- Fallback responses for various error scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discord_Model_Functions:\n",
    "    def __init__(self):\n",
    "        self.discord_client = discord_state.get('discord_client')\n",
    "        logger.info(f\"Initialized Discord Client : {self.discord_client}\")\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        self.user_id=discord_state.get('user_id')\n",
    "        self.user=discord_state.get('user')\n",
    "        logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "     \n",
    "    async def notify_discord_helpers(self, short_message_to_helper: str) -> str:\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        self.user_id=discord_state.get('user_id')\n",
    "        self.user=discord_state.get('user')\n",
    "        logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "\n",
    "        if not request_in_dm:\n",
    "            return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "        await utils.update_text(\"Checking available discord helpers...\")\n",
    "\n",
    "        logger.info(\"Contact Model: Handling contact request for helper notification\")\n",
    "\n",
    "        try:\n",
    "\n",
    "            if not self.guild:\n",
    "                return \"Unable to find the server. Please try again later.\"\n",
    "\n",
    "            # Check if user is already connected to a helper\n",
    "            existing_channel = discord.utils.get(self.guild.channels, name=f\"help-{self.user_id}\")\n",
    "            if existing_channel:\n",
    "                utils.update_ground_sources([existing_channel.jump_url])\n",
    "                return f\"User already has an open help channel.\"\n",
    "\n",
    "            # Find helpers\n",
    "            helper_role = discord.utils.get(self.guild.roles, name=\"Helper\")\n",
    "            if not helper_role:\n",
    "                return \"Unable to find helpers. Please contact an administrator.\"\n",
    "\n",
    "            helpers = [member for member in self.guild.members if helper_role in member.roles and member.status != discord.Status.offline]\n",
    "            if not helpers:\n",
    "                return \"No helpers are currently available. Please try again later.\"\n",
    "\n",
    "            # Randomly select a helper\n",
    "            selected_helper = random.choice(helpers)\n",
    "\n",
    "            # Create a private channel\n",
    "            overwrites = {\n",
    "                self.guild.default_role: discord.PermissionOverwrite(read_messages=False),\n",
    "                user: discord.PermissionOverwrite(read_messages=True, send_messages=True),\n",
    "                selected_helper: discord.PermissionOverwrite(read_messages=True, send_messages=True)\n",
    "            }\n",
    "            \n",
    "            category = discord.utils.get(self.guild.categories, name=\"Customer Service\")\n",
    "            if not category:\n",
    "                return \"Unable to find the Customer Service category. Please contact an administrator.\"\n",
    "\n",
    "            channel = await self.guild.create_text_channel(f\"help-{self.user_id}\", category=category, overwrites=overwrites)\n",
    "\n",
    "            # Send messages\n",
    "            await channel.send(f\"{user.mention} and {selected_helper.mention}, this is your help channel.\")\n",
    "            await channel.send(f\"User's message: {short_message_to_helper}\")\n",
    "\n",
    "            # Notify the helper via DM\n",
    "            await selected_helper.send(f\"You've been assigned to a new help request. Please check {channel.mention}\")\n",
    "            utils.update_ground_sources([channel.jump_url])\n",
    "            return f\"Server Helper Assigned: {selected_helper.name}\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error notifying helpers: {str(e)}\")\n",
    "            return f\"An error occurred while notifying helpers: {str(e)}\"\n",
    "\n",
    "    async def notify_moderators(self, short_message_to_moderator: str) -> str:\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        self.user_id=discord_state.get('user_id')\n",
    "        self.user=discord_state.get('user')\n",
    "        \n",
    "        logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "\n",
    "\n",
    "        if not discord_state.get('request_in_dm'):\n",
    "            return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "        await utils.update_text(\"Checking available discord moderators...\")\n",
    "\n",
    "        logger.info(\"Contact Model: Handling contact request for moderator notification\")\n",
    "\n",
    "        try:\n",
    "            if not self.guild:\n",
    "                return \"Unable to find the server. Please try again later.\"\n",
    "\n",
    "            # Check if user is already connected to a helper\n",
    "            existing_channel = discord.utils.get(self.guild.channels, name=f\"support-{self.user_id}\")\n",
    "            if existing_channel:\n",
    "                utils.update_ground_sources([existing_channel.jump_url])\n",
    "                return f\"User already has an open support channel.\"\n",
    "            # Find helpers/moderators\n",
    "            helper_role = discord.utils.get(self.guild.roles, name=\"mod\")\n",
    "            if not helper_role:\n",
    "                return \"Unable to find helpers. Please contact an administrator.\"\n",
    "\n",
    "            helpers = [member for member in self.guild.members if helper_role in member.roles]\n",
    "            if not helpers:\n",
    "                return \"No helpers are currently available. Please try again later.\"\n",
    "\n",
    "            # Randomly select a helper\n",
    "            selected_helper = random.choice(helpers)\n",
    "\n",
    "            # Create a private channel\n",
    "            overwrites = {\n",
    "                self.guild.default_role: discord.PermissionOverwrite(read_messages=False),\n",
    "                self.user: discord.PermissionOverwrite(read_messages=True, send_messages=True),\n",
    "                selected_helper: discord.PermissionOverwrite(read_messages=True, send_messages=True)\n",
    "            }\n",
    "            \n",
    "            category = discord.utils.get(self.guild.categories, name=\"Customer Service\")\n",
    "            if not category:\n",
    "                return \"Unable to find the Customer Service category. Please contact an administrator.\"\n",
    "\n",
    "            channel = await self.guild.create_text_channel(f\"support-{self.user_id}\", category=category, overwrites=overwrites)\n",
    "\n",
    "            # Send messages\n",
    "            await channel.send(f\"{self.user.mention} and {selected_helper.mention}, this is your support channel.\")\n",
    "            await channel.send(f\"User's message: {short_message_to_moderator}\")\n",
    "\n",
    "            # Notify the helper via DM\n",
    "            await selected_helper.send(f\"You've been assigned to a new support request. Please check {channel.mention}\")\n",
    "            utils.update_ground_sources([channel.jump_url])\n",
    "            return f\"Moderator Assigned: {selected_helper.name}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error notifying moderators: {str(e)}\")\n",
    "            return f\"An error occurred while notifying moderators: {str(e)}\"\n",
    "\n",
    "    # async def start_recording_discord_call(self,channel_id:Any) -> str: \n",
    "\n",
    "        \n",
    "    #     logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "    #     await utils.update_text(\"Checking user permissions...\")\n",
    "       \n",
    "    #     if not discord_state.get('user_has_mod_role'):\n",
    "    #         return \"User does not have enough permissions to start recording a call. This command is only accessible by moderators. Exiting command...\"\n",
    "\n",
    "    #     if not discord_state.get('request_in_dm'):\n",
    "    #         return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "    #     if not discord_state.get('user_voice_channel_id'):\n",
    "    #         return \"User is not in a voice channel. User needs to be in a voice channel to start recording. Exiting command...\"\n",
    "\n",
    "    #     logger.info(\"Discord Model: Handling recording request\")\n",
    "\n",
    "    #     return f\"Recording started!\"\n",
    "\n",
    "    async def create_discord_forum_post(self, title: str, category: str, body_content_1: str, body_content_2: str, body_content_3: str, link:str=None) -> str:\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        \n",
    "        logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "        await utils.update_text(\"Checking user permissions...\")\n",
    "\n",
    "\n",
    "        if not discord_state.get('request_in_dm'):\n",
    "            return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "        logger.info(\"Discord Model: Handling discord forum request with context\")\n",
    "\n",
    "        try:\n",
    "            if not self.guild:\n",
    "                return \"Unable to find the server. Please try again later.\"\n",
    "            try:\n",
    "                \n",
    "                # Find the forum channel \n",
    "                forum_channel = discord.utils.get(self.guild.forums, name='qna')  # Replace with your forum channel name\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error finding forum channel: {str(e)}\")\n",
    "                return f\"An error occurred while finding the forum channel: {str(e)}\"\n",
    "            if not forum_channel:\n",
    "                return \"Forum channel not found. Please ensure the forum exists.\"\n",
    "\n",
    "            # Create the forum post\n",
    "            content = f\"{body_content_1}\\n\\n{body_content_2}\\n\\n{body_content_3}\".strip()\n",
    "            if link:\n",
    "                content+=f\"\\n[Link]({link})\"\n",
    "            try:\n",
    "                logger.info(f\"Forum channel ID: {forum_channel.id if forum_channel else 'None'}\")\n",
    "                \n",
    "                thread = await forum_channel.create_thread(\n",
    "                    name=title,\n",
    "                    content=content,\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                \n",
    "                logger.error(f\"Error creating forum thread: {str(e)}\")\n",
    "                return f\"An error occurred while creating the forum thread: {str(e)}\"\n",
    "            logger.info(f\"Created forum thread {thread.message.id} {type(thread)}\")\n",
    "            \n",
    "            utils.update_ground_sources([f\"https://discord.com/channels/1256076931166769152/{thread.id}\"])\n",
    "            return f\"Forum post created successfully.\\nTitle: {title}\\nDescription: {content[:100]}...\\n\"\n",
    "        \n",
    "\n",
    "        except discord.errors.Forbidden:\n",
    "            return \"The bot doesn't have permission to create forum posts. Please contact an administrator.\"\n",
    "        except discord.errors.HTTPException as e:\n",
    "            logger.error(f\"HTTP error creating forum post: {str(e)}\")\n",
    "            return f\"An error occurred while creating the forum post: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating forum post: {str(e)}\")\n",
    "            return f\"An unexpected error occurred while creating the forum post: {str(e)}\"\n",
    "    \n",
    "    async def create_discord_announcement(self, ping: str, title: str, category: str, body_content_1: str, body_content_2: str, body_content_3: str, link:str = None) -> str:\n",
    "        self.discord_client = discord_state.get('discord_client')\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        \n",
    "        await utils.update_text(\"Checking user permissions...\")\n",
    "\n",
    "\n",
    "        logger.info(f\"Discord Model: Handling discord announcement request with context\")\n",
    "\n",
    "        if not discord_state.get('request_in_dm'):\n",
    "            return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "        if not discord_state.get('user_has_mod_role'):\n",
    "            return \"User does not have enough permissions to create an announcement. This command is only accessible by moderators. Exiting command...\"\n",
    "\n",
    "        try:\n",
    "            # Find the announcements channel\n",
    "            announcements_channel = discord.utils.get(self.discord_client.get_all_channels(), name='announcements')\n",
    "            if not announcements_channel:\n",
    "                return \"Announcements channel not found. Please ensure the channel exists.\"\n",
    "\n",
    "            # Create the embed\n",
    "            embed = discord.Embed(title=title, color=discord.Color.blue())\n",
    "            embed.add_field(name=\"Category\", value=category, inline=False)\n",
    "            embed.add_field(name=\"Details\", value=body_content_1, inline=False)\n",
    "            if body_content_2:\n",
    "                embed.add_field(name=\"Additional Information\", value=body_content_2, inline=False)\n",
    "            if body_content_3:\n",
    "                embed.add_field(name=\"More Details\", value=body_content_3, inline=False)\n",
    "            if link:\n",
    "                embed.add_field(name=\"Links\", value=link, inline=False)\n",
    "\n",
    "            # Send the announcement\n",
    "            message = await announcements_channel.send(content=\"@som\", embed=embed)\n",
    "            utils.update_ground_sources([message.jump_url])\n",
    "            return f\"Announcement created successfully.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating announcement: {str(e)}\")\n",
    "            return f\"An error occurred while creating the announcement: {str(e)}\"\n",
    "  \n",
    "    async def create_discord_event(self, title: str, time_start: str, time_end: str, description: str, img_provided: Any = None) -> str:\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        \n",
    "        logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "        await utils.update_text(\"Checking user permissions...\")\n",
    "\n",
    "\n",
    "        if not discord_state.get('request_in_dm'):\n",
    "            return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "        if not discord_state.get('user_has_mod_role'):\n",
    "            return \"User does not have enough permissions to create an event. This command is only accessible by moderators. Exiting command...\"\n",
    "\n",
    "        logger.info(\"Discord Model: Handling discord event creation request\")\n",
    "\n",
    "        try:\n",
    "            if self.guild:\n",
    "                return \"Unable to find the server. Please try again later.\"\n",
    "\n",
    "            # Parse start and end times\n",
    "            start_time = datetime.fromisoformat(time_start)\n",
    "            end_time = datetime.fromisoformat(time_end)\n",
    "\n",
    "            # Create the event\n",
    "            event = await self.guild.create_scheduled_event(\n",
    "                name=title,\n",
    "                description=description,\n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                location=\"Discord\",  # or specify a different location if needed\n",
    "                privacy_level=discord.PrivacyLevel.guild_only\n",
    "            )\n",
    "\n",
    "            # If an image was provided, set it as the event cover\n",
    "            if img_provided:\n",
    "                await event.edit(image=img_provided)\n",
    "\n",
    "            # Create an embed for the event announcement\n",
    "            embed = discord.Embed(title=title, description=description, color=discord.Color.blue())\n",
    "            embed.add_field(name=\"Start Time\", value=start_time.strftime(\"%Y-%m-%d %H:%M:%S\"), inline=True)\n",
    "            embed.add_field(name=\"End Time\", value=end_time.strftime(\"%Y-%m-%d %H:%M:%S\"), inline=True)\n",
    "            embed.add_field(name=\"Location\", value=\"Discord\", inline=False)\n",
    "            embed.set_footer(text=f\"Event ID: {event.id}\")\n",
    "\n",
    "            # Send the announcement to the announcements channel\n",
    "            announcements_channel = discord.utils.get(self.guild.text_channels, name=\"announcements\")\n",
    "            if announcements_channel:\n",
    "                await announcements_channel.send(embed=embed)\n",
    "            \n",
    "            utils.update_ground_sources([event.url])\n",
    "\n",
    "            return f\"Event created successfully.\\nTitle: {title}\\nDescription: {description[:100]}...\\nStart Time: {start_time}\\nEnd Time: {end_time}\\n\"\n",
    "\n",
    "        except discord.errors.Forbidden:\n",
    "            return \"The bot doesn't have permission to create events. Please contact an administrator.\"\n",
    "        except ValueError as e:\n",
    "            return f\"Invalid date format: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating event: {str(e)}\")\n",
    "            return f\"An unexpected error occurred while creating the event: {str(e)}\"\n",
    "    \n",
    "    async def search_discord(self,query:str):\n",
    "        results = await utils.perform_web_search(optional_query=query,doc_title =query)\n",
    "        return results\n",
    "    \n",
    "    async def create_discord_poll(self, question: str, options: List[str], channel_name: str) -> str:\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        \n",
    "\n",
    "        await utils.update_text(\"Checking user permissions...\")\n",
    "\n",
    "        if not discord_state.get('request_in_dm'):\n",
    "            return \"User can only access this command in private messages. Exiting command.\"\n",
    "\n",
    "        if not discord_state.get('user_has_mod_role'):\n",
    "            return \"User does not have enough permissions to create a poll. This command is only accessible by moderators. Exiting command...\"\n",
    "\n",
    "        logger.info(\"Discord Model: Handling discord poll creation request\")\n",
    "\n",
    "        try:\n",
    "            if not self.guild:\n",
    "                return \"Unable to find the server. Please try again later.\"\n",
    "\n",
    "            # Find the specified channel\n",
    "            channel = discord.utils.get(self.guild.text_channels, name=channel_name)\n",
    "            if not channel:\n",
    "                return f\"Channel '{channel_name}' not found. Please check the channel name and try again.\"\n",
    "\n",
    "            # Create the poll message\n",
    "            poll_message = f\"📊 **{question}**\\n\\n\"\n",
    "            emoji_options = [\"1️⃣\", \"2️⃣\", \"3️⃣\", \"4️⃣\", \"5️⃣\", \"6️⃣\", \"7️⃣\", \"8️⃣\", \"9️⃣\", \"🔟\"]\n",
    "            try:\n",
    "                for i, option in enumerate(options):  # Limit to 10 options\n",
    "                    poll_message += f\"{emoji_options[i]} {option}\\n\"\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error creating poll options: {str(e)}\")\n",
    "                return f\"An unexpected error occurred while creating poll options: {str(e)}\"\n",
    "            \n",
    "            # Send the poll message\n",
    "            try:\n",
    "                poll = await channel.send(poll_message)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error sending poll message: {str(e)}\")\n",
    "                return  f\"An unexpected error occurred while sending poll: {str(e)}\"\n",
    "            \n",
    "            utils.update_ground_sources([poll.jump_url])  \n",
    "\n",
    "            # Add reactions\n",
    "            try:\n",
    "                \n",
    "                for i in range(len(options)):\n",
    "                    await poll.add_reaction(emoji_options[i])\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error adding reactions to poll: {str(e)}\")\n",
    "                return f\"An unexpected error occurred while adding reactions to poll: {str(e)}\"\n",
    "            \n",
    "            return f\"Poll created successfully in channel '{channel_name}'.\\nQuestion: {question}\\nOptions: {', '.join(options)}\"\n",
    "\n",
    "        except discord.errors.Forbidden:\n",
    "            return \"The bot doesn't have permission to create polls or send messages in the specified channel. Please contact an administrator.\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating poll: {str(e)}\")\n",
    "            return f\"An unexpected error occurred while creating the poll: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscordModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = discord_model\n",
    "        self.chat = None\n",
    "        self.functions = Discord_Model_Functions()\n",
    "        self.last_request_time = time.time()\n",
    "        self.request_counter = 0\n",
    "        self.conversations: Dict[str, List[Dict[str, str]]] = {}\n",
    "        \n",
    "    def _initialize_model(self):\n",
    "        if not self.model:\n",
    "            return logger.error(\"Model not initialized at ActionFunction\")\n",
    "            \n",
    "        # Rate limiting check\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_request_time < 1.0:  # 1 second cooldown\n",
    "            raise Exception(\"Rate limit exceeded\")\n",
    "            \n",
    "        self.last_request_time = current_time\n",
    "        self.request_counter += 1\n",
    "        user_id = discord_state.get(\"user_id\")\n",
    "        self.chat = self.model.start_chat(history=self._get_chat_history(user_id),enable_automatic_function_calling=True)\n",
    "        \n",
    "    def _get_chat_history(self, user_id: str) -> List[Dict[str, str]]:\n",
    "        return self.conversations.get(user_id, [])\n",
    "\n",
    "    def _save_message(self, user_id: str, role: str, content: str):\n",
    "        if user_id not in self.conversations:\n",
    "            self.conversations[user_id] = []\n",
    "        \n",
    "        self.conversations[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": content}]\n",
    "        })\n",
    "        \n",
    "        # Limit the conversation length to 3 messages per user\n",
    "        if len(self.conversations[user_id]) > 3:\n",
    "            self.conversations[user_id].pop(0)\n",
    "        \n",
    "    async def execute_function(self, function_call):\n",
    "        \"\"\"Execute the called function and return its result\"\"\"\n",
    "        function_name = function_call.name\n",
    "        function_args = function_call.args\n",
    "        \n",
    "        function_mapping = {\n",
    "            'notify_moderators': self.functions.notify_moderators,\n",
    "            'notify_discord_helpers': self.functions.notify_discord_helpers,\n",
    "            'create_discord_forum_post': self.functions.create_discord_forum_post,\n",
    "            'create_discord_announcement': self.functions.create_discord_announcement,\n",
    "            'create_discord_poll': self.functions.create_discord_poll,\n",
    "            'search_discord': self.functions.search_discord,\n",
    "        }\n",
    "        \n",
    "        if function_name in function_mapping:\n",
    "            function_to_call = function_mapping[function_name]\n",
    "            func_response = await function_to_call(**function_args)\n",
    "            # response = await self.chat.send_message_async(f\"{function_name} response : {func_response}\")\n",
    "            \n",
    "            if func_response:\n",
    "                # self._save_message(user_id, \"model\", f\"\"\"(Only Visible to You) System Tools - Discord Agent Response: {func_response}\"\"\")\n",
    "                return func_response\n",
    "            else:\n",
    "                logger.error(f\"Error extracting text from response: {e}\")\n",
    "                return \"Error processing response\"\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown function: {function_name}\")\n",
    "    \n",
    "    async def determine_action(self, query: str,special_instructions:str) -> str:\n",
    "        \"\"\"Determines and executes the appropriate action based on the user query\"\"\"\n",
    "        try:\n",
    "            self._initialize_model()\n",
    "            user_id = discord_state.get(\"user_id\")\n",
    "            self._save_message(user_id, \"user\", query)\n",
    "            final_response = \"\"\n",
    "            # Simplified prompt that doesn't encourage analysis verbosity\n",
    "            prompt = f\"\"\"\n",
    "            ### Context:\n",
    "            - Current Date and Time: {datetime.now().strftime('%H:%M %d') + ('th' if 11<=int(datetime.now().strftime('%d'))<=13 else {1:'st',2:'nd',3:'rd'}.get(int(datetime.now().strftime('%d'))%10,'th')) + datetime.now().strftime(' %B, %Y') }\n",
    "            - Superior Agent Instruction: {query}\n",
    "            - Superior Agent Remarks (if any): {special_instructions}\n",
    "            {app_config.get_discord_agent_prompt()}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = await self.chat.send_message_async(prompt)\n",
    "            logger.info(self._get_chat_history)\n",
    "            self._save_message(user_id, \"model\", f\"{response.parts}\" )\n",
    "            for part in response.parts:\n",
    "                if hasattr(part, 'function_call') and part.function_call: \n",
    "                    # Execute function and store only its result\n",
    "                    final_response = await self.execute_function(part.function_call)\n",
    "                    firestore.update_message(\"discord_agent_message\", f\"Function called {part.function_call}\\n Function Response {final_response} \")\n",
    "                elif hasattr(part, 'text') and part.text.strip():\n",
    "                    # Only store actual response content, skip analysis messages\n",
    "                    text = part.text.strip()\n",
    "                    firestore.update_message(\"discord_agent_message\", f\"Text Response {text} \")\n",
    "                    if not text.startswith(\"This query\") and not \"can be answered directly\" in text:\n",
    "                        final_response = text.strip()\n",
    "            \n",
    "        \n",
    "        # Return only the final message\n",
    "            return final_response if final_response else \"Hi! How can I help you with ASU or the Discord server today?\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Discord Model : Error in determine_action: {str(e)}\")\n",
    "            return \"I apologize, but I couldn't generate a response at this time. Please try again.\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "discord_model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.0, \n",
    "        \"top_p\": 0.1,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 2500,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    },safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    },\n",
    "\n",
    "system_instruction = f\"\"\" {app_config.get_discord_agent_instruction()}\n",
    "\"\"\",\n",
    "    tools=[\n",
    "        genai.protos.Tool(\n",
    "            function_declarations=[\n",
    "                      \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"notify_moderators\",\n",
    "                    description=\"Contacts Discord moderators (Allowed only in Private Channels)\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"short_message_to_moderator\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Message for moderators \"\n",
    "                            ),\n",
    "                        },\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"notify_discord_helpers\",\n",
    "                    description=\"Contacts Discord helpers (Allowed only in Private Channels)\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"short_message_to_helpers\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Message for helpers \"\n",
    "                            ),\n",
    "                        },\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"search_discord\",\n",
    "                    description=\"Search for messages on discord server\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Keywords to search\"\n",
    "                            ),\n",
    "                        },\n",
    "                    ),\n",
    "                ),\n",
    "                \n",
    "             \n",
    "                # genai.protos.FunctionDeclaration(\n",
    "                #     name=\"start_recording_discord_call\",\n",
    "                #     description=\"Starts recording a voice call (Allowed to special roles only)\",\n",
    "                #     parameters=content.Schema(\n",
    "                #         type=content.Type.OBJECT,\n",
    "                #         properties={\n",
    "                #             \"channel_id\": content.Schema(\n",
    "                #                 type=content.Type.STRING,\n",
    "                #                 description=\"Voice channel ID to record\"\n",
    "                #             ),\n",
    "                #         },\n",
    "                          \n",
    "                #     ),\n",
    "                # ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"create_discord_poll\",\n",
    "                    description=\"Creates a poll in a specified Discord channel (Allowed only in Private Channels)\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"question\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The main question for the poll\"\n",
    "                            ),\n",
    "                            \"options\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(type=content.Type.STRING),\n",
    "                                description=\"List of options for the poll (maximum 10)\"\n",
    "                            ),\n",
    "                            \"channel_name\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The name of the channel where the poll should be posted\"\n",
    "                            )\n",
    "                        },\n",
    "                        required=[\"question\", \"options\", \"channel_name\"]\n",
    "                    ),\n",
    "                ),\n",
    "\n",
    "\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_user_profile_details\",\n",
    "                    description=\"Retrieves user profile information\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"context\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"User context\"\n",
    "                            ),\n",
    "                        },\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"create_discord_announcement\",\n",
    "                    description=\"Creates a server announcement (Allowed to special roles only in Private Channels)\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"ping\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The role or user to ping with the announcement (e.g., @everyone, @role, or user ID)\"\n",
    "                            ),\n",
    "                            \"title\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The title of the announcement\"\n",
    "                            ),\n",
    "                            \"category\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The category of the announcement\"\n",
    "                            ),\n",
    "                            \"body_content_1\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The main content of the announcement\"\n",
    "                            ),\n",
    "                            \"body_content_2\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Additional content for the announcement (optional)\"\n",
    "                            ),\n",
    "                            \"body_content_3\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"More details for the announcement (optional)\"\n",
    "                            ),\n",
    "                            \"link\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Links\"\n",
    "                            ),\n",
    "                            \n",
    "                        },\n",
    "                        required=[\"title\", \"category\", \"body_content_1\",\"body_content_2\",\"body_content_3\"]\n",
    "                    ),\n",
    "                ),\n",
    "\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"create_discord_forum_post\",\n",
    "                    description=\"Creates a new forum post (Allowed only in Private Channels)\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"title\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The title of the forum post\"\n",
    "                            ),\n",
    "                            \"category\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The category tag for the forum post\"\n",
    "                            ),\n",
    "                            \"body_content_1\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The main content of the forum post\"\n",
    "                            ),\n",
    "                            \"body_content_2\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Additional content for the forum post (optional)\"\n",
    "                            ),\n",
    "                            \"body_content_3\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"More details for the forum post (optional)\"\n",
    "                            ),\n",
    "                            \"link\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Links\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required=[\"title\", \"category\", \"body_content_1\",\"body_content_2\",\"body_content_3\"]\n",
    "                    ),\n",
    "                ),\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"create_discord_event\",\n",
    "                    description=\"Creates a new Discord event (Allowed only in Private Channels for users with required permissions)\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"title\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The title of the Discord event\"\n",
    "                            ),\n",
    "                            \"time_start\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The start time of the event in ISO format (e.g., '2023-12-31T23:59:59')\"\n",
    "                            ),\n",
    "                            \"time_end\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The end time of the event in ISO format (e.g., '2024-01-01T01:00:00')\"\n",
    "                            ),\n",
    "                            \"description\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"The description of the event\"\n",
    "                            ),\n",
    "                            \"img_provided\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"URL or file path of an image to be used as the event cover (optional)\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required=[\"title\", \"time_start\", \"time_end\", \"description\"]\n",
    "                    ),\n",
    "                ),\n",
    "                \n",
    "               \n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    tool_config={'function_calling_config': 'ANY'},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### global Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_discord_agent = DiscordModel()\n",
    "logger.info(\"\\nInitailized DIscord Model Instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Model\n",
    "\n",
    "This `ActionModel` serves as a central component for determining and executing appropriate actions based on user queries, integrating various functions and agents to provide comprehensive responses in the ASU Discord Research Assistant Bot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "- Initializes with a model (`action_model`), functions (`ActionModelFunctions`), and conversation tracking.\n",
    "- Implements rate limiting and request counting.\n",
    "\n",
    "#### Function Execution\n",
    "- `execute_function` method dynamically calls the appropriate function based on the function name.\n",
    "- Supports various action functions like performing web searches, accessing other agents, and retrieving specific information.\n",
    "\n",
    "#### Model Configuration\n",
    "- Uses the \"gemini-1.5-flash\" model with specific generation config settings.\n",
    "- Implements safety settings to block low and above levels of hate speech and harassment.\n",
    "\n",
    "#### Action Determination\n",
    "- `determine_action` method processes user queries and special instructions.\n",
    "- Constructs prompts with current context, user query, and agent instructions.\n",
    "- Handles both text responses and function calls from the model.\n",
    "\n",
    "#### Response Processing\n",
    "- Iterates through model response parts, handling both text and function calls.\n",
    "- Executes functions when called and formats the final response.\n",
    "\n",
    "#### Error Handling\n",
    "- Comprehensive error logging throughout the class.\n",
    "- Fallback responses for various error scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action_Model_Functions:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversations = {}\n",
    "        self.client = genai2.Client(api_key=app_config.get_api_key())\n",
    "        self.model_id = \"gemini-2.0-flash-exp\"\n",
    "        self.discord_client = discord_state.get('discord_client')\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        self.user_id=discord_state.get('user_id')\n",
    "        self.user= discord_state.get('user')\n",
    "        self.google_search_tool = Tool(google_search=GoogleSearch())\n",
    "    \n",
    "    def get_final_url(self,url):\n",
    "        try:\n",
    "            response = requests.get(url, allow_redirects=True)\n",
    "            return response.url\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "            return e  \n",
    "\n",
    "    async def access_search_agent(self, instruction_to_agent: str, special_instructions: str):\n",
    "        logger.info(f\"Action Model : accessing search agent with instruction {instruction_to_agent} with special instructions {special_instructions}\")\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'H'))\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'N'))\n",
    "        try:\n",
    "            response = await asu_search_agent.determine_action(instruction_to_agent,special_instructions)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in access search agent: {str(e)}\")\n",
    "            return f\"Search Agent Not Responsive\"\n",
    "         \n",
    "    async def access_discord_agent(self, instruction_to_agent: str,special_instructions: str):\n",
    "        logger.info(f\"Action Model : accessing discord agent with instruction {instruction_to_agent} with special instructions {special_instructions}\")\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'J'))\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'N'))\n",
    "        try:\n",
    "            response = await asu_discord_agent.determine_action(instruction_to_agent,special_instructions)\n",
    "            \n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in access discord agent: {str(e)}\")\n",
    "            return f\"Discord Agent Not Responsive\"\n",
    "        \n",
    "    async def get_user_profile_details(self) -> str:\n",
    "        \"\"\"Retrieve user profile details from the Discord server\"\"\"\n",
    "        self.guild = discord_state.get('target_guild')\n",
    "        self.user_id = discord_state.get('user_id')\n",
    "        logger.info(f\"Discord Model: Handling user profile details request for user ID: {user_id}\")\n",
    "\n",
    "        if not request_in_dm:\n",
    "            return \"User can only access this command in private messages. It seems like the user is trying to access this command in a discord server. Exiting command.\"\n",
    "\n",
    "        try:\n",
    "            # If no user_id is provided, use the requester's ID\n",
    "            if not user_id:\n",
    "                user_id = self.user_id\n",
    "\n",
    "            member = await self.guild.fetch_member(user_id)\n",
    "            if not member:\n",
    "                return f\"Unable to find user with ID {user_id} in the server.\"\n",
    "\n",
    "            # Fetch user-specific data (customize based on your server's setup)\n",
    "            join_date = member.joined_at.strftime(\"%Y-%m-%d\")\n",
    "            roles = [role.name for role in member.roles if role.name != \"@everyone\"]\n",
    "            \n",
    "            # You might need to implement these functions based on your server's systems\n",
    "            # activity_points = await self.get_user_activity_points(user_id)\n",
    "            # leaderboard_position = await self.get_user_leaderboard_position(user_id)\n",
    "            # - Activity Points: {activity_points}\n",
    "            # - Leaderboard Position: {leaderboard_position}\n",
    "\n",
    "            profile_info = f\"\"\"\n",
    "            User Profile for {member.name}#{member.discriminator}:\n",
    "            - Join Date: {join_date}\n",
    "            - Roles: {', '.join(roles)}\n",
    "            - Server Nickname: {member.nick if member.nick else 'None'}\n",
    "            \"\"\"\n",
    "\n",
    "            return profile_info.strip()\n",
    "\n",
    "        except discord.errors.NotFound:\n",
    "            return f\"User with ID {user_id} not found in the server.\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error retrieving user profile: {str(e)}\")\n",
    "            return f\"An error occurred while retrieving the user profile: {str(e)}\"\n",
    "    \n",
    "    async def get_discord_server_info(self) -> str:\n",
    "             \n",
    "        self.discord_client = discord_state.get('discord_client')\n",
    "        logger.info(f\"Initialized Discord Client : {self.discord_client}\")\n",
    "        self.guild = discord_state.get(\"target_guild\")\n",
    "        \n",
    "        logger.info(f\"Initialized Discord Guild : {self.guild}\")\n",
    "        \"\"\"Create discord forum post callable by model\"\"\"\n",
    "\n",
    "        \n",
    "        logger.info(f\"Discord Model : Handling discord server info request with context\")\n",
    "                \n",
    "        \n",
    "        return f\"\"\"1.Sparky Discord Server - Sparky Discord Server is a place where ASU Alumni's or current students join to hangout together, have fun and learn things about ASU together and quite frankly!\n",
    "        2. Sparky Discord Bot -  AI Agent built to help people with their questions regarding ASU related information and sparky's discord server. THis AI Agent can also perform discord actions for users upon request.\"\"\"\n",
    "    \n",
    "    async def access_live_status_agent(self, instruction_to_agent: str, special_instructions: str):\n",
    "        logger.info(f\"Action Model : accessing live status agent with instruction {instruction_to_agent} with special instructions {special_instructions}\")\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'K'))\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'N'))\n",
    "        \n",
    "        try:\n",
    "            response = await asu_live_status_agent.determine_action(instruction_to_agent,special_instructions)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in deep search agent: {str(e)}\")\n",
    "            return \"I apologize, but I couldn't retrieve the information at this time.\"\n",
    "              \n",
    "    async def send_bot_feedback(self, feedback: str) -> str:\n",
    "        self.user = discord_state.get('user') \n",
    "        self.discord_client = discord_state.get('discord_client')\n",
    "        \n",
    "        await utils.update_text(\"Opening feedbacks...\")\n",
    "        \n",
    "        logger.info(\"Contact Model: Handling contact request for server feedback\")\n",
    "\n",
    "        try:\n",
    "            # Find the feedbacks channel\n",
    "            feedbacks_channel = discord.utils.get(self.discord_client.get_all_channels(), name='feedback')\n",
    "            if not feedbacks_channel:\n",
    "                return \"feedbacks channel not found. Please ensure the channel exists.\"\n",
    "\n",
    "            # Create an embed for the feedback\n",
    "            embed = discord.Embed(title=\"New Server feedback\", color=discord.Color.green())\n",
    "            embed.add_field(name=\"feedback\", value=feedback, inline=False)\n",
    "            embed.set_footer(text=f\"Suggested by {self.user.name}\")\n",
    "\n",
    "            # Send the feedback to the channel\n",
    "            message = await feedbacks_channel.send(embed=embed)\n",
    "\n",
    "            # Add reactions for voting\n",
    "            await message.add_reaction('👍')\n",
    "            await message.add_reaction('👎')\n",
    "            \n",
    "            utils.update_ground_sources([message.jump_url])\n",
    "            \n",
    "            return f\"Your feedback has been successfully submitted.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sending feedback: {str(e)}\")\n",
    "            return f\"An error occurred while sending your feedback: {str(e)}\"\n",
    "    \n",
    "    def _get_chat_history(self, user_id):\n",
    "        return self.conversations.get(user_id, [])\n",
    "\n",
    "    def _save_message(self, user_id: str, role: str, content: str):\n",
    "        if user_id not in self.conversations:\n",
    "            self.conversations[user_id] = []\n",
    "        \n",
    "        self.conversations[user_id].append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [{\"text\": content}]\n",
    "        })\n",
    "        \n",
    "        # Limit the conversation length to 3 messages per user\n",
    "        if len(self.conversations[user_id]) > 3:\n",
    "            self.conversations[user_id].pop(0)\n",
    "\n",
    "    async def access_google_agent(self, original_query: str, detailed_query: str, generalized_query: str, relative_query: str, categories: list):\n",
    "        firestore.update_message(\"category\", categories)\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'L'))\n",
    "        await (google_sheet.increment_function_call(discord_state.get('user_id'), 'M'))\n",
    "        \n",
    "        user_id = discord_state.get('user_id')\n",
    "        responses=[]\n",
    "        logger.info(f\"Action Model: accessing Google Search with instruction {original_query}\")\n",
    "        try:\n",
    "            # Perform database search\n",
    "            queries = [\n",
    "                {\"search_bar_query\": original_query},\n",
    "                {\"search_bar_query\": detailed_query},\n",
    "                {\"search_bar_query\": generalized_query},\n",
    "                {\"search_bar_query\": relative_query}\n",
    "            ]\n",
    "            for query in queries:\n",
    "                response = await utils.perform_database_search(query[\"search_bar_query\"], categories) or []\n",
    "                responses.append(response)\n",
    "\n",
    "            responses = [resp for resp in responses if resp]\n",
    "        except:\n",
    "            logger.error(\"No results found in database\")\n",
    "            pass\n",
    "        # Get chat history\n",
    "        \n",
    "        chat_history = self._get_chat_history(user_id)\n",
    "\n",
    "        # Prepare the prompt\n",
    "        prompt = f\"\"\"\n",
    "        \n",
    "        {app_config.get_google_agent_prompt()}\n",
    "        \n",
    "        - If applicable, you may use the related database information : {responses}\n",
    "        \n",
    "        Chat History:\n",
    "        {chat_history}\n",
    "\n",
    "        User's Query: {original_query}\n",
    "\n",
    "        Deliver a direct, actionable response that precisely matches the query's specificity.\"\"\"\n",
    "        \n",
    "        try:     \n",
    "            # Generate response\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model_id,\n",
    "                contents=prompt,\n",
    "                config=GenerateContentConfig(\n",
    "                    tools=[self.google_search_tool],\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    system_instruction=f\"{app_config.get_google_agent_instruction()}\",\n",
    "                    max_output_tokens=600\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            grounding_sources = [self.get_final_url(chunk.web.uri) for candidate in response.candidates if candidate.grounding_metadata and candidate.grounding_metadata.grounding_chunks for chunk in candidate.grounding_metadata.grounding_chunks if chunk.web]\n",
    "            \n",
    "            utils.update_ground_sources(grounding_sources)\n",
    "            \n",
    "            response_text = \"\".join([part.text for part in response.candidates[0].content.parts if part.text])\n",
    "\n",
    "\n",
    "            # Save the interaction to chat history\n",
    "            self._save_message(user_id, \"user\", original_query)\n",
    "            self._save_message(user_id, \"model\", response_text)\n",
    "\n",
    "            logger.info(response_text)\n",
    "\n",
    "            if not response_text:\n",
    "                logger.error(\"No response from Google Search\")\n",
    "                return None\n",
    "            return response_text\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Google Search Exception {e}\")\n",
    "            return responses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = action_model\n",
    "        self.chat = None\n",
    "        self.functions = Action_Model_Functions()\n",
    "        self.last_request_time = time.time()\n",
    "        self.request_counter = 0\n",
    "\n",
    "    def _initialize_model(self):\n",
    "        if not self.model:\n",
    "            raise Exception(\"Model is not available.\")\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_request_time < 1.0:\n",
    "            raise Exception(\"Rate limit exceeded. Please try again later.\")\n",
    "        self.last_request_time = current_time\n",
    "        self.request_counter += 1\n",
    "        self.chat = self.model.start_chat(enable_automatic_function_calling=True)\n",
    "\n",
    "    async def execute_function(self, function_call: Any) -> str:\n",
    "        function_mapping = {\n",
    "            'access_search_agent': self.functions.access_search_agent,\n",
    "            'access_google_agent': self.functions.access_google_agent,\n",
    "            'access_discord_agent': self.functions.access_discord_agent,\n",
    "            'send_bot_feedback': self.functions.send_bot_feedback,\n",
    "            'access_live_status_agent': self.functions.access_live_status_agent,\n",
    "            'get_user_profile_details': self.functions.get_user_profile_details,\n",
    "            'get_discord_server_info': self.functions.get_discord_server_info,\n",
    "        }\n",
    "\n",
    "        function_name = function_call.name\n",
    "        function_args = function_call.args\n",
    "\n",
    "        if function_name not in function_mapping:\n",
    "            raise ValueError(f\"Unknown function: {function_name}\")\n",
    "        \n",
    "        function_to_call = function_mapping[function_name]\n",
    "        return await function_to_call(**function_args)\n",
    "\n",
    "    async def process_gemini_response(self, response: Any) -> tuple[str, bool, Any]:\n",
    "        text_response = \"\"\n",
    "        has_function_call = False\n",
    "        function_call = None\n",
    "        logger.info(response)\n",
    "\n",
    "        for part in response.parts:\n",
    "            if hasattr(part, 'text') and part.text.strip():\n",
    "                text_response += f\"\\n{part.text.strip()}\"\n",
    "                firestore.update_message(\"action_agent_message\", f\"Text Response : {text_response} \")\n",
    "            if hasattr(part, 'function_call') and part.function_call:\n",
    "                has_function_call = True\n",
    "                function_call = part.function_call\n",
    "                temp_func =  {\n",
    "                \"function_call\": {\n",
    "                    \"name\": part.function_call.name,\n",
    "                    \"args\": dict(part.function_call.args)\n",
    "                    }\n",
    "                }\n",
    "                firestore.update_message(\"action_agent_message\", json.dumps(temp_func, indent=2))\n",
    "\n",
    "        return text_response, has_function_call, function_call\n",
    "\n",
    "    async def determine_action(self, query: str) -> List[str]:\n",
    "        try:\n",
    "            final_response=\"\"\n",
    "            self._initialize_model()\n",
    "            responses = []\n",
    "            prompt = f\"\"\"\n",
    "            ### Context:\n",
    "            - Current Date and Time: {datetime.now().strftime('%H:%M %d') + ('th' if 11<=int(datetime.now().strftime('%d'))<=13 else {1:'st',2:'nd',3:'rd'}.get(int(datetime.now().strftime('%d'))%10,'th')) + datetime.now().strftime(' %B, %Y') }\n",
    "            - User Query: {query}\n",
    "            {app_config.get_action_agent_prompt()}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = await self.chat.send_message_async(prompt)\n",
    "            logger.info(f\"RAW TEST RESPONSE : {response}\")\n",
    "            \n",
    "            while True:\n",
    "                text_response, has_function_call, function_call = await self.process_gemini_response(response)\n",
    "                responses.append(text_response)\n",
    "                final_response += text_response\n",
    "                if not has_function_call:\n",
    "                    break\n",
    "                function_result = await self.execute_function(function_call)\n",
    "                firestore.update_message(\"action_agent_message\", f\"\"\"(User cannot see this response) System Generated - \\n{function_call.name}\\nResponse: {function_result}\\nAnalyze the response and answer the user's question.\"\"\")\n",
    "                logger.info(\"\\nAction Model @ Function result is: %s\", function_result)\n",
    "                response = await self.chat.send_message_async(f\"\"\"(User cannot see this response) System Generated - \\n{function_call.name}\\nResponse: {function_result}\\nAnalyze the response and answer the user's question.\"\"\")\n",
    "                \n",
    "            final_response = \" \".join(response.strip() for response in responses if response.strip())\n",
    "            \n",
    "            return final_response.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in determine_action: {e}\")\n",
    "            return [\"I'm sorry, I couldn't generate a response. Please try again.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_model = genai.GenerativeModel(\n",
    "    \n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    \n",
    "    generation_config={\n",
    "        \"temperature\": 0.0, \n",
    "        \"top_p\": 0.1,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 3100,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    },\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "    },\n",
    "    \n",
    "    system_instruction = f\"\"\" {app_config.get_action_agent_instruction()}\"\"\",\n",
    "    \n",
    "    tools=[\n",
    "        genai.protos.Tool(\n",
    "            function_declarations=[\n",
    "                            \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"access_search_agent\",\n",
    "                    description=\"Has ability to search for ASU-specific Targeted , real-time information extraction related to Jobs, Scholarships, Library Catalog, News, Events, Social Media, Sport Updates, Clubs\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"instruction_to_agent\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Tasks for the agent\"\n",
    "                            ),\n",
    "                            \"special_instructions\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Remarks about previous search or Special Instructions to Agent\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required= [\"instruction_to_agent\",\"special_instructions\"],\n",
    "                    ),\n",
    "                ),\n",
    "                \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"access_discord_agent\",\n",
    "                    description=\"Has ability to post announcement/event/poll and connect user to moderator/helper request\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"instruction_to_agent\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Tasks for the agent\"\n",
    "                            ),\n",
    "                            \"special_instructions\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Remarks about previous search or Special Instructions to Agent\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required= [\"instruction_to_agent\",\"special_instructions\"]\n",
    "                    ),   \n",
    "                ),\n",
    "                \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"send_bot_feedback\",\n",
    "                    description=\"Submits user's feedbacks about sparky\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"feedback\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Feedback by the user\"\n",
    "                            ),\n",
    "                        },\n",
    "                    required=[\"feedback\"]\n",
    "                    ),\n",
    "                ),\n",
    "                   \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_discord_server_info\",\n",
    "                    description=\"Get Sparky Discord Server related Information\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"context\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Context of Information\"\n",
    "                            ),\n",
    "                        },\n",
    "                          \n",
    "                    ),\n",
    "                ),\n",
    "                 \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"access_live_status_agent\",\n",
    "                    description=\"Has ability to fetch realtime live shuttle/bus, library and StudyRooms status.\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"instruction_to_agent\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Tasks for Live Status Agent\"\n",
    "                            ),\n",
    "                            \"special_instructions\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Special Instructions to the agent\"\n",
    "                            ),\n",
    "                        },\n",
    "                        required= [\"instruction_to_agent\",\"special_instructions\"],\n",
    "                    ),\n",
    "                ),\n",
    "                 \n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"get_user_profile_details\",\n",
    "                    description=\"Get Sparky Discord Server related Information\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"context\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Context of Information\"\n",
    "                            ),\n",
    "                        },\n",
    "                          \n",
    "                    ),\n",
    "                ),\n",
    "\n",
    "                genai.protos.FunctionDeclaration(\n",
    "                    name=\"access_google_agent\",\n",
    "                    description=\"Performs Google Search through to provide rapid result summary\",\n",
    "                    parameters=content.Schema(\n",
    "                        type=content.Type.OBJECT,\n",
    "                        properties={\n",
    "                            \"original_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Original Query to Search\"\n",
    "                            ),\n",
    "                            \"detailed_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Detailed query related to the question\"\n",
    "                            ),\n",
    "                            \"generalized_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"General query related to the question\"\n",
    "                            ),\n",
    "                            \"relative_query\": content.Schema(\n",
    "                                type=content.Type.STRING,\n",
    "                                description=\"Other query related to the question\"\n",
    "                            ),\n",
    "                            \"categories\": content.Schema(\n",
    "                                type=content.Type.ARRAY,\n",
    "                                items=content.Schema(\n",
    "                                    type=content.Type.STRING,\n",
    "                                    enum=[\n",
    "                                        \"libraries_status\", \n",
    "                                        \"shuttles_status\", \n",
    "                                        \"clubs_info\", \n",
    "                                        \"scholarships_info\", \n",
    "                                        \"job_updates\", \n",
    "                                        \"library_resources\",  \n",
    "                                        \"classes_info\", \n",
    "                                        \"events_info\", \n",
    "                                        \"news_info\", \n",
    "                                        \"social_media_updates\", \n",
    "                                    ]\n",
    "                                ),\n",
    "                                description=\"Documents Category Filter\"\n",
    "                            ),\n",
    "\n",
    "                        },\n",
    "                        required=[\"original_query\",\"detailed_query\",\"generalized_query\",\"relative_query\",\"categories\"]\n",
    "                    ),\n",
    "                ),    \n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    tool_config={'function_calling_config': 'AUTO'},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_action_agent = ActionModel()\n",
    "logger.info(\"\\nInitialized ActionAgent Global Instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline\n",
    "\n",
    "This `RAGPipeline` class serves as a streamlined interface for processing user queries, leveraging the action agent for determining appropriate responses and implementing robust error handling for reliable operation in the ASU Discord Research Assistant Bot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Initialization\n",
    "- The class is initialized without any specific parameters.\n",
    "\n",
    "### Query Processing\n",
    "- The `process_question` method is the main entry point for handling user queries:\n",
    "  - Takes a `question` parameter as input.\n",
    "  - Utilizes the `asu_action_agent` to determine the appropriate action for the query.\n",
    "  - Implements error handling and logging for the processing pipeline.\n",
    "\n",
    "### Integration with Action Agent\n",
    "- Delegates the actual query processing to the `asu_action_agent.determine_action` method.\n",
    "- This integration allows for flexible action determination based on the input question.\n",
    "\n",
    "### Error Handling\n",
    "- Implements comprehensive error logging for query processing failures.\n",
    "- Raises exceptions with detailed error messages for debugging purposes.\n",
    "\n",
    "### Logging\n",
    "- Utilizes a logger to track the pipeline's operations and potential issues.\n",
    "\n",
    "### Usage\n",
    "- An instance of the `RAGPipeline` class is created and stored in the `asu_rag` variable.\n",
    "- The pipeline's successful initialization is logged for verification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RAGPipeline:                \n",
    "    async def process_question(self,question: str) -> str:\n",
    "        try:\n",
    "            response = await asu_action_agent.determine_action(question)\n",
    "            logger.info(\"\\nRAG Pipeline called\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"RAG PIPELINE : Error processing question: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asu_rag =  RAGPipeline()\n",
    "\n",
    "logger.info(\"\\n----------------------------------------------------------------\")\n",
    "logger.info(\"\\nASU RAG INITIALIZED SUCCESSFULLY\")\n",
    "logger.info(\"\\n---------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ASUDiscordBot` class provides Discord integration:\n",
    "- Handles command registration and event management\n",
    "- Implements channel validation and question processing\n",
    "- Manages response chunking for long answers\n",
    "- Provides error handling and user feedback\n",
    "- Includes configuration options for customization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification System\n",
    "\n",
    "The verification system consists of three main components: VerifyButton, VerificationModal, and OTPVerificationModal. Here's an overview of each:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VerifyButton(discord.ui.Button):\n",
    "    def __init__(self):\n",
    "        super().__init__(label=\"Verify\", style=discord.ButtonStyle.primary, custom_id=\"verify_button\")\n",
    "\n",
    "    async def callback(self, interaction: discord.Interaction):\n",
    "        await interaction.response.send_modal(VerificationModal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VerificationModal\n",
    "\n",
    "This class extends `discord.ui.Modal` and handles the initial step of the verification process.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Prompts users to enter their ASU email\n",
    "- Validates the email format\n",
    "- Generates and sends a one-time password (OTP) to the provided email\n",
    "- Creates a button for users to proceed to OTP verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerificationModal(discord.ui.Modal):\n",
    "    def __init__(self):\n",
    "        super().__init__(title=\"ASU Email Verification\")\n",
    "        self.email = discord.ui.TextInput(\n",
    "            label=\"ENTER YOUR ASU EMAIL\",\n",
    "            placeholder=\"yourname@asu.edu\",\n",
    "            custom_id=\"email_input\"\n",
    "        )\n",
    "        self.creds = Credentials.from_service_account_file(\n",
    "            'client_secret.json',\n",
    "            scopes=['https://www.googleapis.com/auth/spreadsheets']\n",
    "        )\n",
    "        self.service = build('sheets', 'v4', credentials=self.creds)\n",
    "        self.stored_otp = None\n",
    "        self.spreadsheet_id = app_config.get_spreadsheet_id()\n",
    "        self.add_item(self.email)\n",
    "\n",
    "    async def on_submit(self, interaction: discord.Interaction):\n",
    "        if  not self.stored_otp:  # First submission - email only\n",
    "            if self.validate_asu_email(self.email.value):\n",
    "                self.stored_otp = self.generate_otp()\n",
    "                self.send_otp_email(self.email.value, self.stored_otp)\n",
    "                view = discord.ui.View()\n",
    "                button = discord.ui.Button(label=\"Enter OTP\", style=discord.ButtonStyle.primary)\n",
    "                async def button_callback(button_interaction):\n",
    "                    await button_interaction.response.send_modal(OTPVerificationModal(self.stored_otp, self.email.value, self.spreadsheet_id, self.creds, self.service))\n",
    "                button.callback = button_callback\n",
    "                view.add_item(button)\n",
    "                await interaction.response.send_message(\"OTP has been sent to your email. Click the button below to enter it.\", view=view, ephemeral=True)\n",
    "            else:\n",
    "                await interaction.response.send_message(\"Invalid ASU email. Please try again.\", ephemeral=True)\n",
    "\n",
    "    def validate_asu_email(self, email):\n",
    "        return re.match(r'^[a-zA-Z0-9._%+-]+@asu\\.edu$', email) is not None\n",
    "\n",
    "    def generate_otp(self):\n",
    "        return ''.join(str(random.randint(0, 9)) for _ in range(6))\n",
    "\n",
    "    def send_otp_email(self, email, otp):\n",
    "        sender_email = app_config.get_gmail()\n",
    "        sender_password = app_config.get_gmail_pass()\n",
    "        message = MIMEText(f\"Your OTP for ASU Discord verification is {otp}\")\n",
    "        message['Subject'] = \"ASU Discord Verification OTP\"\n",
    "        message['From'] = sender_email\n",
    "        message['To'] = email\n",
    "        \n",
    "        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n",
    "            server.login(sender_email, sender_password)\n",
    "            server.sendmail(sender_email, email, message.as_string())\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTPVerificationModal\n",
    "\n",
    "This class extends `discord.ui.Modal` and handles the final step of the verification process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Prompts users to enter the OTP sent to their email\n",
    "- Verifies the entered OTP\n",
    "- Assigns the \"verified\" role to the user upon successful verification\n",
    "- Updates the Google Sheet with user information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OTPVerificationModal(discord.ui.Modal):\n",
    "    def __init__(self, correct_otp, email,spreadsheet_id,creds,service):\n",
    "        super().__init__(title=\"Enter OTP\")\n",
    "        self.correct_otp = correct_otp\n",
    "        self.email = email\n",
    "        self.spreadsheet_id = spreadsheet_id\n",
    "        self.otp = discord.ui.TextInput(\n",
    "            label=\"ENTER OTP\",\n",
    "            placeholder=\"Enter the 6-digit OTP sent to your email\",\n",
    "            custom_id=\"otp_input\"\n",
    "        )\n",
    "        self.service = service\n",
    "        self.creds = creds\n",
    "        self.add_item(self.otp)\n",
    "\n",
    "    async def on_submit(self, interaction: discord.Interaction):\n",
    "        if self.otp.value == self.correct_otp:\n",
    "            await self.verify_member(interaction, self.email)\n",
    "        else:\n",
    "            await interaction.response.send_message(\"Incorrect OTP. Please try again.\", ephemeral=True)\n",
    "\n",
    "    async def verify_member(self, interaction: discord.Interaction, email):\n",
    "        verified_role = discord.utils.get(interaction.guild.roles, name=\"verified\")\n",
    "        if verified_role:\n",
    "            await interaction.user.add_roles(verified_role)\n",
    "            await (google_sheet.add_new_user(interaction.user, email))\n",
    "            await interaction.response.send_message(\"You have been verified!\", ephemeral=True)\n",
    "        else:\n",
    "            await interaction.response.send_message(\"Verification role not found. Please contact an administrator.\", ephemeral=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASUDiscordBot Class\n",
    "\n",
    "This class serves as the main interface between Discord and the bot's backend systems, managing user interactions, command processing, and response delivery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BotConfig Class\n",
    "\n",
    "This dataclass defines the configuration for the Discord bot:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `command_name`: Name of the bot command (default: \"ask\")\n",
    "- `command_description`: Description of the bot command\n",
    "- `max_question_length`: Maximum allowed length for user questions (300 characters)\n",
    "- `max_response_length`: Maximum length for bot responses (2000 characters)\n",
    "- `chunk_size`: Size of message chunks for long responses (1900 characters)\n",
    "- `token`: Discord bot token retrieved from app configuration\n",
    "- `thinking_timeout`: Timeout for bot's \"thinking\" state (60 seconds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BotConfig:\n",
    "    \"\"\"Configuration for Discord bot\"\"\"\n",
    "    command_name: str = \"ask\"\n",
    "    command_description: str = \"Ask a question about ASU\"\n",
    "    max_question_length: int = 300\n",
    "    max_response_length: int = 2000\n",
    "    chunk_size: int = 1900\n",
    "    token: str = app_config.get_discord_bot_token()  \n",
    "    thinking_timeout: int = 60\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Initialization\n",
    "- Initializes with a RAG pipeline and optional configuration\n",
    "- Sets up Discord client, command tree, and service for web interactions\n",
    "\n",
    "#### Key Methods\n",
    "- `_register_commands`: Sets up the \"ask\" command\n",
    "- `_register_events`: Handles bot ready event\n",
    "- `_handle_ask_command`: Processes user questions\n",
    "- `_validate_channel`: Ensures command is used in correct channel\n",
    "- `_validate_question_length`: Checks if question is within length limits\n",
    "- `_process_and_respond`: Handles question processing and response generation\n",
    "- `_send_chunked_response`: Sends long responses in chunks\n",
    "- `_send_error_response`: Handles error messaging\n",
    "- `_handle_ready`: Syncs command tree and sets up verification button\n",
    "- `start`: Starts the Discord bot\n",
    "- `close`: Closes the Discord bot connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASUDiscordBot:\n",
    "    \n",
    "    \"\"\"Discord bot for handling ASU-related questions\"\"\"\n",
    "\n",
    "    def __init__(self, rag_pipeline, config: Optional[BotConfig] = None):\n",
    "        \"\"\"\n",
    "        Initialize the Discord bot.\n",
    "        \n",
    "        Args:\n",
    "            rag_pipeline: RAG pipeline instance\n",
    "            config: Optional bot configuration\n",
    "        \"\"\"\n",
    "        logger.info(\"\\nInitializing ASUDiscordBot\")\n",
    "        self.config = config or BotConfig()\n",
    "        self.rag_pipeline = rag_pipeline\n",
    "        \n",
    "        # Initialize Discord client\n",
    "        \n",
    "        self.client = discord_state.get('discord_client')\n",
    "        self.tree = app_commands.CommandTree(self.client)\n",
    "        self.guild = self.client.get_guild(1256076931166769152)\n",
    "        self.service = Service(ChromeDriverManager().install())\n",
    "        \n",
    "        # Register commands and events\n",
    "        self._register_commands()\n",
    "        self._register_events()\n",
    "   \n",
    "    def _register_commands(self) -> None:\n",
    "        \"\"\"Register Discord commands\"\"\"\n",
    "        \n",
    "        @self.tree.command(\n",
    "            name=self.config.command_name,\n",
    "            description=self.config.command_description\n",
    "        )\n",
    "        async def ask(interaction: discord.Interaction, question: str):\n",
    "            await self._handle_ask_command(interaction, question)\n",
    "        \n",
    "    def _register_events(self) -> None:\n",
    "        \"\"\"Register Discord events\"\"\"\n",
    "        \n",
    "        @self.client.event\n",
    "        async def on_ready():\n",
    "            await self._handle_ready()\n",
    "            \n",
    "    async def _handle_ask_command(\n",
    "        self,\n",
    "        interaction: discord.Interaction,\n",
    "        question: str) -> None:\n",
    "        \"\"\"\n",
    "        Handle the ask command.\n",
    "        \n",
    "        Args:\n",
    "            interaction: Discord interaction\n",
    "            question: User's question\n",
    "        \"\"\"\n",
    "        logger.info(f\"User {interaction.user.name} asked: {question}\")\n",
    "        user = interaction.user\n",
    "        user_id= interaction.user.id\n",
    "        request_in_dm = isinstance(interaction.channel, discord.DMChannel)\n",
    "        self.guild = self.client.get_guild(1256076931166769152)\n",
    "        target_guild = self.client.get_guild(1256076931166769152)\n",
    "        user_has_mod_role= None\n",
    "        member = None\n",
    "        user_voice_channel_id=None\n",
    "        # Reset all states\n",
    "\n",
    "        if target_guild:\n",
    "            try:\n",
    "                member = await target_guild.fetch_member(interaction.user.id)\n",
    "                if member:\n",
    "                    required_role_name = \"mod\" \n",
    "                    user_has_mod_role = any(\n",
    "                        role.name == required_role_name for role in member.roles\n",
    "                    )\n",
    "                    \n",
    "                    # Check voice state\n",
    "                    if member.voice:\n",
    "                        user_voice_channel_id = member.voice.channel.id\n",
    "                else:\n",
    "                    return \"You are not part of Sparky Discord Server. Access to command is restricted.\"\n",
    "\n",
    "                    \n",
    "            except discord.NotFound:\n",
    "                return \"You are not part of Sparky Discord Server. Access to command is restricted.\"\n",
    "        await asu_scraper.__login__(app_config.get_handshake_user(),app_config.get_handshake_pass() )\n",
    "        discord_state.update(user=user, target_guild=target_guild, request_in_dm=request_in_dm,user_id=user_id, guild_user = member, user_has_mod_role=user_has_mod_role,user_voice_channel_id=user_voice_channel_id)\n",
    "        firestore.update_collection(\"direct_messages\" if request_in_dm else \"guild_messages\" )\n",
    "         \n",
    "        try:\n",
    "            if not await self._validate_channel(interaction):\n",
    "                return\n",
    "            if not await self._validate_question_length(interaction, question):\n",
    "                return\n",
    "            \n",
    "            await self._process_and_respond(interaction, question)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing ask command: {str(e)}\"\n",
    "            logger.error(error_msg, exc_info=True)\n",
    "            await self._send_error_response(interaction)\n",
    "\n",
    "    async def _validate_channel(self, interaction: discord.Interaction) -> bool:\n",
    "        \"\"\"Validate if command is used in correct channel\"\"\"\n",
    "        if not discord_state.get('request_in_dm') and interaction.channel.id != 1323387010886406224:\n",
    "            await interaction.response.send_message(\n",
    "                \"Please use this command in the designated channel: #general\",\n",
    "                ephemeral=True\n",
    "            )\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    async def _validate_question_length(\n",
    "        self,\n",
    "        interaction: discord.Interaction,\n",
    "        question: str) -> bool:\n",
    "        \"\"\"Validate question length\"\"\"\n",
    "        if len(question) > self.config.max_question_length:\n",
    "            await interaction.response.send_message(\n",
    "                f\"Question too long ({len(question)} characters). \"\n",
    "                f\"Please keep under {self.config.max_question_length} characters.\",\n",
    "                ephemeral=True\n",
    "            )\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    async def _process_and_respond(\n",
    "        self,\n",
    "        interaction: discord.Interaction,\n",
    "        question: str ) -> None:\n",
    "        \"\"\"Process question and send response\"\"\"\n",
    "        try:\n",
    "            \n",
    "            await interaction.response.defer(thinking=True)\n",
    "            global task_message\n",
    "            task_message = await interaction.edit_original_response(content=\"⋯ Understanding your question\")\n",
    "            await utils.start_animation(task_message)\n",
    "            response = await self.rag_pipeline.process_question(question)\n",
    "            await self._send_chunked_response(interaction, response)\n",
    "            logger.info(f\"Successfully processed question for {interaction.user.name}\")\n",
    "            await asu_store.store_to_vector_db()\n",
    "            await (google_sheet.increment_function_call(discord_state.get('user_id'), 'G'))\n",
    "            await (google_sheet.increment_function_call(discord_state.get('user_id'), 'N'))\n",
    "            await (google_sheet.update_user_column(interaction.user.id, 'E', question))\n",
    "            await (google_sheet.update_user_column(interaction.user.id, 'F', response))\n",
    "            \n",
    "            await google_sheet.perform_updates()\n",
    "            \n",
    "            firestore.update_message(\"user_message\", question)\n",
    "            document_id = await firestore.push_message()\n",
    "            logger.info(f\"Message pushed with document ID: {document_id}\")\n",
    "\n",
    "        except asyncio.TimeoutError:\n",
    "            logger.error(\"Response generation timed out\")\n",
    "            await self._send_error_response(\n",
    "                interaction,\n",
    "                \"Sorry, the response took too long to generate. Please try again.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing question at discord class: {str(e)}\", exc_info=True)\n",
    "            await self._send_error_response(interaction)\n",
    "\n",
    "    async def setup_verify_button(self):\n",
    "        channel = self.client.get_channel(1323386003896926248)  # Verify channel ID\n",
    "        if channel:\n",
    "            view = discord.ui.View(timeout=None)\n",
    "            view.add_item(VerifyButton())\n",
    "            await channel.send(\"Click here to verify\", view=view)\n",
    "\n",
    "    async def _send_chunked_response( self,interaction: discord.Interaction,response: str) -> None:\n",
    "        \"\"\"Send response in chunks if needed\"\"\"\n",
    "        try:\n",
    "            ground_sources = utils.get_ground_sources()\n",
    "            # Create buttons for each URL\n",
    "            buttons = []\n",
    "            for url in ground_sources:\n",
    "                domain = urlparse(url).netloc\n",
    "                button = discord.ui.Button(label=domain, url=url, style=discord.ButtonStyle.link)\n",
    "                buttons.append(button)\n",
    "            # Custom link for feedbacks\n",
    "            button = discord.ui.Button(label=\"Feedback\", url=\"https://discord.com/channels/1256076931166769152/1323386415337177150\", style=discord.ButtonStyle.link)\n",
    "            buttons.append(button)\n",
    "\n",
    "            view = discord.ui.View()\n",
    "            for button in buttons:\n",
    "                view.add_item(button)\n",
    "\n",
    "            if len(response) > self.config.max_response_length:\n",
    "                chunks = [\n",
    "                    response[i:i + self.config.chunk_size]\n",
    "                    for i in range(0, len(response), self.config.chunk_size)\n",
    "                ]\n",
    "                global task_message\n",
    "                await utils.stop_animation(task_message, chunks[0])\n",
    "                for chunk in chunks[1:-1]:\n",
    "                    await interaction.followup.send(content=chunk)\n",
    "                await interaction.followup.send(content=chunks[-1], view=view)\n",
    "            else:\n",
    "                await utils.stop_animation(task_message, response,View=view)\n",
    "            \n",
    "            utils.clear_ground_sources()\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sending response: {str(e)}\", exc_info=True)\n",
    "            await self._send_error_response(interaction)\n",
    "\n",
    "    async def _send_error_response(\n",
    "        self,\n",
    "        interaction: discord.Interaction,\n",
    "        message: str = \"Sorry, I encountered an error processing your question. Please try again.\") -> None:\n",
    "        \"\"\"Send error response to user\"\"\"\n",
    "        try:\n",
    "            if not interaction.response.is_done():\n",
    "                await interaction.response.send_message(\n",
    "                    content=message,\n",
    "                    ephemeral=True\n",
    "                )\n",
    "            else:\n",
    "                await interaction.followup.send(\n",
    "                    content=message,\n",
    "                    ephemeral=True\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error sending error response: {str(e)}\", exc_info=True)\n",
    "\n",
    "    async def _handle_ready(self):\n",
    "        try:\n",
    "            await self.tree.sync()\n",
    "            logger.info(f'Bot is ready! Logged in as {self.client.user}')\n",
    "            await self.setup_verify_button()  # Set up the verify button when the bot starts\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in ready event: {str(e)}\", exc_info=True)\n",
    "\n",
    "    async def start(self) -> None:\n",
    "        \"\"\"Start the Discord bot\"\"\"\n",
    "        try:\n",
    "            await self.client.start(self.config.token)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to start bot: {str(e)}\", exc_info=True)\n",
    "            raise\n",
    "\n",
    "    async def close(self) -> None:\n",
    "        \"\"\"Close the Discord bot\"\"\"\n",
    "        try:\n",
    "            await self.client.close()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error closing bot: {str(e)}\", exc_info=True)\n",
    "\n",
    "def run_discord_bot(rag_pipeline, config: Optional[BotConfig] = None):\n",
    "    \"\"\"Run the Discord bot\"\"\"\n",
    "    bot = ASUDiscordBot(rag_pipeline, config)\n",
    "    \n",
    "    async def run():\n",
    "        try:\n",
    "            await bot.start()\n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"\\nBot shutdown requested\")\n",
    "            await bot.close()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Bot error: {str(e)}\", exc_info=True)\n",
    "            await bot.close()\n",
    "\n",
    "    # Run the bot\n",
    "    asyncio.run(run())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = BotConfig(\n",
    "        token=app_config.get_discord_bot_token(),\n",
    "    )\n",
    "    run_discord_bot(asu_rag, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
